[
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Reference",
    "section": "",
    "text": "These pages contain the test models, node descriptions and Ribasim Python API documentation.",
    "crumbs": [
      "Reference"
    ]
  },
  {
    "objectID": "reference/node/tabulated-rating-curve.html",
    "href": "reference/node/tabulated-rating-curve.html",
    "title": "TabulatedRatingCurve",
    "section": "",
    "text": "A TabulatedRatingCurve determines outflow from a Basin by looking up the flow rate that corresponds to the current upstream level from a rating curve. The TabulatedRatingCurve takes a rating curve as input. Use it for instance to model flow over a weir.",
    "crumbs": [
      "Reference",
      "Nodes",
      "TabulatedRatingCurve"
    ]
  },
  {
    "objectID": "reference/node/tabulated-rating-curve.html#static",
    "href": "reference/node/tabulated-rating-curve.html#static",
    "title": "TabulatedRatingCurve",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ncontrol_state\nString\n-\n(optional) sorted per node_id\n\n\nactive\nBool\n-\n(optional, default true)\n\n\nmax_downstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\nsorted per control_state, unique\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nstart at 0, increasing\n\n\n\nThus a single rating curve can be given by the following table:\n\n\n\nnode_id\nflow_rate\nlevel\n\n\n\n\n2\n0.0\n-0.10\n\n\n2\n0.0001\n0.09\n\n\n2\n0.01\n0.29\n\n\n2\n0.9\n20.09\n\n\n\nBelow the lowest given level of -0.10, the flow rate is kept at 0. Between given levels the flow rate is interpolated linearly. Above the maximum given level of 20.09, the flow rate keeps increases linearly according to the slope of the last segment.\n\n1.1.1 Interpolation\nThe \\(Q(h)\\) relationship of a tabulated rating curve is defined as a linear interpolation.\n\n\nCode\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, Markdown\n\nnp.random.seed(0)\nfontsize = 15\n\nN = 10\nlevel = np.cumsum(np.random.rand(N))\nflow = level**2 + np.random.rand(N)\nflow[0] = 0.0\nfig, ax = plt.subplots()\nax.set_xticks([])\nax.set_yticks([0])\nax.scatter(level, flow, label = \"data\")\nax.plot(level, flow, label = \"interpolation\", color = \"C0\")\nax.plot([level[0] - 1, level[0]], [0, 0], label = \"extrapolation\", linestyle = \"dashed\")\nax.legend()\nax.set_xlabel(\"level\", fontsize = fontsize)\nax.set_ylabel(\"flow\", fontsize = fontsize)\n\nlevel_extrap = 2 * level[-1] - level[-2]\nflow_extrap = 2 * flow[-1] - flow[-2]\nax.plot([level[-1], level_extrap], [flow[-1], flow_extrap], color = \"C0\", linestyle = \"dashed\")\nax.set_xlim(level[0] - 0.5, (level[-1] + level_extrap)/2)\n\nmarkdown_table = pd.DataFrame(\n        data = {\n            \"level\" : level,\n            \"flow\" : flow\n        }\n    ).to_markdown(index = False)\n\ndisplay(Markdown(markdown_table))\n\n\n\n\n\nlevel\nflow\n\n\n\n\n0.548814\n0\n\n\n1.264\n2.1266\n\n\n1.86677\n4.05286\n\n\n2.41165\n6.74165\n\n\n2.8353\n8.10999\n\n\n3.4812\n12.2059\n\n\n3.91879\n15.3771\n\n\n4.81056\n23.9741\n\n\n5.77422\n34.1198\n\n\n6.15766\n38.7868\n\n\n\n\n\n\n\n\n\n\n\n\nHere it is validated that the flow starts at \\(0\\) and is non-decreasing. The flow is extrapolated as \\(0\\) backward and linearly forward.",
    "crumbs": [
      "Reference",
      "Nodes",
      "TabulatedRatingCurve"
    ]
  },
  {
    "objectID": "reference/node/tabulated-rating-curve.html#time",
    "href": "reference/node/tabulated-rating-curve.html#time",
    "title": "TabulatedRatingCurve",
    "section": "1.2 Time",
    "text": "1.2 Time\nThis table is the transient form of the TabulatedRatingCurve table. The only difference is that a time column is added. The table must by sorted by time, and per time it must be sorted by node_id. With this the rating curves can be updated over time. Note that a node_id can be either in this table or in the static one, but not both.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ntime\nDateTime\n-\nsorted per node_id\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\nsorted per node_id per time\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\nmax_downstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)",
    "crumbs": [
      "Reference",
      "Nodes",
      "TabulatedRatingCurve"
    ]
  },
  {
    "objectID": "reference/node/discrete-control.html",
    "href": "reference/node/discrete-control.html",
    "title": "DiscreteControl",
    "section": "",
    "text": "Set parameters of other nodes based on model state conditions (e.g. Basin level). The table below shows which parameters are controllable for a given node type.\nCode\nusing Ribasim\nusing DataFrames: DataFrame\nusing MarkdownTables\n\nnode_names = Symbol[]\ncontrollable_parameters = String[]\n\nfor node_type in fieldtypes(Ribasim.Parameters)\n    if node_type &lt;: Ribasim.AbstractParameterNode\n        node_name = nameof(node_type)\n        controllable_fields = Ribasim.controllablefields(node_name)\n        controllable_fields = sort!(string.(controllable_fields))\n        if node_name == :TabulatedRatingCurve\n            controllable_fields = map(s -&gt; replace(s, \"table\" =&gt; \"q(h) relationship (given by level, flow_rate)\"), controllable_fields)\n        end\n        if !isempty(controllable_fields)\n            push!(node_names, Ribasim.snake_case(node_name))\n            push!(controllable_parameters, join(controllable_fields, \", \"))\n        end\n    end\nend\n\ndf = DataFrame(:node =&gt; node_names, :controllable_parameters =&gt; controllable_parameters)\n\nmarkdown_table(df)\n\n\n\n\n\n\n\n\n\nnode\ncontrollable_parameters\n\n\n\n\nlinear_resistance\nactive, resistance\n\n\nmanning_resistance\nactive, manning_n\n\n\ntabulated_rating_curve\nactive, q(h) relationship (given by level, flow_rate)\n\n\npump\nactive, flow_rate\n\n\noutlet\nactive, flow_rate\n\n\npid_control\nactive, derivative, integral, proportional, target",
    "crumbs": [
      "Reference",
      "Nodes",
      "DiscreteControl"
    ]
  },
  {
    "objectID": "reference/node/discrete-control.html#variable",
    "href": "reference/node/discrete-control.html#variable",
    "title": "DiscreteControl",
    "section": "1.1 Variable",
    "text": "1.1 Variable\nThe compound variable schema defines linear combinations of variables which can be used in conditions. This means that this schema defines new variables with the given compound_variable_id that look like \\[\n\\text{weight}_1 * \\text{variable}_1 + \\text{weight}_2 * \\text{variable}_2 + \\ldots,\n\\]\nwhich can be for instance an average or a difference of variables. If a variable comes from a time-series, a look ahead \\(\\Delta t\\) can be supplied.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ncompound_variable_id\nInt32\n-\nsorted per node_id\n\n\nlisten_node_type\nString\n-\nknown node type\n\n\nlisten_node_id\nInt32\n-\nsorted per node_id\n\n\nvariable\nString\n-\nmust be “level” or “flow_rate”, sorted per listen_node_id\n\n\nweight\nFloat64\n-\n(optional, default 1.0)\n\n\nlook_ahead\nFloat64\n\\(\\text{s}\\)\nOnly on transient boundary conditions, non-negative (optional, default 0.0).\n\n\n\nThese variables can be listened to: - The level of a Basin - The level of a LevelBoundary (supports look ahead) - The flow rate through one of these node types: Pump, Outlet, TabulatedRatingCurve, LinearResistance, ManningResistance - The flow rate of a FlowBoundary (supports look ahead)",
    "crumbs": [
      "Reference",
      "Nodes",
      "DiscreteControl"
    ]
  },
  {
    "objectID": "reference/node/discrete-control.html#condition",
    "href": "reference/node/discrete-control.html#condition",
    "title": "DiscreteControl",
    "section": "1.2 Condition",
    "text": "1.2 Condition\nThe condition schema defines conditions of the form ‘the discrete_control node with this node_id listens to whether the variable given by the node_id and compound_variable_id is greater than greater_than’. In equation form:\n\\[\n    \\text{weight}_1 * \\text{variable}_1 + \\text{weight}_2 * \\text{variable}_2 + \\ldots &gt; \\text{greater\\_than}.\n\\]\nMultiple conditions with different greater_than values can be defined on the same compound_variable.\nNote the strict inequality ‘\\(&gt;\\)’ in the equation above. This means for instance that if a simulation starts with a compound variable exactly at the greater_than value, the condition is false.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ncompound_variable_id\nInt32\n-\n-\n\n\ngreater_than\nFloat64\nvarious\nsorted per variable",
    "crumbs": [
      "Reference",
      "Nodes",
      "DiscreteControl"
    ]
  },
  {
    "objectID": "reference/node/discrete-control.html#logic",
    "href": "reference/node/discrete-control.html#logic",
    "title": "DiscreteControl",
    "section": "1.3 Logic",
    "text": "1.3 Logic\nThe logic schema defines which control states are triggered based on the truth of the conditions a DiscreteControl node listens to. DiscreteControl is applied in the Julia core as follows:\n\nDuring the simulation it is checked whether the truth of any of the conditions changes.\nWhen a condition changes, the corresponding DiscreteControl node ID is retrieved (node_id in the condition schema above).\nThe truth value of all the conditions this DiscreteControl node listens to are retrieved, in the sorted order as specified in the condition schema. This is then converted into a string of “T” for true and “F” for false. This string we call the truth state.*\nThe table below determines for the given DiscreteControl node ID and truth state what the corresponding control state is.\nFor all the nodes this DiscreteControl node affects (as given by the “control” edges in Edges / static), their parameters are set to those parameters in NodeType / static corresponding to the determined control state.\n\n*. There is also a second truth state created in which for the last condition that changed it is specified whether it was an upcrossing (“U”) or downcrossing (“D”) of the threshold (greater than) value. If a control state is specified for a truth state that is crossing-specific, this takes precedence over the control state for the truth state that contains only “T” and “F”.\n\n\n\n\n\n\nNote\n\n\n\nWhen creating truth states, it is important to not use the order of the condition table as you provide it, but the order as it is written to the file. Users can provide tables in any order, but when writing the model it gets sorted in the required order as specified in the schema.\n\n\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ncontrol_state\nString\n-\n-\n\n\ntruth_state\nString\n-\nConsists of the characters “T” (true), “F” (false), “U” (upcrossing), “D” (downcrossing) and “*” (any), sorted per node_id",
    "crumbs": [
      "Reference",
      "Nodes",
      "DiscreteControl"
    ]
  },
  {
    "objectID": "reference/node/level-demand.html",
    "href": "reference/node/level-demand.html",
    "title": "LevelDemand",
    "section": "",
    "text": "A LevelDemand node associates a minimum and a maximum level with connected Basins to be used by the allocation algorithm.\nSince this connection conveys information rather than flow, an outgoing control edge must be used. Below the minimum level the Basin has a demand, above the maximum level the Basin has a surplus and acts as a source. The source can be used by all nodes with demands in order of priority.\nThe same LevelDemand node can be used for Basins in different subnetworks.\nBoth min_level and max_level are optional, to be able to handle only the demand or surplus side. If both are missing, LevelDemand won’t have any effects on allocation.",
    "crumbs": [
      "Reference",
      "Nodes",
      "LevelDemand"
    ]
  },
  {
    "objectID": "reference/node/level-demand.html#static",
    "href": "reference/node/level-demand.html#static",
    "title": "LevelDemand",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\nmin_level\nFloat64\n\\(\\text{m}\\)\n(optional, default -Inf)\n\n\nmax_level\nFloat64\n\\(\\text{m}\\)\n(optional, default Inf)\n\n\npriority\nInt32\n-\npositive",
    "crumbs": [
      "Reference",
      "Nodes",
      "LevelDemand"
    ]
  },
  {
    "objectID": "reference/node/level-demand.html#time",
    "href": "reference/node/level-demand.html#time",
    "title": "LevelDemand",
    "section": "1.2 Time",
    "text": "1.2 Time\nThis table is the transient form of the LevelDemand table, in which time-dependent minimum and maximum levels can be supplied. Similar to the static version, only a single priority per LevelDemand node can be provided.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ntime\nDateTime\n-\nsorted per node id\n\n\nmin_level\nFloat64\n\\(\\text{m}\\)\n-\n\n\nmax_level\nFloat64\n\\(\\text{m}\\)\n-\n\n\npriority\nInt32\n-\npositive",
    "crumbs": [
      "Reference",
      "Nodes",
      "LevelDemand"
    ]
  },
  {
    "objectID": "reference/node/linear-resistance.html",
    "href": "reference/node/linear-resistance.html",
    "title": "LinearResistance",
    "section": "",
    "text": "Bidirectional flow proportional to the level difference between the connected basins.",
    "crumbs": [
      "Reference",
      "Nodes",
      "LinearResistance"
    ]
  },
  {
    "objectID": "reference/node/linear-resistance.html#static",
    "href": "reference/node/linear-resistance.html#static",
    "title": "LinearResistance",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ncontrol_state\nString\n-\n(optional) sorted per node_id\n\n\nactive\nBool\n-\n(optional, default true)\n\n\nresistance\nFloat64\n\\(\\text{s}/\\text{m}^2\\)\n-\n\n\nmax_flow_rate\nFloat64\n\\(\\text{m}^3/s\\)\nnon-negative",
    "crumbs": [
      "Reference",
      "Nodes",
      "LinearResistance"
    ]
  },
  {
    "objectID": "reference/node/pump.html",
    "href": "reference/node/pump.html",
    "title": "Pump",
    "section": "",
    "text": "Pump water from a source node to a destination node. The set flow rate will be pumped unless the intake storage is less than \\(10~m^3\\), in which case the flow rate will be linearly reduced to \\(0~m^3/s\\). The intake must be either a Basin or LevelBoundary. When PID controlled, the pump must point away from the controlled basin in terms of edges.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Pump"
    ]
  },
  {
    "objectID": "reference/node/pump.html#static",
    "href": "reference/node/pump.html#static",
    "title": "Pump",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ncontrol_state\nString\n-\n(optional) sorted per node_id\n\n\nactive\nBool\n-\n(optional, default true)\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\nmin_flow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n(optional, default 0.0)\n\n\nmax_flow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n(optional)\n\n\nmin_upstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)\n\n\nmax_downstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)",
    "crumbs": [
      "Reference",
      "Nodes",
      "Pump"
    ]
  },
  {
    "objectID": "reference/node/user-demand.html",
    "href": "reference/node/user-demand.html",
    "title": "UserDemand",
    "section": "",
    "text": "A UserDemand takes water from the Basin that supplies it.\nWhen allocation is not used, a UserDemand node attempts to extract the full demand from the connected Basin. When allocation is used, the amount a UserDemand node is allowed to abstract is determined by the allocation algorithm. This algorithm first tries to allocate from the directly connected basin, and then from other sources whose flow can reach the UserDemand node. Note that priority is used to determine the order in which the UserDemands are allocated water. This parameter is only used when allocation is active and is optional when allocation is not active.\nWhen the connected Basin is almost empty or reaches the minimum level at which the UserDemand can extract water (min_level), it will stop extraction.\nUserDemands need an outgoing flow edge along which they can send their return flow, this can also be to the same Basin from which it extracts water. The amount of return flow is always a fraction of the inflow into the UserDemand. The difference is consumed by the UserDemand.",
    "crumbs": [
      "Reference",
      "Nodes",
      "UserDemand"
    ]
  },
  {
    "objectID": "reference/node/user-demand.html#static",
    "href": "reference/node/user-demand.html#static",
    "title": "UserDemand",
    "section": "1.1 Static",
    "text": "1.1 Static\nThis table contains the static form of the UserDemand node.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\nactive\nBool\n-\n(optional, default true)\n\n\ndemand\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\nreturn_factor\nFloat64\n-\nbetween [0 - 1]\n\n\nmin_level\nFloat64\n\\(\\text{m}\\)\n-\n\n\npriority\nInt32\n-\npositive, sorted per node id",
    "crumbs": [
      "Reference",
      "Nodes",
      "UserDemand"
    ]
  },
  {
    "objectID": "reference/node/user-demand.html#time",
    "href": "reference/node/user-demand.html#time",
    "title": "UserDemand",
    "section": "1.2 Time",
    "text": "1.2 Time\nThis table is the transient form of the UserDemand table. The only difference is that a time column is added and activity is assumed to be true. The table must by sorted by time, and per time it must be sorted by node_id. With this the demand can be updated over time. In between the given times the demand is interpolated linearly, and outside the demand is constant given by the nearest time value. The priority is not allowed to change over time. Note that a node_id can be either in this table or in the static one, but not both.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\npriority\nInt32\n-\npositive, sorted per node id\n\n\ntime\nDateTime\n-\nsorted per priority per node id\n\n\ndemand\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\nreturn_factor\nFloat64\n-\nbetween [0 - 1]\n\n\nmin_level\nFloat64\n\\(\\text{m}\\)\n-",
    "crumbs": [
      "Reference",
      "Nodes",
      "UserDemand"
    ]
  },
  {
    "objectID": "reference/node/pid-control.html",
    "href": "reference/node/pid-control.html",
    "title": "PidControl",
    "section": "",
    "text": "The PidControl node controls the level in a Basin by continuously controlling the flow rate of a connected Pump or Outlet. See also PID controller.\nWhen a PidControl node is made inactive, the node under its control retains the last flow rate value, and the error integral is reset to 0.\nIn the future controlling the flow on a particular edge could be supported.",
    "crumbs": [
      "Reference",
      "Nodes",
      "PidControl"
    ]
  },
  {
    "objectID": "reference/node/pid-control.html#time",
    "href": "reference/node/pid-control.html#time",
    "title": "PidControl",
    "section": "2.1 Time",
    "text": "2.1 Time\nThis table is the transient form of the PidControl table. The differences are that a time column is added and the nodes are assumed to be active so this column is removed. The table must by sorted by time, and per time it must be sorted by node_id. With this the target level and PID coefficients can be updated over time. In between the given times the these values interpolated linearly, and outside these values area constant given by the nearest time value. Note that a node_id can be either in this table or in the static one, but not both.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ntime\nDateTime\n-\nsorted per node_id\n\n\nlisten_node_type\nInt32\n-\nknown node type\n\n\nlisten_node_id\nInt32\n-\n-\n\n\ntarget\nFloat64\n\\(\\text{m}\\)\n-\n\n\nproportional\nFloat64\n\\(\\text{s}^{-1}\\)\n-\n\n\nintegral\nFloat64\n\\(\\text{s}^{-2}\\)\n-\n\n\nderivative\nFloat64\n-\n-",
    "crumbs": [
      "Reference",
      "Nodes",
      "PidControl"
    ]
  },
  {
    "objectID": "reference/node/pid-control.html#the-derivative-term",
    "href": "reference/node/pid-control.html#the-derivative-term",
    "title": "PidControl",
    "section": "3.1 The derivative term",
    "text": "3.1 The derivative term\nWhen \\(K_d \\ne 0\\) this adds a level of complexity. We can see this by looking at the error derivative more closely: \\[\n\\frac{\\text{d}e}{\\text{d}t} = \\frac{\\text{d}\\text{SP}}{\\text{d}t} - \\frac{1}{A(u_\\text{PID})}\\frac{\\text{d}u_\\text{PID}}{\\text{d}t},\n\\]\nwhere \\(A(u_\\text{PID})\\) is the area of the controlled basin as a function of the storage of the controlled basin \\(u_\\text{PID}\\). The complexity arises from the fact that \\(Q_\\text{PID}\\) is a contribution to \\(\\frac{\\text{d}u_\\text{PID}}{\\text{d}t} = f_\\text{PID}\\), which makes Equation 2 an implicit equation for \\(Q_\\text{PID}\\). We define\n\\[\nf_\\text{PID} = \\hat{f}_\\text{PID} \\pm Q_\\text{pump/outlet},\n\\]\nthat is, \\(\\hat{f}_\\text{PID}\\) is the right hand side of the ODE for the controlled basin storage state without the contribution of the PID controlled pump. The plus sign holds for an outlet and the minus sign for a pump, dictated by the way the pump and outlet connectivity to the controlled basin is enforced.\nUsing this, solving Equation 2 for \\(Q_\\text{PID}\\) yields \\[\nQ_\\text{pump/outlet} = \\text{clamp}\\left(\\phi(u_\\text{us})\\frac{K_pe + K_iI + K_d \\left(\\frac{\\text{d}\\text{SP}}{\\text{d}t}-\\frac{\\hat{f}_\\text{PID}}{A(u_\\text{PID})}\\right)}{1\\pm\\phi(u_\\text{us})\\frac{K_d}{A(u_\\text{PID})}}, Q_{\\min}, Q_{\\max}\\right),\n\\]\nwhere the clamping is again done last. Note that to compute this, \\(\\hat{f}_\\text{PID}\\) has to be known first, meaning that the PID controlled Pump or Outlet flow rate has to be computed after all other contributions to the PID controlled Basin’s storage are known.",
    "crumbs": [
      "Reference",
      "Nodes",
      "PidControl"
    ]
  },
  {
    "objectID": "reference/node/pid-control.html#the-sign-of-the-parameters",
    "href": "reference/node/pid-control.html#the-sign-of-the-parameters",
    "title": "PidControl",
    "section": "3.2 The sign of the parameters",
    "text": "3.2 The sign of the parameters\nNote by Equation 1 that the error is positive if the setpoint is larger than the Basin level and negative if the setpoint is smaller than the Basin level.\nWe enforce the convention that when a Pump is controlled, its edge points away from the Basin, and when an Outlet is controlled, its edge points towards the Basin, so that the main flow direction along these edges is positive. Therefore, positive flows of the Pump and Outlet have opposite effects on the Basin, and thus the parameters \\(K_p,K_i,K_d\\) of the Pump and Outlet must have opposite signs to achieve the same goal.",
    "crumbs": [
      "Reference",
      "Nodes",
      "PidControl"
    ]
  },
  {
    "objectID": "reference/python/Node.html",
    "href": "reference/python/Node.html",
    "title": "1 Node",
    "section": "",
    "text": "Node(self, node_id=None, geometry=Point(), **kwargs)\nDefines a node for the model.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nnode_id\nOptional[NonNegativeInt]\nInteger ID of the node. Must be unique for the model.\n\n\ngeometry\nshapely.geometry.Point\nThe coordinates of the node.\n\n\nname\nstr\nAn optional name of the node.\n\n\nsubnetwork_id\nint\nOptionally adds this node to a subnetwork, which is input for the allocation algorithm.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ninto_geodataframe\n\n\n\n\n\n\nNode.into_geodataframe(node_type, node_id)"
  },
  {
    "objectID": "reference/python/Node.html#attributes",
    "href": "reference/python/Node.html#attributes",
    "title": "1 Node",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nnode_id\nOptional[NonNegativeInt]\nInteger ID of the node. Must be unique for the model.\n\n\ngeometry\nshapely.geometry.Point\nThe coordinates of the node.\n\n\nname\nstr\nAn optional name of the node.\n\n\nsubnetwork_id\nint\nOptionally adds this node to a subnetwork, which is input for the allocation algorithm."
  },
  {
    "objectID": "reference/python/Node.html#methods",
    "href": "reference/python/Node.html#methods",
    "title": "1 Node",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ninto_geodataframe\n\n\n\n\n\n\nNode.into_geodataframe(node_type, node_id)"
  },
  {
    "objectID": "reference/python/Model.html",
    "href": "reference/python/Model.html",
    "title": "1 Model",
    "section": "",
    "text": "Model()\nA model of inland water resources systems.\n\n\n\n\n\nName\nDescription\n\n\n\n\nallocation\n\n\n\nbasin\n\n\n\ncontinuous_control\n\n\n\ncrs\n\n\n\ndiscrete_control\n\n\n\nedge\n\n\n\nendtime\n\n\n\nfilepath\n\n\n\nflow_boundary\n\n\n\nflow_demand\n\n\n\ninput_dir\n\n\n\nlevel_boundary\n\n\n\nlevel_demand\n\n\n\nlinear_resistance\n\n\n\nlogging\n\n\n\nmanning_resistance\n\n\n\nmodel_config\n\n\n\noutlet\n\n\n\npid_control\n\n\n\npump\n\n\n\nresults\n\n\n\nresults_dir\n\n\n\nsolver\n\n\n\nstarttime\n\n\n\ntabulated_rating_curve\n\n\n\nterminal\n\n\n\nuse_validation\n\n\n\nuser_demand\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nmodel_post_init\n\n\n\nnode_table\nCompute the full sorted NodeTable from all node types.\n\n\nplot\nPlot the nodes, edges and allocation networks of the model.\n\n\nplot_control_listen\nPlot the implicit listen edges of the model.\n\n\nread\nRead a model from a TOML file.\n\n\nset_crs\nSet the coordinate reference system of the data in the model.\n\n\nset_filepath\nSet the filepath of this instance.\n\n\nto_crs\n\n\n\nto_xugrid\nConvert the network to a xugrid.UgridDataset.\n\n\nwrite\nWrite the contents of the model to disk and save it as a TOML configuration file.\n\n\n\n\n\nModel.model_post_init(__context)\n\n\n\nModel.node_table()\nCompute the full sorted NodeTable from all node types.\n\n\n\nModel.plot(ax=None, indicate_subnetworks=True, aspect_ratio_bound=0.33)\nPlot the nodes, edges and allocation networks of the model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nax\nmatplotlib.pyplot.Artist\nAxes on which to draw the plot.\nNone\n\n\nindicate_subnetworks\nbool\nWhether to indicate subnetworks with a convex hull backdrop.\nTrue\n\n\naspect_ratio_bound\nfloat\nThe maximal aspect ratio in (0,1). The smaller this number, the further the figure shape is allowed to be from a square\n0.33\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmatplotlib.pyplot.Artist\nAxis on which the plot is drawn.\n\n\n\n\n\n\n\nModel.plot_control_listen(ax)\nPlot the implicit listen edges of the model.\n\n\n\nModel.read(filepath)\nRead a model from a TOML file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilepath\nstr | PathLike[str]\nThe path to the TOML file.\nrequired\n\n\n\n\n\n\n\nModel.set_crs(crs)\nSet the coordinate reference system of the data in the model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncrs\nstr\nCoordinate reference system, like “EPSG:4326” for WGS84 latitude longitude.\nrequired\n\n\n\n\n\n\n\nModel.set_filepath(filepath)\nSet the filepath of this instance.\nArgs: filepath (Path): The filepath to set.\n\n\n\nModel.to_crs(crs)\n\n\n\nModel.to_xugrid(add_flow=False, add_allocation=False)\nConvert the network to a xugrid.UgridDataset.\nEither the flow or the allocation data can be added, but not both simultaneously. This method will throw ImportError if the optional dependency xugrid isn’t installed.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nadd_flow\nbool\nadd flow results (Optional, defaults to False)\nFalse\n\n\nadd_allocation\nbool\nadd allocation results (Optional, defaults to False)\nFalse\n\n\n\n\n\n\n\nModel.write(filepath)\nWrite the contents of the model to disk and save it as a TOML configuration file.\nIf filepath.parent does not exist, it is created before writing.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilepath\nstr | PathLike[str]\nA file path with .toml extension.\nrequired"
  },
  {
    "objectID": "reference/python/Model.html#attributes",
    "href": "reference/python/Model.html#attributes",
    "title": "1 Model",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nallocation\n\n\n\nbasin\n\n\n\ncontinuous_control\n\n\n\ncrs\n\n\n\ndiscrete_control\n\n\n\nedge\n\n\n\nendtime\n\n\n\nfilepath\n\n\n\nflow_boundary\n\n\n\nflow_demand\n\n\n\ninput_dir\n\n\n\nlevel_boundary\n\n\n\nlevel_demand\n\n\n\nlinear_resistance\n\n\n\nlogging\n\n\n\nmanning_resistance\n\n\n\nmodel_config\n\n\n\noutlet\n\n\n\npid_control\n\n\n\npump\n\n\n\nresults\n\n\n\nresults_dir\n\n\n\nsolver\n\n\n\nstarttime\n\n\n\ntabulated_rating_curve\n\n\n\nterminal\n\n\n\nuse_validation\n\n\n\nuser_demand"
  },
  {
    "objectID": "reference/python/Model.html#methods",
    "href": "reference/python/Model.html#methods",
    "title": "1 Model",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nmodel_post_init\n\n\n\nnode_table\nCompute the full sorted NodeTable from all node types.\n\n\nplot\nPlot the nodes, edges and allocation networks of the model.\n\n\nplot_control_listen\nPlot the implicit listen edges of the model.\n\n\nread\nRead a model from a TOML file.\n\n\nset_crs\nSet the coordinate reference system of the data in the model.\n\n\nset_filepath\nSet the filepath of this instance.\n\n\nto_crs\n\n\n\nto_xugrid\nConvert the network to a xugrid.UgridDataset.\n\n\nwrite\nWrite the contents of the model to disk and save it as a TOML configuration file.\n\n\n\n\n\nModel.model_post_init(__context)\n\n\n\nModel.node_table()\nCompute the full sorted NodeTable from all node types.\n\n\n\nModel.plot(ax=None, indicate_subnetworks=True, aspect_ratio_bound=0.33)\nPlot the nodes, edges and allocation networks of the model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nax\nmatplotlib.pyplot.Artist\nAxes on which to draw the plot.\nNone\n\n\nindicate_subnetworks\nbool\nWhether to indicate subnetworks with a convex hull backdrop.\nTrue\n\n\naspect_ratio_bound\nfloat\nThe maximal aspect ratio in (0,1). The smaller this number, the further the figure shape is allowed to be from a square\n0.33\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmatplotlib.pyplot.Artist\nAxis on which the plot is drawn.\n\n\n\n\n\n\n\nModel.plot_control_listen(ax)\nPlot the implicit listen edges of the model.\n\n\n\nModel.read(filepath)\nRead a model from a TOML file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilepath\nstr | PathLike[str]\nThe path to the TOML file.\nrequired\n\n\n\n\n\n\n\nModel.set_crs(crs)\nSet the coordinate reference system of the data in the model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncrs\nstr\nCoordinate reference system, like “EPSG:4326” for WGS84 latitude longitude.\nrequired\n\n\n\n\n\n\n\nModel.set_filepath(filepath)\nSet the filepath of this instance.\nArgs: filepath (Path): The filepath to set.\n\n\n\nModel.to_crs(crs)\n\n\n\nModel.to_xugrid(add_flow=False, add_allocation=False)\nConvert the network to a xugrid.UgridDataset.\nEither the flow or the allocation data can be added, but not both simultaneously. This method will throw ImportError if the optional dependency xugrid isn’t installed.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nadd_flow\nbool\nadd flow results (Optional, defaults to False)\nFalse\n\n\nadd_allocation\nbool\nadd allocation results (Optional, defaults to False)\nFalse\n\n\n\n\n\n\n\nModel.write(filepath)\nWrite the contents of the model to disk and save it as a TOML configuration file.\nIf filepath.parent does not exist, it is created before writing.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilepath\nstr | PathLike[str]\nA file path with .toml extension.\nrequired"
  },
  {
    "objectID": "reference/python/Allocation.html",
    "href": "reference/python/Allocation.html",
    "title": "1 Allocation",
    "section": "",
    "text": "Allocation()\nDefines the allocation optimization algorithm options.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ntimestep\nfloat\nThe simulated time in seconds between successive allocation calls (Optional, defaults to 86400)\n\n\nuse_allocation\nbool\nWhether the allocation algorithm should be active. If not, UserDemand nodes attempt to abstract their full demand (Optional, defaults to False)"
  },
  {
    "objectID": "reference/python/Allocation.html#attributes",
    "href": "reference/python/Allocation.html#attributes",
    "title": "1 Allocation",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ntimestep\nfloat\nThe simulated time in seconds between successive allocation calls (Optional, defaults to 86400)\n\n\nuse_allocation\nbool\nWhether the allocation algorithm should be active. If not, UserDemand nodes attempt to abstract their full demand (Optional, defaults to False)"
  },
  {
    "objectID": "reference/python/EdgeTable.html",
    "href": "reference/python/EdgeTable.html",
    "title": "1 EdgeTable",
    "section": "",
    "text": "EdgeTable()\nDefines the connections between nodes.\n\n\n\n\n\nName\nDescription\n\n\n\n\ndf\n\n\n\nfilepath\n\n\n\nmodel_config\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd\nAdd an edge between nodes. The type of the edge (flow or control)\n\n\ncolumns\nRetrieve column names.\n\n\nplot\nPlot the edges of the model.\n\n\nset_filepath\nSet the filepath of this instance.\n\n\nsort\n\n\n\ntablename\nRetrieve tablename based on attached Schema.\n\n\ntableschema\nRetrieve Pandera Schema.\n\n\n\n\n\nEdgeTable.add(from_node, to_node, geometry=None, name='', subnetwork_id=None, edge_id=None, **kwargs)\nAdd an edge between nodes. The type of the edge (flow or control) is automatically inferred from the type of the from_node.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfrom_node\nNodeData\nA node indexed by its node ID, e.g. model.basin[1]\nrequired\n\n\nto_node\nNodeData\nA node indexed by its node ID, e.g. model.linear_resistance[1]\nrequired\n\n\ngeometry\nLineString | MultiLineString | None\nThe geometry of a line. If not supplied, it creates a straight line between the nodes.\nNone\n\n\nname\nstr\nAn optional name for the edge.\n''\n\n\nsubnetwork_id\nint | None\nAn optional subnetwork id for the edge. This edge indicates a source for the allocation algorithm, and should thus not be set for every edge in a subnetwork.\nNone\n\n\n**kwargs\nDict\n\n{}\n\n\n\n\n\n\n\nEdgeTable.columns()\nRetrieve column names.\n\n\n\nEdgeTable.plot(**kwargs)\nPlot the edges of the model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\n**kwargs\nDict\nSupported: ‘ax’, ‘color_flow’, ‘color_control’\n{}\n\n\n\n\n\n\n\nEdgeTable.set_filepath(filepath)\nSet the filepath of this instance.\nArgs: filepath (Path): The filepath to set.\n\n\n\nEdgeTable.sort()\n\n\n\nEdgeTable.tablename()\nRetrieve tablename based on attached Schema.\nNodeSchema -&gt; Schema TabularRatingCurveStaticSchema -&gt; TabularRatingCurve / Static\n\n\n\nEdgeTable.tableschema()\nRetrieve Pandera Schema.\nThe type of the field df is known to always be an DataFrame[TableT]]] | None"
  },
  {
    "objectID": "reference/python/EdgeTable.html#attributes",
    "href": "reference/python/EdgeTable.html#attributes",
    "title": "1 EdgeTable",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndf\n\n\n\nfilepath\n\n\n\nmodel_config"
  },
  {
    "objectID": "reference/python/EdgeTable.html#methods",
    "href": "reference/python/EdgeTable.html#methods",
    "title": "1 EdgeTable",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd\nAdd an edge between nodes. The type of the edge (flow or control)\n\n\ncolumns\nRetrieve column names.\n\n\nplot\nPlot the edges of the model.\n\n\nset_filepath\nSet the filepath of this instance.\n\n\nsort\n\n\n\ntablename\nRetrieve tablename based on attached Schema.\n\n\ntableschema\nRetrieve Pandera Schema.\n\n\n\n\n\nEdgeTable.add(from_node, to_node, geometry=None, name='', subnetwork_id=None, edge_id=None, **kwargs)\nAdd an edge between nodes. The type of the edge (flow or control) is automatically inferred from the type of the from_node.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfrom_node\nNodeData\nA node indexed by its node ID, e.g. model.basin[1]\nrequired\n\n\nto_node\nNodeData\nA node indexed by its node ID, e.g. model.linear_resistance[1]\nrequired\n\n\ngeometry\nLineString | MultiLineString | None\nThe geometry of a line. If not supplied, it creates a straight line between the nodes.\nNone\n\n\nname\nstr\nAn optional name for the edge.\n''\n\n\nsubnetwork_id\nint | None\nAn optional subnetwork id for the edge. This edge indicates a source for the allocation algorithm, and should thus not be set for every edge in a subnetwork.\nNone\n\n\n**kwargs\nDict\n\n{}\n\n\n\n\n\n\n\nEdgeTable.columns()\nRetrieve column names.\n\n\n\nEdgeTable.plot(**kwargs)\nPlot the edges of the model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\n**kwargs\nDict\nSupported: ‘ax’, ‘color_flow’, ‘color_control’\n{}\n\n\n\n\n\n\n\nEdgeTable.set_filepath(filepath)\nSet the filepath of this instance.\nArgs: filepath (Path): The filepath to set.\n\n\n\nEdgeTable.sort()\n\n\n\nEdgeTable.tablename()\nRetrieve tablename based on attached Schema.\nNodeSchema -&gt; Schema TabularRatingCurveStaticSchema -&gt; TabularRatingCurve / Static\n\n\n\nEdgeTable.tableschema()\nRetrieve Pandera Schema.\nThe type of the field df is known to always be an DataFrame[TableT]]] | None"
  },
  {
    "objectID": "reference/usage.html",
    "href": "reference/usage.html",
    "title": "Usage",
    "section": "",
    "text": "Ribasim has a single configuration file, which is written in the TOML format. It contains settings, as well as paths to other input and output files. Ribasim expects the GeoPackage database database.gpkg as well as optional Arrow input files to be available in the input_dir.\n# start- and endtime of the simulation\n# can also be set to a date-time like 1979-05-27T07:32:00\nstarttime = 2019-01-01 # required\nendtime = 2021-01-01   # required\n\n# Coordinate Reference System\n# The accepted strings are documented here:\n# https://proj.org/en/9.4/development/reference/functions.html#c.proj_create\ncrs = \"EPSG:4326\"      # required\n\n# input files\ninput_dir = \".\"         # required\nresults_dir = \"results\" # required\n\nribasim_version = \"2024.11.0\" # required\n\n# Specific tables can also go into Arrow files rather than the database.\n# For large tables this can benefit from better compressed file sizes.\n# This is optional, tables are retrieved from the database if not specified in the TOML.\n[basin]\ntime = \"basin/time.arrow\"\n\n[allocation]\ntimestep = 86400                   # optional (required if use_allocation = true), default 86400\nuse_allocation = false             # optional, default false\n\n[solver]\nalgorithm = \"QNDF\"  # optional, default \"QNDF\"\nsaveat = 86400      # optional, default 86400, 0 saves every timestep, inf saves only at start- and endtime\ndt = 60.0           # optional, remove for adaptive time stepping\ndtmin = 0.0         # optional, default 0.0\ndtmax = 0.0         # optional, default length of simulation\nforce_dtmin = false # optional, default false\nabstol = 1e-7       # optional, default 1e-7\nreltol = 1e-7       # optional, default 1e-7\nwater_balance_abstol = 1e-3 # optional, default 1e-3\nwater_balance_reltol = 1e-2 # optional, default 1e-2\nmaxiters = 1e9      # optional, default 1e9\nsparse = true       # optional, default true\nautodiff = false    # optional, default false\n\n[logging]\n# defines the logging level of Ribasim\nverbosity = \"info\" # optional, default \"info\", can otherwise be \"debug\", \"warn\" or \"error\"\n\n[results]\n# These results files are always written\ncompression = true  # optional, default true, using zstd compression\ncompression_level = 6 # optional, default 6\n\n\nThe solver section in the configuration file is entirely optional, since we aim to use defaults that will generally work well. Common reasons to modify the solver settings are to adjust the calculation or result stepsizes: dt, and saveat. If your model does not converge, or your performance is lower than expected, it can help to adjust other solver settings as well.\nThe default solver algorithm = \"QNDF\", which is a multistep method similar to Matlab’s ode15s (Shampine and Reichelt 1997). It is an implicit method that supports the default adaptive timestepping. The full list of available solvers is: QNDF, FBDF, Rosenbrock23, Rodas4P, Rodas5P, TRBDF2, KenCarp4, Tsit5, RK4, ImplicitEuler, Euler. Information on the solver algorithms can be found on the ODE solvers page.\nBy default Ribasim uses adaptive timestepping, though not all algorithms support adaptive timestepping. To use fixed timesteps, provide a timestep size in seconds; dt = 3600.0 corresponds to an hourly timestep. With adaptive timestepping, dtmin and dtmax control the minimum and maximum allowed dt. If a smaller dt than dtmin is needed to meet the set error tolerances, the simulation stops, unless force_dtmin is set to true. force_dtmin is off by default to ensure an accurate solution.\nThe default result stepsize, saveat = 86400 will save results after every day that passed. The calculation and result stepsize need not be the same. If you wish to save every calculation step, set saveat = 0. If you wish to not save any intermediate steps, set saveat = inf.\nThe water balance error is a measure of the error in the consistency with which the core keeps track of the water resources per Basin, for more details see here. water_balance_abstol and water_balance_reltol give upper bounds on this error, above which an error is thrown. A too large error generally indicates an error in the code or floating point truncation errors.\nThe Jacobian matrix provides information about the local sensitivity of the model with respect to changes in the states. For implicit solvers it must be calculated often, which can be expensive to do. There are several methods to do this. By default Ribasim uses a Jacobian derived automatically using ForwardDiff.jl with memory management provided by PreallocationTools.jl. If this is not used by setting autodiff = false, the Jacobian is calculated with a finite difference method, which can be less accurate and more expensive.\nBy default the Jacobian matrix is a sparse matrix (sparse = true). Since each state typically only depends on a small number of other states, this is generally more efficient, especially for larger models. The sparsity structure is calculated from the network and provided as a Jacobian prototype to the solver. For small or highly connected models it could be faster to use a dense Jacobian matrix instead by setting sparse = false.\nThe total maximum number of iterations maxiters = 1e9, can normally stay as-is unless doing extremely long simulations.\nThe absolute and relative tolerance for adaptive timestepping can be set with abstol and reltol. For more information on these and other solver options, see the DifferentialEquations.jl docs.\n\n\n\nCurrently there are the following allocation settings: - use_allocation: A boolean which says whether allocation should be used or not; - timestep: a float value in seconds which dictates the update interval for allocations.\n\n\n\nThe following entries can be set in the configuration in the [results] section.\n\n\n\n\n\n\n\n\nentry\ntype\ndescription\n\n\n\n\ncompression\nBool\nWhether to apply compression or not.\n\n\ncompression_level\nInt\nZstandard compression level. Default is 6, higher compresses more.\n\n\nsubgrid\nBool\nCompute and output more detailed water levels.\n\n\n\n\n\n\nThe following can be set in the configuration in the [logging] section.\n\n\n\n\n\n\n\n\nentry\ntype\ndescription\n\n\n\n\nverbosity\nString\nVerbosity level: debug, info, warn, or error.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#sec-solver-settings",
    "href": "reference/usage.html#sec-solver-settings",
    "title": "Usage",
    "section": "",
    "text": "The solver section in the configuration file is entirely optional, since we aim to use defaults that will generally work well. Common reasons to modify the solver settings are to adjust the calculation or result stepsizes: dt, and saveat. If your model does not converge, or your performance is lower than expected, it can help to adjust other solver settings as well.\nThe default solver algorithm = \"QNDF\", which is a multistep method similar to Matlab’s ode15s (Shampine and Reichelt 1997). It is an implicit method that supports the default adaptive timestepping. The full list of available solvers is: QNDF, FBDF, Rosenbrock23, Rodas4P, Rodas5P, TRBDF2, KenCarp4, Tsit5, RK4, ImplicitEuler, Euler. Information on the solver algorithms can be found on the ODE solvers page.\nBy default Ribasim uses adaptive timestepping, though not all algorithms support adaptive timestepping. To use fixed timesteps, provide a timestep size in seconds; dt = 3600.0 corresponds to an hourly timestep. With adaptive timestepping, dtmin and dtmax control the minimum and maximum allowed dt. If a smaller dt than dtmin is needed to meet the set error tolerances, the simulation stops, unless force_dtmin is set to true. force_dtmin is off by default to ensure an accurate solution.\nThe default result stepsize, saveat = 86400 will save results after every day that passed. The calculation and result stepsize need not be the same. If you wish to save every calculation step, set saveat = 0. If you wish to not save any intermediate steps, set saveat = inf.\nThe water balance error is a measure of the error in the consistency with which the core keeps track of the water resources per Basin, for more details see here. water_balance_abstol and water_balance_reltol give upper bounds on this error, above which an error is thrown. A too large error generally indicates an error in the code or floating point truncation errors.\nThe Jacobian matrix provides information about the local sensitivity of the model with respect to changes in the states. For implicit solvers it must be calculated often, which can be expensive to do. There are several methods to do this. By default Ribasim uses a Jacobian derived automatically using ForwardDiff.jl with memory management provided by PreallocationTools.jl. If this is not used by setting autodiff = false, the Jacobian is calculated with a finite difference method, which can be less accurate and more expensive.\nBy default the Jacobian matrix is a sparse matrix (sparse = true). Since each state typically only depends on a small number of other states, this is generally more efficient, especially for larger models. The sparsity structure is calculated from the network and provided as a Jacobian prototype to the solver. For small or highly connected models it could be faster to use a dense Jacobian matrix instead by setting sparse = false.\nThe total maximum number of iterations maxiters = 1e9, can normally stay as-is unless doing extremely long simulations.\nThe absolute and relative tolerance for adaptive timestepping can be set with abstol and reltol. For more information on these and other solver options, see the DifferentialEquations.jl docs.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#allocation-settings",
    "href": "reference/usage.html#allocation-settings",
    "title": "Usage",
    "section": "",
    "text": "Currently there are the following allocation settings: - use_allocation: A boolean which says whether allocation should be used or not; - timestep: a float value in seconds which dictates the update interval for allocations.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#results-settings",
    "href": "reference/usage.html#results-settings",
    "title": "Usage",
    "section": "",
    "text": "The following entries can be set in the configuration in the [results] section.\n\n\n\n\n\n\n\n\nentry\ntype\ndescription\n\n\n\n\ncompression\nBool\nWhether to apply compression or not.\n\n\ncompression_level\nInt\nZstandard compression level. Default is 6, higher compresses more.\n\n\nsubgrid\nBool\nCompute and output more detailed water levels.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#logging-settings",
    "href": "reference/usage.html#logging-settings",
    "title": "Usage",
    "section": "",
    "text": "The following can be set in the configuration in the [logging] section.\n\n\n\n\n\n\n\n\nentry\ntype\ndescription\n\n\n\n\nverbosity\nString\nVerbosity level: debug, info, warn, or error.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#table-requirements",
    "href": "reference/usage.html#table-requirements",
    "title": "Usage",
    "section": "2.1 Table requirements",
    "text": "2.1 Table requirements\nBelow we give details per file, in which we describe the schema of the table using a syntax like this:\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\nstorage\nFloat64\n\\(m^3\\)\nnon-negative\n\n\n\nThis means that two columns are required, one named node_id, that contained elements of type Int32, and a column named storage that contains elements of type Float64. The order of the columns does not matter. In some cases there may be restrictions on the values. This is indicated under restriction.\nTables are also allowed to have rows for timestamps that are not part of the simulation, these will be ignored. That makes it easy to prepare data for a larger period, and test models on a shorted period.\nWhen preparing the model for simulation, input validation is performed in the Julia core. The validation rules are described in the validation section.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#custom-metadata",
    "href": "reference/usage.html#custom-metadata",
    "title": "Usage",
    "section": "2.2 Custom metadata",
    "text": "2.2 Custom metadata\nIt may be advantageous to add metadata to rows. For example, basin areas might have names and objects such as weirs might have specific identification codes. Additional columns can be freely added to tables. The column names should be prefixed with meta_. They will not be used in computations or validated by the Julia core.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#basin---basin.arrow",
    "href": "reference/usage.html#basin---basin.arrow",
    "title": "Usage",
    "section": "5.1 Basin - basin.arrow",
    "text": "5.1 Basin - basin.arrow\nThe Basin table contains:\n\nResults of the storage and level of each Basin, which are instantaneous values;\nResults of the fluxes on each Basin, which are mean values over the saveat intervals. In the time column the start of the period is indicated.\nThe initial condition is written to the file, but the final state is not. It will be placed in a separate output state file in the future.\nThe inflow_rate and outflow_rate are the sum of the flows from other nodes into and out of the Basin respectively. The actual flows determine in which term they are counted, not the edge direction.\nThe storage_rate is the net mean flow that is needed to achieve the storage change between timesteps.\nThe inflow_rate consists of the sum of all modelled flows into the basin: inflow_rate (horizontal flows into the basin, independent of edge direction) + precipitation + drainage.\nThe outflow_rate consists of the sum of all modelled flows out of the basin: outflow_rate (horizontal flows out of the basin, idependent of edge direction) + evaporation + infiltration.\nThe balance_error is the difference between the storage_rate on one side and the inflow_rate and outflow_rate on the other side: storage_rate - (inflow_rate - outflow_rate). It can be used to check if the numerical error when solving the water balance is sufficiently small.\nThe relative_error is the fraction of the balance_error over the mean of the total_inflow and total_outflow.\n\nFor a more in-depth explanation of the water balance error see here.\n\n\n\ncolumn\ntype\nunit\n\n\n\n\ntime\nDateTime\n-\n\n\nnode_id\nInt32\n-\n\n\nstorage\nFloat64\n\\(\\text{m}^3\\)\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\n\n\ninflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\noutflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\nstorage_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\nprecipitation\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\nevaporation\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\ndrainage\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\ninfiltration\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\nbalance_error\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\nrelative_error\nFloat64\n-\n\n\n\nThe table is sorted by time, and per time it is sorted by node_id.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#flow---flow.arrow",
    "href": "reference/usage.html#flow---flow.arrow",
    "title": "Usage",
    "section": "5.2 Flow - flow.arrow",
    "text": "5.2 Flow - flow.arrow\nThe flow table contains calculated mean flows over the saveat intervals for every flow edge in the model. In the time column the start of the period is indicated.\n\n\n\ncolumn\ntype\nunit\n\n\n\n\ntime\nDateTime\n-\n\n\nedge_id\nInt32\n-\n\n\nfrom_node_type\nString\n-\n\n\nfrom_node_id\nInt32\n-\n\n\nto_node_type\nString\n-\n\n\nto_node_id\nInt32\n-\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\n\nThe table is sorted by time, and per time the same edge_id order is used, though not sorted. The edge_id value is the same as the fid written to the Edge table, and can be used to directly look up the Edge geometry. Flows from the “from” to the “to” node have a positive sign, and if the flow is reversed it will be negative.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#sec-state",
    "href": "reference/usage.html#sec-state",
    "title": "Usage",
    "section": "5.3 State - basin_state.arrow",
    "text": "5.3 State - basin_state.arrow\nThe Basin state table contains the water levels in each Basin at the end of the simulation.\n\n\n\ncolumn\ntype\nunit\n\n\n\n\nnode_id\nInt32\n-\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\n\n\n\nTo use this result as the initial condition of another simulation, see the Basin / state table reference.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#discretecontrol---control.arrow",
    "href": "reference/usage.html#discretecontrol---control.arrow",
    "title": "Usage",
    "section": "5.4 DiscreteControl - control.arrow",
    "text": "5.4 DiscreteControl - control.arrow\nThe control table contains a record of each change of control state: when it happened, which control node was involved, to which control state it changed and based on which truth state.\n\n\n\ncolumn\ntype\n\n\n\n\ntime\nDateTime\n\n\ncontrol_node_id\nInt32\n\n\ntruth_state\nString\n\n\ncontrol_state\nString",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#allocation---allocation.arrow",
    "href": "reference/usage.html#allocation---allocation.arrow",
    "title": "Usage",
    "section": "5.5 Allocation - allocation.arrow",
    "text": "5.5 Allocation - allocation.arrow\nThe allocation table contains a record of allocation results: when it happened, for which node, in which allocation network, and what the demand, allocated flow and realized flow were. The realized values at the starting time of the simulation can be ignored.\n\n\n\ncolumn\ntype\n\n\n\n\ntime\nDateTime\n\n\nsubnetwork_id\nInt32\n\n\nnode_type\nString\n\n\nnode_id\nInt32\n\n\npriority\nInt32\n\n\ndemand\nFloat64\n\n\nallocated\nFloat64\n\n\nrealized\nFloat64\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe LevelDemand node allocations are listed as node type Basin. This is because one LevelDemand node can link to multiple Basins, and doesn’t receive flow by itself.\n\n\nFor Basins the values demand, allocated and realized are positive if the Basin level is below the minimum level given by a LevelDemand node. The values are negative if the Basin supplies due to a surplus of water.\n\n\n\n\n\n\nNote\n\n\n\nCurrently the stored demand and abstraction rate are those at the allocation timepoint (and the abstraction rate is based on the previous allocation optimization). In the future these will be an average over the previous allocation timestep.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#allocation-flow---allocation_flow.arrow",
    "href": "reference/usage.html#allocation-flow---allocation_flow.arrow",
    "title": "Usage",
    "section": "5.6 Allocation flow - allocation_flow.arrow",
    "text": "5.6 Allocation flow - allocation_flow.arrow\nThe allocation flow table contains results of the optimized allocation flow on every edge in the model that is part of a subnetwork, for each time an optimization problem is solved (see also here). If in the model a main network and subnetwork(s) are specified, there are 2 different types of optimization for the subnetwork: collecting its total demand per priority (for allocating flow from the main network to the subnetwork), and allocating flow within the subnetwork. The column collect_demands provides the distinction between these two optimization types.\n\n\n\ncolumn\ntype\n\n\n\n\ntime\nDateTime\n\n\nedge_id\nInt32\n\n\nfrom_node_type\nString\n\n\nfrom_node_id\nInt32\n\n\nto_node_type\nString\n\n\nto_node_id\nInt32\n\n\nsubnetwork_id\nInt32\n\n\npriority\nInt32\n\n\nflow_rate\nFloat64\n\n\ncollect_demands\nBool",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#subgrid-level---subgrid_level.arrow",
    "href": "reference/usage.html#subgrid-level---subgrid_level.arrow",
    "title": "Usage",
    "section": "5.7 Subgrid level - subgrid_level.arrow",
    "text": "5.7 Subgrid level - subgrid_level.arrow\nThis result file is only written if the model contains a Basin / subgrid table. See there for more information on the meaning of this output.\n\n\n\ncolumn\ntype\n\n\n\n\ntime\nDateTime\n\n\nsubgrid_id\nInt32\n\n\nsubgrid_level\nFloat64",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#solver-statistics---solver_stats.arrow",
    "href": "reference/usage.html#solver-statistics---solver_stats.arrow",
    "title": "Usage",
    "section": "5.8 Solver statistics - solver_stats.arrow",
    "text": "5.8 Solver statistics - solver_stats.arrow\nThis result file contains statistics about the solver, which can give an insight into how well the solver is performing over time. The data is solved by saveat (see configuration file). water_balance refers to the right-hand-side function of the system of differential equations solved by the Ribasim core.\n\n\n\ncolumn\ntype\n\n\n\n\ntime\nDateTime\n\n\nwater_balance_calls\nInt\n\n\nlinear_solves\nInt\n\n\naccepted_timesteps\nInt\n\n\nrejected_timesteps\nInt",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "install.html",
    "href": "install.html",
    "title": "Installation",
    "section": "",
    "text": "In this document, we describe how to install the different components of Ribasim. First the components and their relation are introduced, then installation instructions per component follow.",
    "crumbs": [
      "Overview",
      "Installation"
    ]
  },
  {
    "objectID": "install.html#install-ribasim-plugin",
    "href": "install.html#install-ribasim-plugin",
    "title": "Installation",
    "section": "4.1 Install Ribasim plugin",
    "text": "4.1 Install Ribasim plugin\nFirstly, download ribasim_qgis.zip:\n\nQGIS plugin: ribasim_qgis.zip.\n\nIn QGIS, go to Plugins menu &gt; Manage and Install Plugins…\n\n\n\n\n\nSelect “Install from ZIP”:\n\nBrowse to the ribasim_qgis.zip file containing the plugin that was downloaded earlier\nClick “Install Plugin”\n\n\n\n\n\n\nOpen the Ribasim plugin panel.",
    "crumbs": [
      "Overview",
      "Installation"
    ]
  },
  {
    "objectID": "install.html#install-imod-plugin",
    "href": "install.html#install-imod-plugin",
    "title": "Installation",
    "section": "4.2 Install iMOD plugin",
    "text": "4.2 Install iMOD plugin\nIn QGIS, navigate to “Plugins &gt; Manage and Install Plugins &gt; All”. In the search bar, type: “iMOD”. Select the iMOD plugin, and click “Install”.\nAt least version 0.5.2 of the iMOD plugin is required.\nThe Time Series widget from the iMOD plugin is used for visualizing Ribasim results, which is described in the results section. Documentation on the Time Series widget can be found in the iMOD documentation.",
    "crumbs": [
      "Overview",
      "Installation"
    ]
  },
  {
    "objectID": "concept/concept.html",
    "href": "concept/concept.html",
    "title": "Introduction",
    "section": "",
    "text": "Decision makers need to balance the supply and demand of water at the river basin scale, under increasing environmental pressure. Ribasim allows users to model basins under current and changing conditions to evaluate and design and management of the water system. It is available as free and open source software under the MIT license. Besides a model simulation core, Ribasim also includes tooling to assist in building models from basic datasets and visualize results. The model and its results provides insights to decision makers, enabling them to build consensus amongst water users and make informed decisions about how to manage water resources optimally.\nThe model concept of Ribasim is composed of multiple layers:\n\na physical layer representing water bodies and associated infrastructure as well as abstractions,\na rule-based control layer to manage the infrastructure, and\n(optionally) a priority-based allocation layer to take centralized decisions on user abstractions.\n(optionally) a coupling layer to exchange fluxes and heads with other kernels\n\nTypically hydrological processes on land will be represented in detail by other models which can be coupled (online) to Ribasim with the help of iMOD Coupler. Currently, an online coupling with MODFLOW 6 (groundwater) and with Metaswap + MODFLOW 6 (unsaturated zone + groundwater) is available. The corresponding documentation can be found within the iMOD Suite Documentation.\nThis version of Ribasim is the follow up of the legacy Fortran kernel of Ribasim (version 7) applied world wide, the Fortran kernel SIMRES applied in the Netherlands, and the surface water models Distribution Model and Mozart of the Dutch National Hydrological Instrument.",
    "crumbs": [
      "Concepts",
      "Introduction"
    ]
  },
  {
    "objectID": "concept/concept.html#sec-physical",
    "href": "concept/concept.html#sec-physical",
    "title": "Introduction",
    "section": "2.1 Physical layer",
    "text": "2.1 Physical layer\nTo represent the physical characteristics of the water system in an area, Ribasim allows you to divide the area into a network of connected representative elementary watersheds (Reggiani, Sivapalan, and Majid Hassanizadeh 1998). Within Ribasim, these elements are called basins, which are essentially buckets or reservoirs holding an aggregated volume of water bodies in an area. Basins are chained in a graph with connector nodes determining the exchange of water between the basins. These connector nodes can represent open water connections (e.g. bifurcations or resistance in a free flowing open water channel) or infrastructure elements such as pumps, gates or weirs. An overview of node types and associated data inputs is provided on the usage page, while the associated mathematical formations are described on the equations page.",
    "crumbs": [
      "Concepts",
      "Introduction"
    ]
  },
  {
    "objectID": "concept/concept.html#sec-control",
    "href": "concept/concept.html#sec-control",
    "title": "Introduction",
    "section": "2.2 Control layer",
    "text": "2.2 Control layer\nInfrastructure elements are often controlled by humans to implement a certain water management strategy. Ribasim allows the configuration of conditional rules to influence the exchange of water between basins, either by setting inflow or outflow, or by controlling a water level. Control rules evaluate one or multiple conditions to change a parameter setting of an infrastructure element when the conditional criteria are met. Conditions can be either calculated values within the network as well as boundary conditions or (todo) external observations, i.e. observation values external to the model. An overview of node types and associated data inputs is provided on the usage page, while the associated mathematical formations are described on the equations page.",
    "crumbs": [
      "Concepts",
      "Introduction"
    ]
  },
  {
    "objectID": "concept/concept.html#sec-allocation",
    "href": "concept/concept.html#sec-allocation",
    "title": "Introduction",
    "section": "2.3 Allocation layer",
    "text": "2.3 Allocation layer\nRibasim allows water users (water demands) to abstract water from the basins (i.e. from the physical layer) unless the water level drops below a minimum level. Under dry conditions, water managers may want to prioritize some abstractions over other abstractions. The Ribasim allocation layer can take care of this prioritization by reducing the abstraction rates of lower-priority demands to ensure that sufficient water remains available in the system for the higher-priority demands. The associated mathematical formulations are described on the allocation page. In case of large networks, a subdivision in a main network with subnetworks is recommended. For more details see the explanation of the simulation loop.\nThe layers and the main components and dataflows between the layers are shown in the next figure:\n\n\n\n\n\nflowchart TB\nphysical:::layer\nrbc:::layer\nallocation:::layer\nuser_demand\nbasin\nconnector[basin connector]\ncontrol[control rules]\ncondition\nalloc[global allocation]\n\nsubgraph physical[physical layer]\n    user_demand--&gt;|abstraction| basin\n    basin&lt;--&gt;|flow| connector\nend\n\nsubgraph rbc[rule based control layer]\n   condition --&gt; control\nend\n\nsubgraph allocation[allocation layer]\n    alloc\nend\n\nuser_demand--&gt;|request demand| alloc\nalloc--&gt;|assign allocation| user_demand\nbasin--&gt;|volume| alloc\nbasin --&gt; |volume or level| condition\nalloc --&gt; |optional flow update| control\ncontrol --&gt; |action| connector\n\n%% class definitions for C4 model\nclassDef layer fill:transparent,stroke-dasharray:5 5",
    "crumbs": [
      "Concepts",
      "Introduction"
    ]
  },
  {
    "objectID": "concept/numerics.html",
    "href": "concept/numerics.html",
    "title": "Numerical considerations",
    "section": "",
    "text": "We want to solve the following initial value problem: \\[\n\\begin{cases}\n    \\frac{\\text{d}\\mathbf{u}}{\\text{d}t} = \\mathbf{f}(\\mathbf{u},t) \\quad t_0 &lt; t &lt; t_\\text{end} \\\\\n    \\mathbf{u}(t_0) = \\mathbf{u}_0\n\\end{cases},\n\\tag{1}\\]\nwhere \\(\\mathbf{f}\\) denotes water_balance! and \\(\\mathbf{u_0} = \\mathbf{0}\\) the initial cumulative flows (and the PID integrals which also start out at \\(0\\)).\nIn general \\(\\mathbf{f}\\) is a non-linear function in \\(\\mathbf{u}\\). These non-linearities are introduced by e.g.:\nThe problem Equation 1 can be solved by various numerical time-integration methods. To do this the time interval \\([t_0,t_\\text{end}]\\) is discretized into a finite number of time points \\(t_0 &lt; t_1 &lt; \\ldots &lt; t_N = t_\\text{end}\\) for which approximate solutions \\(\\mathbf{w}_n \\approx \\mathbf{u}(t_n)\\) are computed. In general we do not assume a fixed timestep (the interval between successive points in time). Rather, the solver attempts to make as large a step as possible while keeping error tolerances within requirements. The solver settings section details the available configuration options.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Numerical considerations"
    ]
  },
  {
    "objectID": "concept/numerics.html#euler-forward",
    "href": "concept/numerics.html#euler-forward",
    "title": "Numerical considerations",
    "section": "1.1 Euler forward",
    "text": "1.1 Euler forward\nThe simplest numerical method is Euler forward: \\[\n\\mathbf{w}_{n+1} = \\mathbf{w}_n + (t_{n+1}-t_n)\\mathbf{f}(\\mathbf{w}_n, t_n).\n\\tag{2}\\]\nHere \\(\\mathbf{w}_{n+1}\\) is given as a simple explicit function of \\(\\mathbf{w}_n\\).",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Numerical considerations"
    ]
  },
  {
    "objectID": "concept/numerics.html#euler-backward",
    "href": "concept/numerics.html#euler-backward",
    "title": "Numerical considerations",
    "section": "1.2 Euler backward",
    "text": "1.2 Euler backward\nEuler backward is formulated as follows: \\[\n\\mathbf{w}_{n+1} = \\mathbf{w}_n + (t_{n+1}-t_n)\\mathbf{f}(\\mathbf{w}_{n+1},t_{n+1}).\n\\tag{3}\\]\nNote that this is an implicit equation for \\(\\mathbf{w}_{n+1}\\), which is non-linear because of the non-linearity of \\(\\mathbf{f}\\).\nGenerally one of the following iterative methods is used for finding solutions to non-linear equations like this:\n\nPicard iteration for fixed points. This method aims to approximate \\(\\mathbf{w}_{n+1}\\) as a fixed point of the function \\[\n\\mathbf{g}(\\mathbf{x}) = \\mathbf{w}_n + (t_{n+1}-t_n)\\mathbf{f}(\\mathbf{x},t_{n+1})\n\\] by iterating \\(\\mathbf{g}\\) on an initial guess of \\(\\mathbf{w}_{n+1}\\);\nNewton iterations: approximate \\(\\mathbf{w}_{n+1}\\) as a root of the function \\[\n\\mathbf{h}(\\mathbf{x}) = \\mathbf{w}_n + (t_{n+1}-t_n)\\mathbf{f}(\\mathbf{x},t_{n+1}) - \\mathbf{x},\n\\] by iteratively finding the root of its linearized form:\n\n\\[\\begin{align}\n\\mathbf{0} =& \\mathbf{h}(\\mathbf{w}_{n+1}^k) + \\mathbf{J}(\\mathbf{h})(\\mathbf{w}_{n+1}^k)(\\mathbf{w}_{n+1}^{k+1}-\\mathbf{w}_{n+1}^k) \\\\\n=& \\mathbf{w}_n + (t_{n+1}-t_n)\\mathbf{f}(\\mathbf{w}_{n+1}^k,t_{n+1}) - \\mathbf{w}_{n+1}^k \\\\ +&\\left[(t_{n+1}-t_n)\\mathbf{J}(\\mathbf{f})(\\mathbf{w}_{n+1}^k)-\\mathbf{I}\\right](\\mathbf{w}_{n+1}^{k+1}-\\mathbf{w}_{n+1}^k).\n\\end{align}\\] Note that this thus requires an evaluation of the Jacobian of \\(\\mathbf{f}\\) and solving a linear system per iteration.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Numerical considerations"
    ]
  },
  {
    "objectID": "concept/numerics.html#basin-profiles",
    "href": "concept/numerics.html#basin-profiles",
    "title": "Numerical considerations",
    "section": "4.1 Basin profiles",
    "text": "4.1 Basin profiles\nThe basin profiles affect \\(\\mathbf{f}\\) in many ways, anywhere where a basin level or area is required.\n\n\n\n\n\n\nNote\n\n\n\nThis section needs to be updated and extended after once this issue is resolved.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Numerical considerations"
    ]
  },
  {
    "objectID": "concept/numerics.html#qh-relations",
    "href": "concept/numerics.html#qh-relations",
    "title": "Numerical considerations",
    "section": "4.2 Q(h) relations",
    "text": "4.2 Q(h) relations\nTabulatedRatingCurve nodes contribute to \\(\\mathbf{f}\\) with terms of the following form:\n\\[\n    Q(h(u))\n\\]\nwhere the continuity of this term is given by the least continuous of \\(Q\\) and \\(h\\).",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Numerical considerations"
    ]
  },
  {
    "objectID": "concept/numerics.html#empty-basins",
    "href": "concept/numerics.html#empty-basins",
    "title": "Numerical considerations",
    "section": "4.3 Empty basins",
    "text": "4.3 Empty basins\nReduction factors are introduced at several points in the definition of \\(\\mathbf{f}\\) to smooth out otherwise discontinuous transitions (e.g. the flow rate of a pump going to zero when the source basin dries out). If flows are not too large with respect to basin storage, this will prevent basins from reaching 0. Rather, the basin gets a very small storage. The reduction factors help with performance, but are also an important tool to avoid getting negative storage in basins. Negative storage needs to be avoided since it is not a real solution, and would introduce water into the model that doesn’t exist. Another tool used to avoid negative storage is the isoutoutofdomain option, which Ribasim makes use of. This rejects timesteps that lead to negative storage, instead retrying with a smaller timestep.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Numerical considerations"
    ]
  },
  {
    "objectID": "concept/equations.html",
    "href": "concept/equations.html",
    "title": "Equations",
    "section": "",
    "text": "In this section we give a formal description of the problem that is solved by Ribasim. The problem is of the form \\[\n    \\frac{\\text{d}\\mathbf{u}}{\\text{d}t} = f(\\mathbf{u},p(t),t), \\quad t \\in [t_0, t_\\text{end}],\n\\]\nwhich is a system of coupled first order differential equations.\nThe model is given by a directed graph, consisting of a set of node IDs (vertices) \\(V\\) and edges \\(E\\), consisting of ordered pairs of node IDs. We denote the subset of the nodes given by the Basins \\(B \\subset V\\), and the subset of nodes that prescribe flow \\(N \\subset V\\).\nThe states \\(\\mathbf{u}\\) of the model are given by cumulative flows since the start of the simulation as prescribed by the nodes \\(N\\): \\[\n    u_n(t) = \\int_{t_0}^t q_n\\text{d}t' \\quad \\forall n \\in N,\n\\] as well as by the Basin forcings: \\[\n    u_b^\\text{forcing}(t) = \\int_{t_0}^t q_b^\\text{forcing}\\text{d}t' \\quad \\forall b \\in B.\n\\]\nBecause of this definition, the initial conditions of all states are simple: \\[\n    u_i(t_0) = 0 \\quad \\forall i.\n\\]\nFrom these cumulative flows, the storage in each Basin can be determined at each point in time: \\[\n    S_b(t) = S_i(0) + S^\\text{exact}(t) - u_b^\\text{forcing}(t) + \\sum_{n\\;|\\;(n,b)\\in E} u(t) - \\sum_{n\\;|\\;(b,n)\\in E} u(t),\n\\]\ni.e. the storage is given by:\n\nthe initial storage;\nplus the exactly integrated flows (more on that below);\nminus the cumulative outgoing forcings;\nplus the cumulative horizontal inflows;\nminus the cumulative horizontal outflows.\n\nFrom these storages in combination with the Basin profiles the Basin levels \\(h\\) are computed. The relationship between the profile and the storage is given by \\[\n    S_b = \\int_{h_0}^h A_b(\\ell)\\text{d}\\ell,\n\\]\nwhere \\(A_b\\) is the linear interpolation of the area as a function of the level. These levels are then inputs for determining the flows prescribed by the nodes \\(N\\). From this relation it also follows that\n\\[\n    \\frac{\\text{d}h}{\\text{d}t} = \\frac{1}{A_b},\n\\] and so areas of zero are not allowed in the Basin profiles.\n\n\nThere’s one other type of state, which is not a cumulative flow but a cumulative error. This is the error integral for PID control, further explained in PID equations.\n\n\n\nThe more states the problem has, the more time it takes to solve it. Therefore we want to minimize the number of states. Flows do not have to be states when they can be integrated over time exactly because they do not depend on the other states. This is true for FlowBoundary nodes, and Basin precipitation (which uses a fixed basin area) and drainage.\n\n\n\nThe Jacobian is an \\(N \\times N\\) matrix where \\(N\\) is the number of states in the simulation. It is computed as part of implicit time stepping methods. There are 2 different methods available for computing this matrix: finite difference or automatic differentiation. For more details on the computation of the Jacobian and how it is used in the solvers see numerical considerations.\nThe entries of the Jacobian \\(J\\) are given by \\[\n    J_{i,j} = \\frac{\\partial f_j}{\\partial u_i},\n\\] i.e. \\(J_{i,j}\\) quantifies how \\(f_j\\). the time derivative of state \\(j\\), changes with respect to changes in state \\(i\\). Most of these entries are \\(0\\), because flows in distant parts of the model do not depend on each other.\n\n\n\nThe water balance error quantifies how well the water volume in the model is conserved for each Basin over an output save period, i.e. whether no water erroneously appears or disappears. It looks at the storage rate \\[\n    \\text{storage rate} = \\frac{\\Delta S_b}{\\Delta t}\n\\]\nin a Basin over a time period \\(\\Delta t\\) and compares that to the total inflows and outflows of that Basin over that period. More precisely, we first compute the total inflow and outflow, where:\n\n\\(\\text{total inflow}\\): the precipitation, drainage and horizontal flows into the Basin;\n\\(\\text{total outflow}\\): the evaporation, infiltration and horizontal flows out of the Basin.\n\nWhether a flow is an inflow or an outflow depends on whether the flow contributes to or takes from the Basin storage, which means that this is independent of the edge direction. This is determined for each solver timestep individually.\nThen from this we compute the errors:\n\\[\n    \\begin{align}\n    \\text{balance error} =&& \\text{storage rate} - (\\text{total inflow} - \\text{total outflow}) \\\\\n    \\text{relative error}=&& \\frac{\\text{absolute error}}{0.5(\\text{total inflow} + \\text{total outflow})}\n    \\end{align}\n\\] Hence the reference used for computing the relative error is the average of the total inflow and total outflow of the Basin (which are both non-negative).\nThe default tolerances are \\(0.001 \\text{ m}^3\\) for the balance error and \\(0.01\\) for the relative error, which should not be exceeded for realistic models.\nIn extreme cases where the storage rate is many orders of magnitude smaller than the storage itself, these computations can have floating point truncation errors which can lead to large relative errors. This is however only when the storage is roughly $ ^{15}$ times bigger than the storage rate.\n\n\nSay we have the following model:\n\n\n\n\n\nand we want to calculate the water balance error for Basin 6. We have the following data:\n\nTime period length: \\(10.0 \\text{ s}\\)\nBasin storage start: \\(100.0 \\text{ m}^3\\)\nBasin storage end: \\(50.0 \\text{ m}^3\\)\nUserDemand #11 inflow average: \\(10.0 \\text{ m}^3/\\text{s}\\)\nUserDemand #11 outflow average: \\(5.0 \\text{ m}^3/\\text{s}\\)\nOutlet #7 flow average: \\(- 3.5 \\text{ m}^3/\\text{s}\\)\nOutlet #11 flow average: \\(4.0 \\text{ m}^3/\\text{s}\\)\n\nAnd so we get\n\\[\n\\begin{align}\n    \\text{storage rate} = && \\frac{50.0 - 100.0}{10.0} &= & -6.0 \\text{ m}^3/\\text{s} \\\\\n    \\text{total inflow} = && 5.0 + 3.5 &= & 8.5 \\text{ m}^3/\\text{s}\\\\\n    \\text{total outflow} = && 10.0 + 4.0 &= & 14.0 \\text{ m}^3/\\text{s}\\\\\n    \\text{balance error} = && -6.0 - (8.5 - 14.0) &= & -0.5 \\text{ m}^3/\\text{s}\\\\\n    \\text{relative error} = && \\frac{-0.5}{8.5 + 14.0} &\\approx & -0.022\n\\end{align}\n\\] Note that the balance error and relative error are negative, but we use their absolute value to compare to the respective tolerances.\n\n\n\n\nYou might wonder why in the above explanation the states are given by the cumulative flows and not by the Basin storages, which is arguably conceptually simpler. The reason is that we do not just want to model the storages in the Basins over time, but we also want accurate output of each individual flow, e.g. to model the spread of pollutants.\nWhen the states are given by the storages, generally the individual flows can not accurately be computed from that as a post processing step, because there are more flows than storages. Also, we can only compute flows at individual points in time explicitly, not over a whole interval. When the states are given by the cumulative flows however, the output of the problem solve gives these flows directly, and from those the storage over time can be computed accurately. Hence in short, the formulation above gives more information than a formulation with Basin storages as states.\n\n\n\nRibasim uses OrdinaryDiffEq.jl to provide a numerical solution to the water balance equations. Changes to forcings or parameters such as precipitation, but also the allocated water abstraction is managed through the use of callback functions (SciML Development Team 2022). In a coupled run, the exchanges with MODFLOW 6 are also managed via the use of a callback function. For more a more in-depth discussion of numerical computations see Numerical considerations.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Equations"
    ]
  },
  {
    "objectID": "concept/equations.html#the-pid-control-integral-state",
    "href": "concept/equations.html#the-pid-control-integral-state",
    "title": "Equations",
    "section": "",
    "text": "There’s one other type of state, which is not a cumulative flow but a cumulative error. This is the error integral for PID control, further explained in PID equations.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Equations"
    ]
  },
  {
    "objectID": "concept/equations.html#exactly-integrating-flows-to-minimize-the-number-of-states",
    "href": "concept/equations.html#exactly-integrating-flows-to-minimize-the-number-of-states",
    "title": "Equations",
    "section": "",
    "text": "The more states the problem has, the more time it takes to solve it. Therefore we want to minimize the number of states. Flows do not have to be states when they can be integrated over time exactly because they do not depend on the other states. This is true for FlowBoundary nodes, and Basin precipitation (which uses a fixed basin area) and drainage.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Equations"
    ]
  },
  {
    "objectID": "concept/equations.html#the-jacobian",
    "href": "concept/equations.html#the-jacobian",
    "title": "Equations",
    "section": "",
    "text": "The Jacobian is an \\(N \\times N\\) matrix where \\(N\\) is the number of states in the simulation. It is computed as part of implicit time stepping methods. There are 2 different methods available for computing this matrix: finite difference or automatic differentiation. For more details on the computation of the Jacobian and how it is used in the solvers see numerical considerations.\nThe entries of the Jacobian \\(J\\) are given by \\[\n    J_{i,j} = \\frac{\\partial f_j}{\\partial u_i},\n\\] i.e. \\(J_{i,j}\\) quantifies how \\(f_j\\). the time derivative of state \\(j\\), changes with respect to changes in state \\(i\\). Most of these entries are \\(0\\), because flows in distant parts of the model do not depend on each other.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Equations"
    ]
  },
  {
    "objectID": "concept/equations.html#the-water-balance-error",
    "href": "concept/equations.html#the-water-balance-error",
    "title": "Equations",
    "section": "",
    "text": "The water balance error quantifies how well the water volume in the model is conserved for each Basin over an output save period, i.e. whether no water erroneously appears or disappears. It looks at the storage rate \\[\n    \\text{storage rate} = \\frac{\\Delta S_b}{\\Delta t}\n\\]\nin a Basin over a time period \\(\\Delta t\\) and compares that to the total inflows and outflows of that Basin over that period. More precisely, we first compute the total inflow and outflow, where:\n\n\\(\\text{total inflow}\\): the precipitation, drainage and horizontal flows into the Basin;\n\\(\\text{total outflow}\\): the evaporation, infiltration and horizontal flows out of the Basin.\n\nWhether a flow is an inflow or an outflow depends on whether the flow contributes to or takes from the Basin storage, which means that this is independent of the edge direction. This is determined for each solver timestep individually.\nThen from this we compute the errors:\n\\[\n    \\begin{align}\n    \\text{balance error} =&& \\text{storage rate} - (\\text{total inflow} - \\text{total outflow}) \\\\\n    \\text{relative error}=&& \\frac{\\text{absolute error}}{0.5(\\text{total inflow} + \\text{total outflow})}\n    \\end{align}\n\\] Hence the reference used for computing the relative error is the average of the total inflow and total outflow of the Basin (which are both non-negative).\nThe default tolerances are \\(0.001 \\text{ m}^3\\) for the balance error and \\(0.01\\) for the relative error, which should not be exceeded for realistic models.\nIn extreme cases where the storage rate is many orders of magnitude smaller than the storage itself, these computations can have floating point truncation errors which can lead to large relative errors. This is however only when the storage is roughly $ ^{15}$ times bigger than the storage rate.\n\n\nSay we have the following model:\n\n\n\n\n\nand we want to calculate the water balance error for Basin 6. We have the following data:\n\nTime period length: \\(10.0 \\text{ s}\\)\nBasin storage start: \\(100.0 \\text{ m}^3\\)\nBasin storage end: \\(50.0 \\text{ m}^3\\)\nUserDemand #11 inflow average: \\(10.0 \\text{ m}^3/\\text{s}\\)\nUserDemand #11 outflow average: \\(5.0 \\text{ m}^3/\\text{s}\\)\nOutlet #7 flow average: \\(- 3.5 \\text{ m}^3/\\text{s}\\)\nOutlet #11 flow average: \\(4.0 \\text{ m}^3/\\text{s}\\)\n\nAnd so we get\n\\[\n\\begin{align}\n    \\text{storage rate} = && \\frac{50.0 - 100.0}{10.0} &= & -6.0 \\text{ m}^3/\\text{s} \\\\\n    \\text{total inflow} = && 5.0 + 3.5 &= & 8.5 \\text{ m}^3/\\text{s}\\\\\n    \\text{total outflow} = && 10.0 + 4.0 &= & 14.0 \\text{ m}^3/\\text{s}\\\\\n    \\text{balance error} = && -6.0 - (8.5 - 14.0) &= & -0.5 \\text{ m}^3/\\text{s}\\\\\n    \\text{relative error} = && \\frac{-0.5}{8.5 + 14.0} &\\approx & -0.022\n\\end{align}\n\\] Note that the balance error and relative error are negative, but we use their absolute value to compare to the respective tolerances.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Equations"
    ]
  },
  {
    "objectID": "concept/equations.html#why-this-formulation",
    "href": "concept/equations.html#why-this-formulation",
    "title": "Equations",
    "section": "",
    "text": "You might wonder why in the above explanation the states are given by the cumulative flows and not by the Basin storages, which is arguably conceptually simpler. The reason is that we do not just want to model the storages in the Basins over time, but we also want accurate output of each individual flow, e.g. to model the spread of pollutants.\nWhen the states are given by the storages, generally the individual flows can not accurately be computed from that as a post processing step, because there are more flows than storages. Also, we can only compute flows at individual points in time explicitly, not over a whole interval. When the states are given by the cumulative flows however, the output of the problem solve gives these flows directly, and from those the storage over time can be computed accurately. Hence in short, the formulation above gives more information than a formulation with Basin storages as states.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Equations"
    ]
  },
  {
    "objectID": "concept/equations.html#numerical-solution",
    "href": "concept/equations.html#numerical-solution",
    "title": "Equations",
    "section": "",
    "text": "Ribasim uses OrdinaryDiffEq.jl to provide a numerical solution to the water balance equations. Changes to forcings or parameters such as precipitation, but also the allocated water abstraction is managed through the use of callback functions (SciML Development Team 2022). In a coupled run, the exchanges with MODFLOW 6 are also managed via the use of a callback function. For more a more in-depth discussion of numerical computations see Numerical considerations.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Equations"
    ]
  },
  {
    "objectID": "guide/examples.html",
    "href": "guide/examples.html",
    "title": "Examples",
    "section": "",
    "text": "import shutil\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom ribasim import Allocation, Model, Node, Solver\nfrom ribasim.nodes import (\n    basin,\n    continuous_control,\n    discrete_control,\n    flow_boundary,\n    level_boundary,\n    level_demand,\n    linear_resistance,\n    manning_resistance,\n    outlet,\n    pid_control,\n    pump,\n    tabulated_rating_curve,\n    user_demand,\n)\nfrom shapely.geometry import Point\n\n\ndatadir = Path(\"data\")\nshutil.rmtree(datadir, ignore_errors=True)\n\n\nmodel = Model(starttime=\"2020-01-01\", endtime=\"2021-01-01\", crs=\"EPSG:4326\")\n\nSetup the basins:\n\ntime = pd.date_range(model.starttime, model.endtime)\nday_of_year = time.day_of_year.to_numpy()\nseconds_per_day = 24 * 60 * 60\nevaporation = (\n    (-1.0 * np.cos(day_of_year / 365.0 * 2 * np.pi) + 1.0) * 0.0025 / seconds_per_day\n)\nrng = np.random.default_rng(seed=0)\nprecipitation = (\n    rng.lognormal(mean=-1.0, sigma=1.7, size=time.size) * 0.001 / seconds_per_day\n)\n\n# Convert steady forcing to m/s\n# 2 mm/d precipitation, 1 mm/d evaporation\n\nbasin_data = [\n    basin.Profile(area=[0.01, 1000.0], level=[0.0, 1.0]),\n    basin.Time(\n        time=pd.date_range(model.starttime, model.endtime),\n        drainage=0.0,\n        potential_evaporation=evaporation,\n        infiltration=0.0,\n        precipitation=precipitation,\n    ),\n    basin.State(level=[1.4]),\n]\n\nbasin1 = model.basin.add(Node(1, Point(0.0, 0.0)), basin_data)\nbasin3 = model.basin.add(Node(3, Point(2.0, 0.0)), basin_data)\nbasin6 = model.basin.add(Node(6, Point(3.0, 2.0)), basin_data)\nbasin9 = model.basin.add(Node(9, Point(5.0, 0.0)), basin_data)\n\nSetup linear resistance:\n\nlinear_resistance10 = model.linear_resistance.add(\n    Node(10, Point(6.0, 0.0)),\n    [linear_resistance.Static(resistance=[5e3])],\n)\nlinear_resistance12 = model.linear_resistance.add(\n    Node(12, Point(2.0, 1.0)),\n    [linear_resistance.Static(resistance=[3600.0 * 24.0 / 100.0])],\n)\n\nSetup Manning resistance:\n\nmanning_resistance2 = model.manning_resistance.add(\n    Node(2, Point(1.0, 0.0)),\n    [\n        manning_resistance.Static(\n            length=[900], manning_n=[0.04], profile_width=[6.0], profile_slope=[3.0]\n        )\n    ],\n)\n\nSet up rating curve nodes:\n\nq = 10 / 86400  # 10 m³/day\ntabulated_rating_curve4 = model.tabulated_rating_curve.add(\n    Node(8, Point(3.0, -1.0)),\n    [\n        tabulated_rating_curve.Static(\n            level=[0.0, 1.0],\n            flow_rate=[0.0, 0.6 * q],\n        )\n    ],\n)\ntabulated_rating_curve5 = model.tabulated_rating_curve.add(\n    Node(5, Point(3.0, 1.0)),\n    [\n        tabulated_rating_curve.Static(\n            level=[0.0, 1.0],\n            flow_rate=[0.0, 0.3 * q],\n        )\n    ],\n)\ntabulated_rating_curve8 = model.tabulated_rating_curve.add(\n    Node(4, Point(4.0, 0.0)),\n    [\n        tabulated_rating_curve.Static(\n            level=[0.0, 1.0],\n            flow_rate=[0.0, 0.1 * q],\n        )\n    ],\n)\n\nSetup pump:\n\npump7 = model.pump.add(Node(7, Point(4.0, 1.0)), [pump.Static(flow_rate=[0.5 / 3600])])\n\nSetup level boundary:\n\nlevel_boundary11 = model.level_boundary.add(\n    Node(11, Point(2.0, 2.0)), [level_boundary.Static(level=[0.5])]\n)\nlevel_boundary17 = model.level_boundary.add(\n    Node(17, Point(6.0, 1.0)), [level_boundary.Static(level=[1.5])]\n)\n\nSetup flow boundary:\n\nflow_boundary15 = model.flow_boundary.add(\n    Node(15, Point(3.0, 3.0)), [flow_boundary.Static(flow_rate=[1e-4])]\n)\nflow_boundary16 = model.flow_boundary.add(\n    Node(16, Point(0.0, 1.0)), [flow_boundary.Static(flow_rate=[1e-4])]\n)\n\nSetup terminal:\n\nterminal14 = model.terminal.add(Node(14, Point(3.0, -2.0)))\n\nSetup the edges:\n\nmodel.edge.add(basin1, manning_resistance2)\nmodel.edge.add(manning_resistance2, basin3)\nmodel.edge.add(\n    basin3,\n    tabulated_rating_curve8,\n)\nmodel.edge.add(\n    basin3,\n    tabulated_rating_curve5,\n)\nmodel.edge.add(\n    basin3,\n    tabulated_rating_curve4,\n)\nmodel.edge.add(tabulated_rating_curve5, basin6)\nmodel.edge.add(tabulated_rating_curve8, basin9)\nmodel.edge.add(\n    tabulated_rating_curve4,\n    terminal14,\n)\nmodel.edge.add(basin6, pump7)\nmodel.edge.add(pump7, basin9)\nmodel.edge.add(basin9, linear_resistance10)\nmodel.edge.add(level_boundary11, linear_resistance12)\nmodel.edge.add(linear_resistance12, basin3)\nmodel.edge.add(flow_boundary15, basin6)\nmodel.edge.add(flow_boundary16, basin1)\nmodel.edge.add(linear_resistance10, level_boundary17)\n\nLet’s take a look at the model:\n\nmodel.plot()\n\n\n\n\n\n\n\n\nWrite the model to a TOML and GeoPackage:\n\ntoml_path = datadir / \"basic/ribasim.toml\"\nmodel.write(toml_path)\n\nPosixPath('data/basic/ribasim.toml')\n\n\n\n\nNow run the model. You can open a terminal and run it from there. For example, to run the basic model, input:\nribasim basic/ribasim.toml\nAfter running the model, read back the results:\n\ndf_basin = pd.read_feather(\n    datadir / \"basic/results/basin.arrow\", dtype_backend=\"pyarrow\"\n)\ndf_basin_wide = df_basin.pivot_table(\n    index=\"time\", columns=\"node_id\", values=[\"storage\", \"level\"]\n)\nax = df_basin_wide[\"level\"].plot()\nax.set_ylabel(\"level [m]\");\n\n\n\n\n\n\n\n\n\ndf_flow = pd.read_feather(datadir / \"basic/results/flow.arrow\", dtype_backend=\"pyarrow\")\ndf_flow[\"edge\"] = list(zip(df_flow.from_node_id, df_flow.to_node_id))\ndf_flow[\"flow_m3d\"] = df_flow.flow_rate * 86400\nax = df_flow.pivot_table(index=\"time\", columns=\"edge\", values=\"flow_m3d\").plot()\nax.legend(bbox_to_anchor=(1.3, 1), title=\"Edge\")\nax.set_ylabel(\"flow [m³day⁻¹]\");",
    "crumbs": [
      "How-to guides",
      "Examples"
    ]
  },
  {
    "objectID": "guide/examples.html#running-a-model",
    "href": "guide/examples.html#running-a-model",
    "title": "Examples",
    "section": "",
    "text": "Now run the model. You can open a terminal and run it from there. For example, to run the basic model, input:\nribasim basic/ribasim.toml\nAfter running the model, read back the results:\n\ndf_basin = pd.read_feather(\n    datadir / \"basic/results/basin.arrow\", dtype_backend=\"pyarrow\"\n)\ndf_basin_wide = df_basin.pivot_table(\n    index=\"time\", columns=\"node_id\", values=[\"storage\", \"level\"]\n)\nax = df_basin_wide[\"level\"].plot()\nax.set_ylabel(\"level [m]\");\n\n\n\n\n\n\n\n\n\ndf_flow = pd.read_feather(datadir / \"basic/results/flow.arrow\", dtype_backend=\"pyarrow\")\ndf_flow[\"edge\"] = list(zip(df_flow.from_node_id, df_flow.to_node_id))\ndf_flow[\"flow_m3d\"] = df_flow.flow_rate * 86400\nax = df_flow.pivot_table(index=\"time\", columns=\"edge\", values=\"flow_m3d\").plot()\nax.legend(bbox_to_anchor=(1.3, 1), title=\"Edge\")\nax.set_ylabel(\"flow [m³day⁻¹]\");",
    "crumbs": [
      "How-to guides",
      "Examples"
    ]
  },
  {
    "objectID": "guide/qgis.html",
    "href": "guide/qgis.html",
    "title": "QGIS plugin",
    "section": "",
    "text": "This guide assumes you have already installed the Ribasim core, test models and QGIS plugin as described in the install page. Open an existing model or create a new model. As an example of an existing model, you can use the “basic” model from generated_testmodels.zip.\n\n\n\n\n\nCheck if your coordinate reference system (CRS) is set correctly.\n\n\n\n\n\nIf you are working with an unknown CRS, right click the model database group in Layers, and click “Set Group CRS…”.\n\n\n\n\n\nIf you are modeling the Netherlands, select “Amersfoort / RD New” (EPSG:28992).\n\n\n\n\n\n\n\n\n\nSelect the Node layer.\n\n\n\n\n\nTurn on the edit mode to be able to add nodes on the map.\n\n\n\n\n\nAdd nodes to the map with a left click and select the node type.\n\nTurn the edit mode off and save the edits to the Nodes layer.\n\n\n\n\n\n\n\n\nRight click a layer and select “Open Attribute Table”.\n\n\n\n\n\nClick the yellow pencil icon on the top left to enable editing, and copy and paste a record. A record can be selected by clicking on the row number.\n\n\n\n\n\nAdjust the content. Note that the node_id field is connected to the Node layer and thus must be set to an existing node_id. If you prefer, it also works to copy data with the same columns from Excel. Turn off edit mode and save changes to the layer.\n\n\n\n\n\n\n\n\n\n\n\nMake sure the Snapping Toolbar is visible, by going to the View &gt; Toolbars menu. Turn on snapping mode by clicking the magnet and set the snapping distance to 25 pixels. The keyboard shortcut for snapping is s (once the toolbar is enabled).\n\n\n\n\n\n\n\n\nSelect the Edge layer and turn on the edit mode.\n\n\n\n\n\nSelect “Add line feature”.\n\n\n\n\n\nCreate a connection by left clicking a source node and right clicking the destination node.\n\nA form where one can change the edge attributes will pop up. Once done with editing, click ok.\n\nNow leave the edit mode and save the results to the layer. Your model is now ready to run. See",
    "crumbs": [
      "How-to guides",
      "QGIS plugin"
    ]
  },
  {
    "objectID": "guide/qgis.html#editing-nodes",
    "href": "guide/qgis.html#editing-nodes",
    "title": "QGIS plugin",
    "section": "",
    "text": "Select the Node layer.\n\n\n\n\n\nTurn on the edit mode to be able to add nodes on the map.\n\n\n\n\n\nAdd nodes to the map with a left click and select the node type.\n\nTurn the edit mode off and save the edits to the Nodes layer.\n\n\n\n\n\n\n\n\nRight click a layer and select “Open Attribute Table”.\n\n\n\n\n\nClick the yellow pencil icon on the top left to enable editing, and copy and paste a record. A record can be selected by clicking on the row number.\n\n\n\n\n\nAdjust the content. Note that the node_id field is connected to the Node layer and thus must be set to an existing node_id. If you prefer, it also works to copy data with the same columns from Excel. Turn off edit mode and save changes to the layer.",
    "crumbs": [
      "How-to guides",
      "QGIS plugin"
    ]
  },
  {
    "objectID": "guide/qgis.html#connect-nodes",
    "href": "guide/qgis.html#connect-nodes",
    "title": "QGIS plugin",
    "section": "",
    "text": "Make sure the Snapping Toolbar is visible, by going to the View &gt; Toolbars menu. Turn on snapping mode by clicking the magnet and set the snapping distance to 25 pixels. The keyboard shortcut for snapping is s (once the toolbar is enabled).\n\n\n\n\n\n\n\n\nSelect the Edge layer and turn on the edit mode.\n\n\n\n\n\nSelect “Add line feature”.\n\n\n\n\n\nCreate a connection by left clicking a source node and right clicking the destination node.\n\nA form where one can change the edge attributes will pop up. Once done with editing, click ok.\n\nNow leave the edit mode and save the results to the layer. Your model is now ready to run. See",
    "crumbs": [
      "How-to guides",
      "QGIS plugin"
    ]
  },
  {
    "objectID": "tutorial/reservoir.html",
    "href": "tutorial/reservoir.html",
    "title": "Reservoir",
    "section": "",
    "text": "from pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport plotly.express as px\nfrom ribasim import Model, Node\nfrom ribasim.nodes import (\n    basin,\n    flow_boundary,\n    tabulated_rating_curve,\n    user_demand,\n)\nfrom shapely.geometry import Point\nbase_dir = Path(\"crystal-basin\")\n\nstarttime = \"2022-01-01\"\nendtime = \"2023-01-01\"\nmodel = Model(\n    starttime=starttime,\n    endtime=endtime,\n    crs=\"EPSG:4326\",\n)\nThese nodes are identical to the previous tutorial:\n# FlowBoundary\ndata = pd.DataFrame({\n    \"time\": pd.date_range(start=\"2022-01-01\", end=\"2023-01-01\", freq=\"MS\"),\n    \"main\": [74.7, 57.9, 63.2, 183.9, 91.8, 47.5, 32.6, 27.6, 26.5, 25.1, 39.3, 37.8, 57.9],\n    \"minor\": [16.3, 3.8, 3.0, 37.6, 18.2, 11.1, 12.9, 12.2, 11.2, 10.8, 15.1, 14.3, 11.8]\n})  # fmt: skip\ndata[\"total\"] = data[\"minor\"] + data[\"main\"]\nmain = model.flow_boundary.add(\n    Node(1, Point(0.0, 0.0), name=\"main\"),\n    [\n        flow_boundary.Time(\n            time=data.time,\n            flow_rate=data.main,\n        )\n    ],\n)\nminor = model.flow_boundary.add(\n    Node(2, Point(-3.0, 0.0), name=\"minor\"),\n    [\n        flow_boundary.Time(\n            time=data.time,\n            flow_rate=data.minor,\n        )\n    ],\n)\n\n# Basin\nconfluence = model.basin.add(\n    Node(3, Point(-1.5, -1), name=\"confluence\"),\n    [\n        basin.Profile(area=[672000, 5600000], level=[0, 6]),\n        basin.State(level=[4]),\n        basin.Time(time=[starttime, endtime]),\n    ],\n)\n\n# TabulatedRatingCurve\nweir = model.tabulated_rating_curve.add(\n    Node(4, Point(-1.5, -1.5), name=\"weir\"),\n    [\n        tabulated_rating_curve.Static(\n            level=[0.0, 2, 5],\n            flow_rate=[0.0, 50, 200],\n        )\n    ],\n)\ndiversion_weir = model.tabulated_rating_curve.add(\n    Node(8, Point(-1.125, -0.75), name=\"diversion_weir\"),\n    [\n        tabulated_rating_curve.Static(\n            level=[0.0, 1.5, 5],\n            flow_rate=[0.0, 45, 200],\n        )\n    ],\n)\n\n# UserDemand\nirrigation = model.user_demand.add(\n    Node(7, Point(-1.5, 0.5), name=\"irrigation\"),\n    [\n        user_demand.Time(\n            demand=[0.0, 0.0, 10, 12, 12, 0.0],\n            return_factor=0,\n            min_level=0,\n            priority=1,\n            time=[\n                starttime,\n                \"2022-03-31\",\n                \"2022-04-01\",\n                \"2022-07-01\",\n                \"2022-09-30\",\n                \"2022-10-01\",\n            ],\n        )\n    ],\n)\n\n# Terminal\nsea = model.terminal.add(Node(5, Point(-1.5, -3.0), name=\"sea\"))\nDue to the increase of population and climate change Crystal city has implemented a reservoir upstream to store water for domestic use (See Figure 1). The reservoir is to help ensure a reliable supply during dry periods. In this module, the user will update the model to incorporate the reservoir’s impact on the whole Crystal basin.",
    "crumbs": [
      "Tutorials",
      "Reservoir"
    ]
  },
  {
    "objectID": "tutorial/reservoir.html#reservoir",
    "href": "tutorial/reservoir.html#reservoir",
    "title": "Reservoir",
    "section": "1 Reservoir",
    "text": "1 Reservoir\n\n1.1 Add a Basin\nThe diversion_basin from the previous tutorial is not used, but replaced by a larger reservoir Basin. Its water will play an important role for the users (the city and the irrigation district). The reservoir has a maximum area of \\(32.3 \\text{ km}^2\\) and a maximum depth of \\(7 \\text{ m}\\).\n\nreservoir = model.basin.add(\n    Node(6, Point(-0.75, -0.5), name=\"reservoir\"),\n    [\n        basin.Profile(area=[20000000, 32300000], level=[0, 7]),\n        basin.State(level=[3.5]),\n        basin.Time(time=[starttime, endtime]),\n    ],\n)\n\n\n\n1.2 Add a demand node\n\\(50.000\\) people live in Crystal City. To represents the total flow rate or abstraction rate required to meet the water demand of \\(50.000\\) people, another demand node needs to be added assuming a return flow of \\(60%\\).\n\ncity = model.user_demand.add(\n    Node(9, Point(0, -1), name=\"city\"),\n    [\n        user_demand.Time(\n            # Total demand in m³/s\n            demand=[0.07, 0.08, 0.09, 0.10, 0.12, 0.14, 0.15, 0.14, 0.12, 0.10, 0.09, 0.08],\n            return_factor=0.6,\n            min_level=0,\n            priority=1,\n            time=pd.date_range(start=\"2022-01-01\", periods=12, freq=\"MS\"),\n        )\n    ],\n)  # fmt: skip\n\n\nmodel.edge.add(main, reservoir, name=\"main\")\nmodel.edge.add(minor, confluence, name=\"minor\")\nmodel.edge.add(reservoir, irrigation, name=\"irrigation\")\nmodel.edge.add(irrigation, confluence)\nmodel.edge.add(reservoir, city, name=\"city\")\nmodel.edge.add(city, confluence, name=\"city returnflow\")\nmodel.edge.add(reservoir, diversion_weir, name=\"not diverted\")\nmodel.edge.add(diversion_weir, confluence)\nmodel.edge.add(confluence, weir)\nmodel.edge.add(weir, sea, name=\"sea\")\n\n\nmodel.plot();\n\n\n\n\n\n\n\n\n\ntoml_path = base_dir / \"Crystal-3/ribasim.toml\"\nmodel.write(toml_path)\ncli_path = \"ribasim\"\n\n\n\n1.3 Adjust the code\nAdjust the naming of the Basin in the dictionary mapping and the saving file should be Crystal-3.",
    "crumbs": [
      "Tutorials",
      "Reservoir"
    ]
  },
  {
    "objectID": "tutorial/reservoir.html#plot-reservoir-storage-and-level",
    "href": "tutorial/reservoir.html#plot-reservoir-storage-and-level",
    "title": "Reservoir",
    "section": "2 Plot reservoir storage and level",
    "text": "2 Plot reservoir storage and level\n\ndf_basin = pd.read_feather(\n    base_dir / \"Crystal-3/results/basin.arrow\", dtype_backend=\"pyarrow\"\n)\n\n# Create pivot tables and plot for Basin data\ndf_basin_wide = df_basin.pivot_table(\n    index=\"time\", columns=\"node_id\", values=[\"storage\", \"level\"]\n)\ndf_basin_wide = df_basin_wide.loc[:, pd.IndexSlice[:, reservoir.node_id]]\n\n# Plot level and storage on the same graph with dual y-axes\nfig, ax1 = plt.subplots(figsize=(12, 6))\n\n# Plot level on the primary y-axis\ncolor = \"b\"\nax1.set_xlabel(\"Time\")\nax1.set_ylabel(\"Level [m]\", color=color)\nax1.plot(df_basin_wide.index, df_basin_wide[\"level\"], color=color)\nax1.tick_params(axis=\"y\", labelcolor=color)\n\n# Create a secondary y-axis for storage\nax2 = ax1.twinx()\ncolor = \"r\"\nax2.set_ylabel(\"Storage [m³]\", color=\"r\")\nax2.plot(df_basin_wide.index, df_basin_wide[\"storage\"], linestyle=\"--\", color=color)\nax2.tick_params(axis=\"y\", labelcolor=color)\n\nfig.tight_layout()  # Adjust layout to fit labels\nplt.title(\"Basin level and storage\")\nplt.show()\n\n\n\n\n\n\n\n\nThe figure above illustrates the storage and water level at the reservoir. As expected, after increasing the profile of the Basin, its storage capacity increased as well.",
    "crumbs": [
      "Tutorials",
      "Reservoir"
    ]
  },
  {
    "objectID": "tutorial/reservoir.html#plot-flows",
    "href": "tutorial/reservoir.html#plot-flows",
    "title": "Reservoir",
    "section": "3 Plot flows",
    "text": "3 Plot flows\n\ndf_flow = pd.read_feather(\n    base_dir / \"Crystal-3/results/flow.arrow\", dtype_backend=\"pyarrow\"\n)\n# Add the edge names and then remove unnamed edges\ndf_flow[\"name\"] = model.edge.df[\"name\"].loc[df_flow[\"edge_id\"]].to_numpy()\ndf_flow = df_flow[df_flow[\"name\"].astype(bool)]\n\n# Plot the flow data, interactive plot with Plotly\npivot_flow = df_flow.pivot_table(\n    index=\"time\", columns=\"name\", values=\"flow_rate\"\n).reset_index()\nfig = px.line(pivot_flow, x=\"time\", y=pivot_flow.columns[1:], title=\"Flow [m3/s]\")\n\nfig.update_layout(legend_title_text=\"Edge\")\nfig.show()",
    "crumbs": [
      "Tutorials",
      "Reservoir"
    ]
  },
  {
    "objectID": "tutorial/natural-flow.html",
    "href": "tutorial/natural-flow.html",
    "title": "Getting started",
    "section": "",
    "text": "Welcome to Ribasim! This tutorial will help you get started with the basics of using Ribasim for river basin simulation. In this tutorial, the schematization of models is done in Python using the Ribasim Python package. The Ribasim Python package (named ribasim) simplifies the process of building, updating, and analyzing Ribasim model programmatically. It also allows for the creation of entire models from base data, ensuring that your model setup is fully reproducible.\n\n\nIn this tutorial, we will focus on a fictional river basin called Crystal, which will serve as our case study. The guide is divided into different modules, each covering various scenarios. These include simulating natural flow, implementing reservoirs, and observing the impact of other structures. While not all node types and possibilities will be demonstrated, the focus will be on the most commonly used and significant situations. By the end of the tutorial, users will be able to:\n\nSet up a basic Ribasim model: Understand how to create a new model for a river basin using the Ribasim Python package.\nEvaluate the impact of demands: Introduce water demand (such as irrigation) and assess their effects on the river basin.\nModify and update models: Learn how to update existing models with new data and changes.\nAnalyze simulation results: Use built-in tools to analyze and interpret the results of your simulations.\n\n\n\n\nFirst install the latest release of Ribasim as documented in the installation guide.\nDownload the Crystal_Basin.zip file from the website. Extract Crystal_Basin.zip and place it in the same directory as your Ribasim installation. This folder includes:\n\nQuickStartGuide.pdf\ndata: Contains data inputs such as time series needed for running the case. Additionally, your Python model (.py) and the results will also be saved in this folder.",
    "crumbs": [
      "Tutorials",
      "Getting started"
    ]
  },
  {
    "objectID": "tutorial/natural-flow.html#learning-objectives",
    "href": "tutorial/natural-flow.html#learning-objectives",
    "title": "Getting started",
    "section": "",
    "text": "In this tutorial, we will focus on a fictional river basin called Crystal, which will serve as our case study. The guide is divided into different modules, each covering various scenarios. These include simulating natural flow, implementing reservoirs, and observing the impact of other structures. While not all node types and possibilities will be demonstrated, the focus will be on the most commonly used and significant situations. By the end of the tutorial, users will be able to:\n\nSet up a basic Ribasim model: Understand how to create a new model for a river basin using the Ribasim Python package.\nEvaluate the impact of demands: Introduce water demand (such as irrigation) and assess their effects on the river basin.\nModify and update models: Learn how to update existing models with new data and changes.\nAnalyze simulation results: Use built-in tools to analyze and interpret the results of your simulations.",
    "crumbs": [
      "Tutorials",
      "Getting started"
    ]
  },
  {
    "objectID": "tutorial/natural-flow.html#prerequisites",
    "href": "tutorial/natural-flow.html#prerequisites",
    "title": "Getting started",
    "section": "",
    "text": "First install the latest release of Ribasim as documented in the installation guide.\nDownload the Crystal_Basin.zip file from the website. Extract Crystal_Basin.zip and place it in the same directory as your Ribasim installation. This folder includes:\n\nQuickStartGuide.pdf\ndata: Contains data inputs such as time series needed for running the case. Additionally, your Python model (.py) and the results will also be saved in this folder.",
    "crumbs": [
      "Tutorials",
      "Getting started"
    ]
  },
  {
    "objectID": "tutorial/natural-flow.html#natural-flow",
    "href": "tutorial/natural-flow.html#natural-flow",
    "title": "Getting started",
    "section": "2.1 Natural flow",
    "text": "2.1 Natural flow\n\n2.1.1 Import packages\nBefore building the model we need to import some modules. Open your favorite Python editor (Visual Studio Code, Jupyter, …) and create a new script or notebook and name it Crystal_1.1 and save it into your model folder Crystal_Basin. Import the following modules in Python:\n\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom ribasim import Model, Node\nfrom ribasim.nodes import basin, flow_boundary, tabulated_rating_curve\nfrom shapely.geometry import Point\n\n\n\n2.1.2 Setup paths and model configuration\nReference the paths of the Ribasim installation and model directory and define the time period (2022-01-01 until 2023-01-01) for the model simulation. The coordinate reference system (CRS) is also required, and set to EPSG:4326, which means all coordinates are interpreted as latitude and longitude values. The CRS is important for correctly placing Ribasim models on the map, but since this is a fictional model, it is not important.\n\nbase_dir = Path(\"crystal-basin\")\n\nstarttime = \"2022-01-01\"\nendtime = \"2023-01-01\"\nmodel = Model(\n    starttime=starttime,\n    endtime=endtime,\n    crs=\"EPSG:4326\",\n)\n\n\n\n2.1.3 FlowBoundary nodes\nThe Crystal basin consists of two inflow points, the tributary and the main Crystal river, we will call them Minor and Main respectively. This is a monthly inflow timeseries from 2014 to 2023. The used simulation period is defined by the starttime and endtime of the model, not by the input timeseries.\n\ndata = pd.DataFrame({\n    \"time\": pd.date_range(start=\"2022-01-01\", end=\"2023-01-01\", freq=\"MS\"),\n    \"main\": [74.7, 57.9, 63.2, 183.9, 91.8, 47.5, 32.6, 27.6, 26.5, 25.1, 39.3, 37.8, 57.9],\n    \"minor\": [16.3, 3.8, 3.0, 37.6, 18.2, 11.1, 12.9, 12.2, 11.2, 10.8, 15.1, 14.3, 11.8]\n})  # fmt: skip\ndata[\"total\"] = data[\"minor\"] + data[\"main\"]\ndisplay(data)\n\n# Average and max inflow of the total inflow data timeseries\n# From 2014 - 2023\nprint(\"Average inflow [m3/s]:\", data[\"total\"].mean())\nprint(\"Maximum inflow [m3/s]:\", data[\"total\"].max())\n\nmain = model.flow_boundary.add(\n    Node(1, Point(0.0, 0.0), name=\"main\"),\n    [\n        flow_boundary.Time(\n            time=data.time,\n            flow_rate=data.main,\n        )\n    ],\n)\n\nminor = model.flow_boundary.add(\n    Node(2, Point(-3.0, 0.0), name=\"minor\"),\n    [\n        flow_boundary.Time(\n            time=data.time,\n            flow_rate=data.minor,\n        )\n    ],\n)\n\n\n\n\n\n\n\n\ntime\nmain\nminor\ntotal\n\n\n\n\n0\n2022-01-01\n74.7\n16.3\n91.0\n\n\n1\n2022-02-01\n57.9\n3.8\n61.7\n\n\n2\n2022-03-01\n63.2\n3.0\n66.2\n\n\n3\n2022-04-01\n183.9\n37.6\n221.5\n\n\n4\n2022-05-01\n91.8\n18.2\n110.0\n\n\n5\n2022-06-01\n47.5\n11.1\n58.6\n\n\n6\n2022-07-01\n32.6\n12.9\n45.5\n\n\n7\n2022-08-01\n27.6\n12.2\n39.8\n\n\n8\n2022-09-01\n26.5\n11.2\n37.7\n\n\n9\n2022-10-01\n25.1\n10.8\n35.9\n\n\n10\n2022-11-01\n39.3\n15.1\n54.4\n\n\n11\n2022-12-01\n37.8\n14.3\n52.1\n\n\n12\n2023-01-01\n57.9\n11.8\n69.7\n\n\n\n\n\n\n\nAverage inflow [m3/s]: 72.62307692307692\nMaximum inflow [m3/s]: 221.5\n\n\n\n\n2.1.4 Basin node (confluence)\nTo schematize the confluence from the tributary we will use the Basin node. The node by itself portrays as water storage with a certain volume of water and can be used for different purposes, such as a reservoir, river reach, lake or in this case a confluence. Figure 2 visualizes a cross section of the confluence point in our model.\n\n\n\n\n\n\nFigure 2: Basin node concept for the confluence\n\n\n\nTable 1 shows the input data for the Basin node profile.\n\n\n\nTable 1: Profile data for the basin node\n\n\n\n\n\nArea [\\(\\text{m}^2\\)]\nLevel [\\(\\text{m}\\)]\n\n\n\n\n\\(672000.0\\)\n\\(0.0\\)\n\n\n\\(5600000.0\\)\n\\(6.0\\)\n\n\n\n\n\n\nWhilst in this case the level starts at \\(0.0\\) and therefore happens to be the same as the depth, it should never be interpreted as a depth. All water levels in Ribasim are assumed to be with respect to a shared reference datum, like mean sea level (MSL). The first water level in the profile is the height of the Basin bottom above this reference datum.\nTo specify the Basin profile, the following code is used:\n\nconfluence = model.basin.add(\n    Node(3, Point(-1.5, -1), name=\"confluence\"),\n    [\n        basin.Profile(area=[672000, 5600000], level=[0, 6]),\n        basin.State(level=[4]),\n        basin.Time(time=[starttime, endtime]),\n    ],\n)\n\n\n\n2.1.5 TabulatedRatingCurve\nIn the previous step we implemented a Basin node that functions as a confluence. Conceptually, the Basin acts as a store of water, accumulating inflows and then releasing them. A Basin cannot directly connect to another Basin, because the rules for water exchange between them need to be defined. Connector nodes take care of this. The first such node we introduce is the TabulatedRatingCurve. It defines a relation between the water level (\\(h\\)) in the Basin and the outflow (\\(Q\\)) from the Basin. This setup mimics the behavior of a gate or spillway, allowing us to model how varying water levels influence flow rates at the confluence.\nAs the two inflows come together at the confluence, we expect, as mentioned above, a discharge average of \\(44.45 \\text{ m}^3/\\text{s}\\). It is therefore expected that the confluence Basin goes towards a level where the outflow is equal to the inflow via the rating curve. Only then is the confluence Basin in equilibrium. The maximum depth of the river is \\(6 \\text{ m}\\), and the maximum inflow is \\(221.5 \\text{ m}^3/\\text{s}\\) The \\(Q(h)\\) relationship in Table 2 allows such inflows with reasonable water levels.\n\n\n\nTable 2: Input data for the Tabulated Rating Curve\n\n\n\n\n\n\n\n\n\nWater Level (\\(h\\)) [\\(\\text{m}\\)]\nOutflow (\\(Q\\)) [\\(\\text{m}^3/\\text{s}\\)]\n\n\n\n\n\\(0.0\\)\n\\(0.0\\)\n\n\n\\(2.0\\)\n\\(50.0\\)\n\n\n\\(5.0\\)\n\\(200.0\\)\n\n\n\n\n\n\nIn Ribasim, the \\(Q(h)\\) relation is a piecewise linear function, so the points in between will be linearly interpolated. Figure 3 illustrates the visual process and shows a progressive increase in discharge with rising water levels. In this case this means:\n\nAt level \\(0.0\\): No discharge occurs. This represents a condition where the water level is too low for any flow to be discharged.\nAt level \\(2.0\\): Discharge is \\(50.0 \\text{ m}^3/\\text{s}\\). This is a bit above the average discharge rate, corresponding to the water level where normal flow conditions are established.\nAt level \\(5.0\\): Discharge rate reaches \\(200.0 \\text{ m}^3/\\text{s}\\). This discharge rate occurs at the water level during wet periods, indicating higher flow capacity.\n\n\n\n\n\n\n\nFigure 3: Discharge at corresponding water levels\n\n\n\nTaking this into account, add the TabulatedRatingCurve as follows:\n\nweir = model.tabulated_rating_curve.add(\n    Node(4, Point(-1.5, -1.5), name=\"weir\"),\n    [\n        tabulated_rating_curve.Static(\n            level=[0.0, 2, 5],\n            flow_rate=[0.0, 50, 200],\n        )\n    ],\n)\n\n\n\n2.1.6 Terminal node\nFinally all the water will discharge into the sea. We schematize this with the Terminal node, as it portrays the end point of the model, that can receive but not give water. Besides the node number/name and location, no further input is needed.\n\nsea = model.terminal.add(Node(5, Point(-1.5, -3.0), name=\"sea\"))\n\n\n\n2.1.7 Defining edges\nImplement the connections (edges) between the nodes.\n\nmodel.edge.add(main, confluence, name=\"main\")\nmodel.edge.add(minor, confluence, name=\"minor\")\nmodel.edge.add(confluence, weir)\nmodel.edge.add(weir, sea, name=\"sea\")\n\n\n\n2.1.8 Visualization and model execution\nPlot the schematization.\n\nmodel.plot();\n\n\n\n\n\n\n\n\nWrite the model configuration to the TOML file. Name the output file Crystal-1/ribasim.toml:\n\ntoml_path = base_dir / \"Crystal-1/ribasim.toml\"\nmodel.write(toml_path)\ncli_path = \"ribasim\"\n\nAfter running model.write a subfolder Crystal-1 is created, which contains the model input data and configuration:\n\nribasim.toml: The model configuration\ndatabase.gpkg: A GeoPackage containing the network geometry and input data of the nodes used.\n\nNow run the model. You can open a terminal and run it from there. For example:\nribasim Crystal-1/ribasim.toml\nFrom Python you can run it with:\nimport subprocess\nresult = subprocess.run([cli_path, toml_path], capture_output=True, encoding=\"utf-8\")\nprint(result.stderr)\nresult.check_returncode()\nWhere cli_path is a string with either the full path to the Ribasim executable, like r\"c:\\bin\\ribasim\\ribasim\", or just \"ribasim\" in case you added the ribasim folder to your PATH.\nThe print(result.stderr) ensures you see the same logging and error messages that you would see in the terminal. And result.check_returncode() will throw an error when the simulation was not successful.\n\n\n2.1.9 Post-processing results\nRead the Arrow files and plot the simulated flows from different edges and the levels and storages at our confluence point:\n\ndf_basin = pd.read_feather(\n    base_dir / \"Crystal-1/results/basin.arrow\", dtype_backend=\"pyarrow\"\n)\n\n# Create pivot tables and plot for Basin data\ndf_basin_wide = df_basin.pivot_table(\n    index=\"time\", columns=\"node_id\", values=[\"storage\", \"level\"]\n)\n\n# Plot level and storage on the same graph with dual y-axes\nfig, ax1 = plt.subplots(figsize=(12, 6))\n\n# Plot level on the primary y-axis\ncolor = \"b\"\nax1.set_xlabel(\"Time\")\nax1.set_ylabel(\"Level [m]\", color=color)\nax1.plot(df_basin_wide.index, df_basin_wide[\"level\"], color=color)\nax1.tick_params(axis=\"y\", labelcolor=color)\n\n# Create a secondary y-axis for storage\nax2 = ax1.twinx()\ncolor = \"r\"\nax2.set_ylabel(\"Storage [m³]\", color=\"r\")\nax2.plot(df_basin_wide.index, df_basin_wide[\"storage\"], linestyle=\"--\", color=color)\nax2.tick_params(axis=\"y\", labelcolor=color)\n\nfig.tight_layout()  # Adjust layout to fit labels\nplt.title(\"Basin level and storage\")\nplt.show()\n\n\n\n\n\n\n\n\nThe figure above shows the storage and levels in the Basin node.\nTo accurately represent the relationship between water levels and discharge rates at this confluence, a TabulatedRatingCurve is used. This setup mimics the behavior of a gate or spillway, allowing us to model how varying water levels influence flow rates at the confluence. Since the basin node is functioning as a confluence rather than a storage reservoir, the simulated water levels and storage trends will closely follow the inflow patterns. This is because there is no net change in storage; all incoming water is balanced by outgoing flow.\n\n# Plot flow data\n# Read the flow results\ndf_flow = pd.read_feather(\n    base_dir / \"Crystal-1/results/flow.arrow\", dtype_backend=\"pyarrow\"\n)\n# Add the edge names and then remove unnamed edges\ndf_flow[\"name\"] = model.edge.df[\"name\"].loc[df_flow[\"edge_id\"]].to_numpy()\ndf_flow = df_flow[df_flow[\"name\"].astype(bool)]\n\n# Create a pivot table\npivot_flow = df_flow.pivot_table(index=\"time\", columns=\"name\", values=\"flow_rate\")\n\nline_styles = [\"-\", \"--\", \"-\", \"-.\"]\nnum_styles = len(line_styles)\n\nfig, ax = plt.subplots(figsize=(12, 6))\nfor i, column in enumerate(pivot_flow.columns):\n    pivot_flow[column].plot(\n        ax=ax, linestyle=line_styles[i % num_styles], linewidth=1.5, alpha=0.8\n    )\n\n# Set labels and title\nax.set_xlabel(\"Time\")\nax.set_ylabel(\"Flow [m³/s]\")\nax.legend(bbox_to_anchor=(1.15, 1), title=\"Edge\")\nplt.title(\"Flow\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThe figure above shows the discharges in \\(\\text{m}^3/\\text{s}\\) on each edge.\nEdge (3,4) represents the flow from the confluence to the TabulatedRatingCurve and edge (4,5) represents the flow from the TabulatedRatingCurve to the Terminal. Both show the same discharge over time. Which is expected in a natural flow environment, as what is coming into the confluence must come out.",
    "crumbs": [
      "Tutorials",
      "Getting started"
    ]
  },
  {
    "objectID": "dev/ci.html",
    "href": "dev/ci.html",
    "title": "Continuous integration",
    "section": "",
    "text": "Continuous integration (CI) is about commits being merged frequently, resulting in new features being released frequently. When proposing new changes to the code base a pull request is opened. When a new commit in that pull request, a series of tests will be done to make sure that this commit is error-free and robust in different environments. This process drive each new development through building, testing, quality checking.\ngraph LR\n    A[New development]--&gt;B[Continuous integration]\n    B--&gt;C[Merge]\nThis page contains an extensive explanation on how the Ribasim continuous integration works.",
    "crumbs": [
      "Contributing",
      "Continuous integration"
    ]
  },
  {
    "objectID": "dev/ci.html#conditions-of-using-teamcity",
    "href": "dev/ci.html#conditions-of-using-teamcity",
    "title": "Continuous integration",
    "section": "2.1 Conditions of using TeamCity",
    "text": "2.1 Conditions of using TeamCity\nTeamCity only runs workflows with the following conditions:\n\nWhen the workflow would take too long to run on GitHub Action\nWhen the release depends on the artifacts of the workflow.\nWhen other TeamCity projects depend on artifacts of Ribasim (e.g. iMOD coupler)",
    "crumbs": [
      "Contributing",
      "Continuous integration"
    ]
  },
  {
    "objectID": "dev/ci.html#release-process",
    "href": "dev/ci.html#release-process",
    "title": "Continuous integration",
    "section": "2.2 Release process",
    "text": "2.2 Release process\nIn the release, we include the generated testmodels, Ribasim CLI on Windows and Linux, Ribasim QGIS, and the source code.\nWe have the following pipeline to generate artifects for releasing:\n\nGenerate Testmodels: produces generated_testmodels artifact which is part of the release.\nMake GitHub Release: uses artifacts and makes the release. TeamCity constantly monitors the GitHub repository. When a tag starts with v20 is added, it triggers the release process.\nBuild Ribasim: builds library and executable of Ribasim on Linux and Windows. The artifacts are tested in Test Ribasim Binaries and used by iMOD Coupler.\nTest Ribasim Binaries: tests libribasim artifact and ribasim_cli artifact on Linux and Windows\n\n\n\n\n\n\n\nNote\n\n\n\nMake GitHub Release does not publish artifacts of “Test Ribasim Binaries”. It only publishes artifacts of “Build Ribasim” if the beforementioned tests pass.\n\n\n\n\n\n\n\ngraph LR\n    A[Make GitHub Release]--&gt;B(Release)\n    F[Generate Testmodels]--&gt;A\n    G[Make QGIS plugin]--&gt;A\n    H[Build Ribasim]---D[Test Ribasim Binaries]\n    D--&gt;A",
    "crumbs": [
      "Contributing",
      "Continuous integration"
    ]
  },
  {
    "objectID": "dev/allocation.html",
    "href": "dev/allocation.html",
    "title": "Allocation",
    "section": "",
    "text": "In this document, the allocation workflow is explained. Below is an overview of it.\n\n\n\n\n\nflowchart TD\n    subgraph update_allocation\n        direction TB\n        G[update mean flows]--&gt;E[collect demand]\n        E--&gt;F[allocate]\n    end\n    style update_allocation fill:#9ff\n    C(Begin)--&gt;A[Initialization allocation]\n    A--&gt; update_allocation --&gt; H[\\end of time?\\]\n    H--&gt; |No| update_allocation\n    H --&gt; |Yes| D(End)\n\n\n\n\n\n\nIf allocation is used in a model, Allocation structs are created. The allocation struct stores the data that is needed for the calculations and stores also the results of the calculation. In allocation, optimization is an essential part. JuMP.jl is used to model and solve the optimization problems that are defined by allocation. The AllocationModel struct is used for constructing the JuMP model. When an instance of AllocationModel is created, a JuMP optimization model is defined and initialized in the instance. More details on how allocation interacts with JuMP.jl is explained here.\nAfter initialization, as the simulation starts, the allocation problem is solved and updated after every allocation timestep (which is specified in the TOML). With every allocation timestep a new optimization problem is formulated and solved, using the latest available (simulation) model conditions and forcing and demand predictions.\nThe update of allocation (update_allocation) is repeating and spread into three parts:\n\nUpdating the mean flows. The mean flow data is only used only for output, not used by any internal functions.\n“Collect demand”. This step initialize and solve the optimization problems that collects the demand from the subnetworks.\n“Allocate”. This step solves the optimization problems that allocates the demand. For the main network this step allocates to the subnetworks and demand nodes that are in the main network. For the subnetwork this step allocates to the demand nodes.\n\nThe steps “collect demand” and “allocate” correspond to the function collect_demand and allocate_demand in the code.\nThe iteration stops when it reaches the end time step.\n\n\nThe Allocation struct stores necessary data and calculation results.\n\n\n\n\n\n\n\n\nfield\ntype\ndescription\n\n\n\n\nsubnetwork_ids\nVector{Int32}\nThe unique sorted allocation network IDs\n\n\nallocation_models\nAllocationModel\nThe allocation models for the main network and subnetworks corresponding to subnetwork_ids\n\n\nmain_network_connections\nVector{Vector{Tuple{NodeID, NodeID}}}\n(from_id, to_id) from the main network to the subnetwork per subnetwork\n\n\npriorities\nVector{Int32}\nAll used priority values.\n\n\nsubnetwork_demands\nDict{Tuple{NodeID, NodeID}, Vector{Float64}}\nThe demand of an edge from the main network to a subnetwork\n\n\nsubnetwork_allocateds\nDict{Tuple{NodeID, NodeID}, Vector{Float64}}\nThe allocated flow of an edge from the main network to a subnetwork\n\n\nmean_input_flows\nDict{Tuple{NodeID, NodeID}, Float64}\nFlows averaged over Δt_allocation over edges that are allocation sources\n\n\nmean_realized_flows\nDict{Tuple{NodeID, NodeID}, Float64}\nFlows averaged over Δt_allocation over edges that realize a demand\n\n\nrecord_demand\n\nA record of demands and allocated flows for nodes that have these\n\n\nrecord_flow\n\nA record of all flows computed by allocation optimization, eventually saved to output file\n\n\n\n\n\n\nThe AllocationModel struct has all the data that is needed for the JuMP optimization problem.\n\n\n\n\n\n\n\n\nfield\ntype\ndescription\n\n\n\n\nsubnetwork_id\nInt32\nThe ID of this allocation network\n\n\ncapacity\nJuMP.Containers.SparseAxisArray\nThe capacity per edge of the allocation network, as constrained by nodes that have a max_flow_rate\n\n\nproblem\nJuMP.Model\nThe JuMP.jl model for solving the allocation problem\n\n\nΔt_allocation\nFloat64\nThe time interval between consecutive allocation solves\n\n\n\n\n\n\nWhen working with optimization problems using JuMP, there are three fundamental components that need to be defined:\n\nOptimization variables: These are the variables that are optimized in the allocation problem formulation. They are defined using the @variable macro. For example, to specify the flow rates in all the edges in the allocation network as variables:\n\nproblem[:F] = JuMP.@variable(problem, F[edge = edges] &gt;= 0.0)\nMore details about setting up variables in allocation can be found in the section below.\n\nConstraints: These are the constraints that the optimization variables must satisfy. They are defined using the @constraint macro. The definition of the edge capacity constraints is shown in section below. add_constraints_... functions are used to add constraints to the optimization problem. The initial value of the constraints is set in the function set_initial_values_.... During the iteration, the constraints are updated based on the current state of the allocation network. When looping over priorities, the constraints are updated by the function adjust_....\nObjective function: This is the function that sets the objective of the optimization problem. It is defined using the @objective macro.\n\nThe functions JuMP.normalized_rhs and JuMP.set_normalized_rhs are used to read and write the constant right hand side of constraints.\nFor example, to update the capacity of one of the edges, JuMP.normalized_rhs moves all the constants to the right-hand sides and all variables to the left-hand side and JuMP.set_normalized_rhs sets the new right-hand-side value.\nJuMP.set_normalized_rhs(\n    constraints_capacity[edge_id],\n    JuMP.normalized_rhs(constraints_capacity[edge_id]) - JuMP.value(F[edge_id]),\n)\nSome JuMP data structures are used to store intermediate or result data. For more information, see JuMP API.",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#sec-allocation-struct",
    "href": "dev/allocation.html#sec-allocation-struct",
    "title": "Allocation",
    "section": "",
    "text": "The Allocation struct stores necessary data and calculation results.\n\n\n\n\n\n\n\n\nfield\ntype\ndescription\n\n\n\n\nsubnetwork_ids\nVector{Int32}\nThe unique sorted allocation network IDs\n\n\nallocation_models\nAllocationModel\nThe allocation models for the main network and subnetworks corresponding to subnetwork_ids\n\n\nmain_network_connections\nVector{Vector{Tuple{NodeID, NodeID}}}\n(from_id, to_id) from the main network to the subnetwork per subnetwork\n\n\npriorities\nVector{Int32}\nAll used priority values.\n\n\nsubnetwork_demands\nDict{Tuple{NodeID, NodeID}, Vector{Float64}}\nThe demand of an edge from the main network to a subnetwork\n\n\nsubnetwork_allocateds\nDict{Tuple{NodeID, NodeID}, Vector{Float64}}\nThe allocated flow of an edge from the main network to a subnetwork\n\n\nmean_input_flows\nDict{Tuple{NodeID, NodeID}, Float64}\nFlows averaged over Δt_allocation over edges that are allocation sources\n\n\nmean_realized_flows\nDict{Tuple{NodeID, NodeID}, Float64}\nFlows averaged over Δt_allocation over edges that realize a demand\n\n\nrecord_demand\n\nA record of demands and allocated flows for nodes that have these\n\n\nrecord_flow\n\nA record of all flows computed by allocation optimization, eventually saved to output file",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#sec-allocation-model-struct",
    "href": "dev/allocation.html#sec-allocation-model-struct",
    "title": "Allocation",
    "section": "",
    "text": "The AllocationModel struct has all the data that is needed for the JuMP optimization problem.\n\n\n\n\n\n\n\n\nfield\ntype\ndescription\n\n\n\n\nsubnetwork_id\nInt32\nThe ID of this allocation network\n\n\ncapacity\nJuMP.Containers.SparseAxisArray\nThe capacity per edge of the allocation network, as constrained by nodes that have a max_flow_rate\n\n\nproblem\nJuMP.Model\nThe JuMP.jl model for solving the allocation problem\n\n\nΔt_allocation\nFloat64\nThe time interval between consecutive allocation solves",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#sec-jump-problem",
    "href": "dev/allocation.html#sec-jump-problem",
    "title": "Allocation",
    "section": "",
    "text": "When working with optimization problems using JuMP, there are three fundamental components that need to be defined:\n\nOptimization variables: These are the variables that are optimized in the allocation problem formulation. They are defined using the @variable macro. For example, to specify the flow rates in all the edges in the allocation network as variables:\n\nproblem[:F] = JuMP.@variable(problem, F[edge = edges] &gt;= 0.0)\nMore details about setting up variables in allocation can be found in the section below.\n\nConstraints: These are the constraints that the optimization variables must satisfy. They are defined using the @constraint macro. The definition of the edge capacity constraints is shown in section below. add_constraints_... functions are used to add constraints to the optimization problem. The initial value of the constraints is set in the function set_initial_values_.... During the iteration, the constraints are updated based on the current state of the allocation network. When looping over priorities, the constraints are updated by the function adjust_....\nObjective function: This is the function that sets the objective of the optimization problem. It is defined using the @objective macro.\n\nThe functions JuMP.normalized_rhs and JuMP.set_normalized_rhs are used to read and write the constant right hand side of constraints.\nFor example, to update the capacity of one of the edges, JuMP.normalized_rhs moves all the constants to the right-hand sides and all variables to the left-hand side and JuMP.set_normalized_rhs sets the new right-hand-side value.\nJuMP.set_normalized_rhs(\n    constraints_capacity[edge_id],\n    JuMP.normalized_rhs(constraints_capacity[edge_id]) - JuMP.value(F[edge_id]),\n)\nSome JuMP data structures are used to store intermediate or result data. For more information, see JuMP API.",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#data-processing",
    "href": "dev/allocation.html#data-processing",
    "title": "Allocation",
    "section": "2.1 Data processing",
    "text": "2.1 Data processing\n\n2.1.1 Deriving edge capacities\nEdge capacities are important constraints in the optimization problem. They set the limit for the flows between the nodes. Therefore, the capacities of all the flow edges in the subnetworks are obtained. The capacity of an edge is given by the smallest max_flow_rate of the nodes connected to the edges if these nodes have such a value. The capacities are stored in a SparseArray object from JuMP.jl called capacities, indexed by a tuple of node IDs.\nThe function get_capacity obtains the capacities of the edges within a subnetwork given a subnetwork ID and the Ribasim model parameters p, if the sources of the subnetwork are valid (checked in function valid_sources).\n\n\n2.1.2 Handling the connection between the main network and subnetworks\nThe function find_subnetwork_connetions finds the edges that connected the main network to a subnetwork. subnetwork_demands and subnetwork_allocateds will be created, which stores demands and allocated values for subnetworks as a whole. main_network_connections is a vector of edges that connect a subnetwork with the main network.",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#sec-optimization-problem",
    "href": "dev/allocation.html#sec-optimization-problem",
    "title": "Allocation",
    "section": "2.2 The optimization problem",
    "text": "2.2 The optimization problem\n\n2.2.1 Setting up the optimization variables\nThere are three types of variables in the optimization problems:\n\nflows between the edges in the allocation model\nflows in and out of a basin with a level demand\nflows in and out of nodes that have a buffer, which are nodes that have a flow demand\n\nThe function add_variables_flow is used to add the variable of flows between the edges. The variables are obtained from the capacity array. And variables named by F($startnode, $endnode) are created.\nedges = keys(capacity.data)\nproblem[:F] = JuMP.@variable(problem, F[edge = edges] &gt;= 0.0)\nIn the function add_variables_basin, variables that represent flows of those basins that are connected with level demand are defined. Part of the function is shown in the code block below. A variable is named F_basin_in if the corresponding basin is supplied by a level demand and F_basin_out if consumed by a level demand.\n# Get the node IDs from the subnetwork for basins that have a level demand\nnode_ids_basin = [\n    node_id for\n    node_id in graph[].node_ids[subnetwork_id] if graph[node_id].type == :basin &&\n    has_external_demand(graph, node_id, :level_demand)[1]\n]\nproblem[:F_basin_in] =\n    JuMP.@variable(problem, F_basin_in[node_id = node_ids_basin,] &gt;= 0.0)\nproblem[:F_basin_out] =\n    JuMP.@variable(problem, F_basin_out[node_id = node_ids_basin,] &gt;= 0.0)\nThe last set of optimization variables is the flow edges in and out of the buffer of nodes with a flow demand. It is defined in a similar way to the second set of variables.\n\n\n2.2.2 Setting up initial optimization constraints\nAll the variables are greater and equal to 0. This is set when the variables are added to the optimization problem.\nOther constraints are capacity, source_user, source, flow_conservation, fractional_flow, basin_outflow, flow_buffer_outflow and flow_demand_outflow.\nFor each set of constraints, a function named add_constrains_[constraints name] is created.\nTake add_constraints_user_source as an example, the nodes that are relevant for the constraints are added to the optimization problem by calling JuMP.@constraint.\nnode_ids_user = [node_id for node_id in node_ids if node_id.type == NodeType.UserDemand]\n\nproblem[:source_user] = JuMP.@constraint(\n    problem,\n    [node_id = node_ids_user],\n    F[(node_id, outflow_id(graph, node_id))] &lt;= 0.0,\n    base_name = \"source_user\"\n)",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#preparing-the-optimization-problem",
    "href": "dev/allocation.html#preparing-the-optimization-problem",
    "title": "Allocation",
    "section": "3.1 Preparing the optimization problem",
    "text": "3.1 Preparing the optimization problem\n\n3.1.1 Setting up the objective function\nThe optimization objective is the sum of three quadratic error terms. The quadratic terms are defined with the add_objective_term function.\nFunction set_objective_priority sets the objective function based on the main network for a given priority with the following steps:\n\nFirst, it treats the subnetworks as user demand nodes and adds the quadratic terms of the main network.\nThen it loops over all the edges in allocation.\nBased on the type of the node that the edge is pointing to (user demand or flow demand), it adds the corresponding quadratic terms.\nFinally, it does the same to the edges that start from a level demand node.\n\n\n\n3.1.2 Setting the constraints and capacities\nIn the function set_initial_values, the following capacities and demands are initialized:\n\nSource capacities come from the physical layer\nEdge capacities derived from the maximum capacities between the connected nodes\nBasin capacities come from the disk of water above the max level set by a level demand node\nBuffer capacities start at 0\nUser demands fractional return flow starts at 0\nDemands either come from the Ribasim model or are set via the BMI\n\nAs shown below, these functions set the capacities to the corresponding initial values.\nset_initial_capacities_source!(allocation_model, p)\nset_initial_capacities_edge!(allocation_model, p)\nset_initial_capacities_basin!(allocation_model, p, u, t)\nset_initial_capacities_buffer!(allocation_model)\nset_initial_capacities_returnflow!(allocation_model)\n\nset_initial_demands_user!(allocation_model, p, t)\nset_initial_demands_level!(allocation_model, u, p, t)\nset_initial_demands_flow!(allocation_model, p, t)\nThese capacities determine the constraints of the optimization problem. Take set_initial_capacities_source as an example, the right-hand-side values of the source_constraints are set to the source_capacity.\nfor edge_metadata in values(graph.edge_data)\n    (; edge) = edge_metadata\n    if graph[edge...].subnetwork_id_source == subnetwork_id\n        # If it is a source edge for this allocation problem\n        if edge ∉ main_network_source_edges\n            # Reset the source to the averaged flow over the last allocation period\n            source_capacity = mean_input_flows[edge][]\n            JuMP.set_normalized_rhs(\n                source_constraints[edge],\n                # It is assumed that the allocation procedure does not have to be differentiated.\n                source_capacity,\n            )\n        end\n    end\nend\nApart from the set_initial_* function above, capacities of inlet are the allocated capacities from the main network to the subnetworks. Source constraints will be adapted based on the optimization type. This function is called separately and thus not part of the set_initial_values.",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#looping-over-priorities",
    "href": "dev/allocation.html#looping-over-priorities",
    "title": "Allocation",
    "section": "3.2 Looping over priorities",
    "text": "3.2 Looping over priorities\n\n3.2.1 Updating capacities\nWhile optimizing a given priority, the function set_capacities_flow_demand_outflow updates the constraints flow_demand_outflow. If the current priority is the same as the priority of the flow demand, constraints will be infinite, otherwise 0. At priorities where there is no flow demand, flow can go freely trough the node. When there is flow demand, flow is directed into the buffer. This is to make sure that flow can go to the node with the flow demand, even though the flow might have nowhere to go after that node.\nThe optimization objective function is updated based on the new demands and the given priority.\nIf a solution is found by the solver, the allocation result will be updated. And it will be saved, so the physical layer can make use of it.\nLastly, capacities and demands are updated, as shown below:\nadjust_capacities_source!(allocation_model)\nadjust_capacities_edge!(allocation_model)\nadjust_capacities_basin!(allocation_model)\nadjust_capacities_buffer!(allocation_model)\nadjust_capacities_returnflow!(allocation_model, p)\n\nfor parameter in propertynames(p)\n    demand_node = getfield(p, parameter)\n    if demand_node isa AbstractDemandNode\n        adjust_demands!(allocation_model, p, priority_idx, demand_node)\n    end\nend",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#output-data",
    "href": "dev/allocation.html#output-data",
    "title": "Allocation",
    "section": "3.3 Output data",
    "text": "3.3 Output data\nThe function save_demands_and_allocations saves the demand and the allocated value per demand node. And the function save_allocation_flows saves the optimized flows over the edges in the subnetwork. These values are saved in the record_demand and record_flow fields of the Allocation struct and only written to the output file at the end of the simulation.",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#communicating-to-the-physical-layer",
    "href": "dev/allocation.html#communicating-to-the-physical-layer",
    "title": "Allocation",
    "section": "3.4 Communicating to the physical layer",
    "text": "3.4 Communicating to the physical layer\nThe function assign_allocations updates the subnetwork demand if the optimization task is collect_demands. It assigns the allocated amount to the UserDemand nodes with the result of the optimization if the optimization task is allocate. Afterwards, it writes the resulting flow to the Allocation object.\n\n3.4.1 UserDemand abstraction\nWhen allocation is active, the amount each UserDemand node is allowed to extract from its upstream basin is determined by the allocation algorithm. See here for more details on how allocation updates the UserDemand node.\n\n\n3.4.2 Controlling pumps/weirs based on allocation results\nN/A and TODO in this task.",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/python.html",
    "href": "dev/python.html",
    "title": "Python tooling development",
    "section": "",
    "text": "In order to run tests on Ribasim Python execute\npixi run test-ribasim-python\n\n\n\nMake sure to run Clear All Outputs on the notebook before committing.\n\n\n\nBefore running the Julia tests or building binaries, example model input needs to created. This is done by running the following:\npixi run generate-testmodels\nThis places example model input files under ./generated_testmodels/. If the example models change, re-run this script.\n\n\n\nInstall the Python, ruff and autoDocstring extensions.\n\n\n\nTo run our linting suite locally, execute:\npixi run lint",
    "crumbs": [
      "Contributing",
      "Python tooling development"
    ]
  },
  {
    "objectID": "dev/python.html#sec-test",
    "href": "dev/python.html#sec-test",
    "title": "Python tooling development",
    "section": "",
    "text": "In order to run tests on Ribasim Python execute\npixi run test-ribasim-python",
    "crumbs": [
      "Contributing",
      "Python tooling development"
    ]
  },
  {
    "objectID": "dev/python.html#updating-example-notebooks",
    "href": "dev/python.html#updating-example-notebooks",
    "title": "Python tooling development",
    "section": "",
    "text": "Make sure to run Clear All Outputs on the notebook before committing.",
    "crumbs": [
      "Contributing",
      "Python tooling development"
    ]
  },
  {
    "objectID": "dev/python.html#prepare-model-input",
    "href": "dev/python.html#prepare-model-input",
    "title": "Python tooling development",
    "section": "",
    "text": "Before running the Julia tests or building binaries, example model input needs to created. This is done by running the following:\npixi run generate-testmodels\nThis places example model input files under ./generated_testmodels/. If the example models change, re-run this script.",
    "crumbs": [
      "Contributing",
      "Python tooling development"
    ]
  },
  {
    "objectID": "dev/python.html#sec-vscode",
    "href": "dev/python.html#sec-vscode",
    "title": "Python tooling development",
    "section": "",
    "text": "Install the Python, ruff and autoDocstring extensions.",
    "crumbs": [
      "Contributing",
      "Python tooling development"
    ]
  },
  {
    "objectID": "dev/python.html#linting",
    "href": "dev/python.html#linting",
    "title": "Python tooling development",
    "section": "",
    "text": "To run our linting suite locally, execute:\npixi run lint",
    "crumbs": [
      "Contributing",
      "Python tooling development"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html",
    "href": "dev/qgis_test_plan.html",
    "title": "QGIS plugin manual test plan",
    "section": "",
    "text": "This document describes how to perform a full manual test on the Ribasim QGIS plugin. Known shortcomings and issues can be documented here. Bugs can be reported on GitHub.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#enable-and-disable",
    "href": "dev/qgis_test_plan.html#enable-and-disable",
    "title": "QGIS plugin manual test plan",
    "section": "1.1 Enable and disable",
    "text": "1.1 Enable and disable\n\nOpen QGIS and navigate to “Plugins &gt; Manage and Install Plugins…”: The plugin management window opens.\nNavigate to “Installed”: Ribasim plugin is in the list (enabled).\nDisable the Ribasim plugin: Ribasim plugin panel hides if it was open, Ribasim button hides from navigation toolbar.\nEnable the Ribasim plugin: Ribasim button shows on the navigation toolbar.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#open-and-close",
    "href": "dev/qgis_test_plan.html#open-and-close",
    "title": "QGIS plugin manual test plan",
    "section": "1.2 Open and close",
    "text": "1.2 Open and close\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nOpen the application via the Ribasim button on the QGIS toolbar: Ribasim panel opens.\nPress the Ribasim button on the QGIS toolbar: Ribasim panel hides.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#button-states-on-startup",
    "href": "dev/qgis_test_plan.html#button-states-on-startup",
    "title": "QGIS plugin manual test plan",
    "section": "1.3 Button states on startup",
    "text": "1.3 Button states on startup\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nOpen the application via the Ribasim button on the QGIS toolbar: Ribasim panel opens.\nIn the Model tab, the “Add to QGIS” and “Remove from Dataset” buttons are disabled.\nIn the Nodes tab, all buttons are disabled.\n\n❌ Failing",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#new-and-cancel",
    "href": "dev/qgis_test_plan.html#new-and-cancel",
    "title": "QGIS plugin manual test plan",
    "section": "2.1 New and cancel",
    "text": "2.1 New and cancel\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nOpen the application via the Ribasim button on the QGIS toolbar: Ribasim panel opens.\nPress the “New” button in the Model tab: file navigation window pops up.\nFill in a name.\nPress “Cancel”: Ensure that no files are created in that location.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#new-single-model",
    "href": "dev/qgis_test_plan.html#new-single-model",
    "title": "QGIS plugin manual test plan",
    "section": "2.2 New single model",
    "text": "2.2 New single model\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nOpen the application via the Ribasim button on the QGIS toolbar: Ribasim panel opens.\nPress the “New” button in the Model tab: file navigation window pops up.\nFill in a name (“test1”).\nPress OK: A TOML and database file are created on the given location.\nThe layers tab shows a group with a “Node” and “Edge” layer, the canvas is empty.\nThe Ribasim panel shows a Node and Edge layer, the file path is set in the text field, all nodes buttons are enabled.\nCleanup: Delete the created files from disk.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#new-model-in-same-folder",
    "href": "dev/qgis_test_plan.html#new-model-in-same-folder",
    "title": "QGIS plugin manual test plan",
    "section": "2.3 New model in same folder",
    "text": "2.3 New model in same folder\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nOpen the application via the Ribasim button on the QGIS toolbar: Ribasim panel opens.\nPress the “New” button in the Model tab: file navigation window pops up.\nFill in a name (“test1”).\nPress OK: A TOML and database file are created on the given location.\nPress the “New” button in the Model tab: file navigation window pops up.\nFill in a name (“test2”).\nPress OK: An error is given that the database.gpkg already exists, test2.toml is not written.\nCleanup: Delete the created files from disk.\n\n❌ Failing",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#new-model-with-same-name",
    "href": "dev/qgis_test_plan.html#new-model-with-same-name",
    "title": "QGIS plugin manual test plan",
    "section": "2.4 New model with same name",
    "text": "2.4 New model with same name\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nOpen the application via the Ribasim button on the QGIS toolbar: Ribasim panel opens.\nPress the “New” button in the Model tab: file navigation window pops up.\nFill in a name (“test1”).\nPress OK: A TOML and database file are created on the given location.\nOpen test1.toml in a text editor and write “EXTRA_LINE=true”\nPress the “New” button in the Model tab: file navigation window pops up.\nFill in a name (“test1”).\nPress OK: Shows a popup window to ask if you want to overwrite.\nPress Yes: An error is given that the database.gpkg already exists, test1.toml is not overwritten (EXTRA_LINE=true) is still in test1.toml.\nCleanup: Delete the created files from disk.\n\nUnsure if this is wanted behavior, as we said we wanted to overwrite the TOML file, and therefore also the database file. Perhaps we should create folders instead of TOML files only.\n❌ Failing",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#new-model-and-clean-new-project-cleans-ribasim-plugin",
    "href": "dev/qgis_test_plan.html#new-model-and-clean-new-project-cleans-ribasim-plugin",
    "title": "QGIS plugin manual test plan",
    "section": "2.5 New model and clean new project cleans Ribasim plugin",
    "text": "2.5 New model and clean new project cleans Ribasim plugin\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nOpen the application via the Ribasim button on the QGIS toolbar: Ribasim panel opens.\nPress the “New” button in the Model tab: file navigation window pops up.\nFill in a name (“test1”).\nPress OK: A TOML and database file are created on the given location.\nPress “Project &gt; New”: Popup asks to save the project.\nPress Discard: Layers tab is emptied, Ribasim panel is emptied.\n\n❌ Failing",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#open-model-twice",
    "href": "dev/qgis_test_plan.html#open-model-twice",
    "title": "QGIS plugin manual test plan",
    "section": "3.1 Open model twice",
    "text": "3.1 Open model twice\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nOpen the application via the Ribasim button on the QGIS toolbar: Ribasim panel opens.\nPress the “New” button in the Model tab: file navigation window pops up.\nFill in a name (“test1”).\nPress OK: A TOML and database file are created on the given location.\nPress the “Open” button in the Model tab: file navigation window pops up.\nOpen test1.toml: A new layer group is added to the layers panel.\nIn the Nodes tab press “Basin / profile”: A Basin / profile table layer is added to the last layer group only.\n\nIntended behavior: The same model is loaded twice, but there is only a connection on the last loaded model when interacting with the plugin.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#add-to-qgis-button",
    "href": "dev/qgis_test_plan.html#add-to-qgis-button",
    "title": "QGIS plugin manual test plan",
    "section": "3.2 Add to QGIS button",
    "text": "3.2 Add to QGIS button\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nOpen the application via the Ribasim button on the QGIS toolbar: Ribasim panel opens.\nPress the “New” button in the Model tab: file navigation window pops up.\nFill in a name (“test1”).\nPress OK: A TOML and database file are created on the given location.\nPress “Add to QGIS”: Nothing happens.\nPress the “Edge” layer in the Model tab: “Add to QGIS” button is disabled.\n\n❌ Failing",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#remove-from-dataset-button",
    "href": "dev/qgis_test_plan.html#remove-from-dataset-button",
    "title": "QGIS plugin manual test plan",
    "section": "3.3 Remove from Dataset button",
    "text": "3.3 Remove from Dataset button\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nOpen the application via the Ribasim button on the QGIS toolbar: Ribasim panel opens.\nPress the “New” button in the Model tab: file navigation window pops up.\nFill in a name (“test1”).\nPress OK: A TOML and database file are created on the given location.\nPress the “Edge” layer in the Model tab, press “Remove from Dataset”: Popup shows “Deleting: Edge”.\nPress “Yes”: “Edge” layer is removed from Layers panel and from Model tab.\n\nUnsure if this is wanted behavior, it is now impossible to load the model afterwards because it no longer contains an Edge layer. Perhaps better if we only allow removal of the optional tables. See this bug report.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#add-all-tables-to-new-model",
    "href": "dev/qgis_test_plan.html#add-all-tables-to-new-model",
    "title": "QGIS plugin manual test plan",
    "section": "4.1 Add all tables to new model",
    "text": "4.1 Add all tables to new model\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nOpen the application via the Ribasim button on the QGIS toolbar: Ribasim panel opens.\nPress the “New” button in the Model tab: file navigation window pops up.\nFill in a name (“test1”).\nPress OK: A TOML and database file are created on the given location.\nGo to the Nodes tab: All buttons are enabled.\nFrom left to right, top to bottom, press every button to add tables to the layers: The layer group contains extra layers for every button clicked. Basin / area is a MultiPolygon layer.\nNavigate to Model tab: All layers are added to the panel.\nPress the “Open” button to open the same model once again: The layers panel adds the model containing all of its layers, the Model tab was refreshed.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#add-table-twice-to-new-model",
    "href": "dev/qgis_test_plan.html#add-table-twice-to-new-model",
    "title": "QGIS plugin manual test plan",
    "section": "4.2 Add table twice to new model",
    "text": "4.2 Add table twice to new model\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nOpen the application via the Ribasim button on the QGIS toolbar: Ribasim panel opens.\nPress the “New” button in the Model tab: file navigation window pops up.\nFill in a name (“test1”).\nPress OK: A TOML and database file are created on the given location.\nGo to the Nodes tab: All buttons are enabled.\nPress the Basin / time button: A layer is added to the layers panel with that name, the button becomes disabled.\n\n❌ Failing",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#add-points-to-node-layer",
    "href": "dev/qgis_test_plan.html#add-points-to-node-layer",
    "title": "QGIS plugin manual test plan",
    "section": "5.1 Add points to Node layer",
    "text": "5.1 Add points to Node layer\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nOpen the application via the Ribasim button on the QGIS toolbar: Ribasim panel opens.\nPress the “New” button in the Model tab: file navigation window pops up.\nFill in a name (“test1”).\nPress OK: A TOML and database file are created on the given location.\nSelect the Node layer in the Layers tab: edit buttons in the toolbar become enabled.\nEdit the layer by pressing the pencil button: Add Point Feature button becomes enabled.\nClick in the canvas: Popup appears with Feature Attributes to fill in.\nPress OK: The first Node appears on the map.\nClick in the canvas again: Popup appears with Feature Attributes to fill in.\nPress OK: The second Node appears on the map.\n\nUnexpected behavior: The default type of the nodes is NULL, and therefore undefined. Should be enforced and validated. See issue.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#add-edges-to-edge-layer",
    "href": "dev/qgis_test_plan.html#add-edges-to-edge-layer",
    "title": "QGIS plugin manual test plan",
    "section": "5.2 Add edges to Edge layer",
    "text": "5.2 Add edges to Edge layer\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nOpen the application via the Ribasim button on the QGIS toolbar: Ribasim panel opens.\nPress the “New” button in the Model tab: file navigation window pops up.\nFill in a name (“test1”).\nPress OK: A TOML and database file are created on the given location.\nSelect the Node layer in the Layers tab: edit buttons in the toolbar become enabled.\nEdit the layer by pressing the pencil button: Add Point Feature button becomes enabled.\nClick in the canvas: Popup appears with Feature Attributes to fill in.\nAdd a node id of 1, press OK: The first Node appears on the map.\nClick in the canvas again: Popup appears with Feature Attributes to fill in.\nAdd a node id of 2, press OK: The second Node appears on the map.\nSelect the Edge layer in the Layers tab: edit buttons in the toolbar become enabled.\nEnable snapping under View &gt; Toolbars &gt; Snapping Toolbars: Magnet button is enabled and active.\nPress the Add Line Feature button: Mouse becomes a crosshair.\nSnap a line between the two nodes, click the two nodes and then right click to finish: Popup shows with input, most fields are set to NULL.\nPress OK: Line appears on screen between the two nodes.\nSave the layer’s edits: The line becomes blue.\nOpen the attribute table: The information shows the from_node_id, to_node_id. This information matches the information from the Node table.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#node-selection-on-map-triggers-table-selection",
    "href": "dev/qgis_test_plan.html#node-selection-on-map-triggers-table-selection",
    "title": "QGIS plugin manual test plan",
    "section": "5.3 Node selection on map triggers table selection",
    "text": "5.3 Node selection on map triggers table selection\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nOpen the application via the Ribasim button on the QGIS toolbar: Ribasim panel opens.\nPress the “Open” button in the Model tab: file navigation window pops up.\nChoose an existing model from the generated_testmodels folder.\nPress OK: The model layers appear in the layer panel and on the map.\nSelect the node layer, and make a subselection of nodes on the map: Nodes are highlighted in yellow, including their edges.\nOpen the Edge attribute table: The highlighted rows are those with a from/to node_id that was selected.\nOpen any non-spatial attribute table: The highlighted rows are those with an node_id that was selected.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#edit-tables-with-data",
    "href": "dev/qgis_test_plan.html#edit-tables-with-data",
    "title": "QGIS plugin manual test plan",
    "section": "6.1 Edit tables with data",
    "text": "6.1 Edit tables with data\nTODO",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#edit-the-type-of-a-node",
    "href": "dev/qgis_test_plan.html#edit-the-type-of-a-node",
    "title": "QGIS plugin manual test plan",
    "section": "6.2 Edit the type of a node",
    "text": "6.2 Edit the type of a node\nTODO",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#edit-information-in-optional-tables",
    "href": "dev/qgis_test_plan.html#edit-information-in-optional-tables",
    "title": "QGIS plugin manual test plan",
    "section": "6.3 Edit information in optional tables",
    "text": "6.3 Edit information in optional tables\nTODO",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#run-a-model-and-check-the-time-series",
    "href": "dev/qgis_test_plan.html#run-a-model-and-check-the-time-series",
    "title": "QGIS plugin manual test plan",
    "section": "7.1 Run a model and check the time series",
    "text": "7.1 Run a model and check the time series\nTODO",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#perform-tutorial-in-documentation",
    "href": "dev/qgis_test_plan.html#perform-tutorial-in-documentation",
    "title": "QGIS plugin manual test plan",
    "section": "8.1 Perform tutorial in documentation",
    "text": "8.1 Perform tutorial in documentation\nGo through the tutorial as described in the How-to guide.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/benchmark.html",
    "href": "dev/benchmark.html",
    "title": "Benchmark",
    "section": "",
    "text": "This document describes how the benchmarking and performance testing of Ribasim is handled. In Ribasim, the benchmarking includes and regression tests on the test models and regressive performance tests on the production models.\nThe idea of regression tests on the test models is to run models with various solvers, run models with a sparse Jacobian and a dense one and compare the outputs. It will possibly involve production models in the future. And runtime performance test is lined up for the next step (in issue #1698).\nThe idea of regressive performance tests on the production models is to test the performance of running the production models. It will report if the new changes in the code decrease the model’s performance or result in failed runs.",
    "crumbs": [
      "Contributing",
      "Benchmark"
    ]
  },
  {
    "objectID": "dev/benchmark.html#benchmark-the-ode-solvers",
    "href": "dev/benchmark.html#benchmark-the-ode-solvers",
    "title": "Benchmark",
    "section": "1.1 Benchmark the ODE solvers",
    "text": "1.1 Benchmark the ODE solvers\nThe benchmarking of the ODE solvers is done by running the test models with different ODE solvers and solver settings and comparing the output with the benchmark.\nThe settings include toggling the sparse and autodiff solver settings. Currently, 4 models are chosen to undergo the regression tests. They are trivial, basic, pid_control and subnetwork_with_sources.\nThe benchmark reference are the output files of a run of the test models with default solver settings. The output files basin.arrow and flow.arrow are used for comparison. Different margins are set for the comparison of the outputs, and the benchmark is considered passed if the output is within the margin. Since we are still in the process of evaluating the performance of different solvers, the margin is subject to change.\nThe regression tests are run on a weekly basis.",
    "crumbs": [
      "Contributing",
      "Benchmark"
    ]
  },
  {
    "objectID": "dev/addnode.html",
    "href": "dev/addnode.html",
    "title": "Adding node types",
    "section": "",
    "text": "Several parts of the code have to be made aware of the new node type. In the rest of this page we shall call our new node type NewNodeType.",
    "crumbs": [
      "Contributing",
      "Adding node types"
    ]
  },
  {
    "objectID": "dev/addnode.html#parameters",
    "href": "dev/addnode.html#parameters",
    "title": "Adding node types",
    "section": "1.1 Parameters",
    "text": "1.1 Parameters\nThe parameters object (defined in parameter.jl) passed to the ODE solver must be made aware of the new node type. Therefore define a struct in parameter.jl which holds the data for each node of the new node type:\nstruct NewNodeType &lt;: AbstractParameterNode\n    node_id::Vector{NodeID}\n    # Other fields\nend\nAnother abstract type which subtypes from AbstractParameterNode is called AbstractDemandNode. For creating new node type used in allocation, define a struct:\nstruct NewNodeType &lt;: AbstractDemandNode\n    node_id::Vector{NodeID}\n    # Other fields\nend\nThese fields do not have to correspond 1:1 with the input tables (see below). The vector with all node IDs that are of the new type in a given model is a mandatory field. Now you can:\n\nAdd new_node_type::NewNodeType to the Parameters object;\nAdd new_node_type = NewNodeType(db,config) to the function Parameters in read.jl and add new_node_type at the proper location in the Parameters constructor call.",
    "crumbs": [
      "Contributing",
      "Adding node types"
    ]
  },
  {
    "objectID": "dev/addnode.html#reading-from-configuration",
    "href": "dev/addnode.html#reading-from-configuration",
    "title": "Adding node types",
    "section": "1.2 Reading from configuration",
    "text": "1.2 Reading from configuration\nThere can be several schemas associated with a single node type. To define a schema for the new node type, add the following to schema.jl:\n@schema \"ribasim.newnodetype.static\" NewNodeTypeStatic\n\n\"\"\"\nnode_id: node ID of the NewNodeType node\n\"\"\"\n@version NewNodeTypeStaticV1 begin\n    node_id::Int32\n    # Other fields\nend\nHere static refers to data that does not change over time. For naming conventions of these schemas see Node usage. If a new schema contains a priority column for allocation, it must also be added to the list of all such schemas in the function get_all_priorities in util.jl.\nvalidation.jl deals with checking and applying a specific sorting order for the tabular data (default is sorting by node ID only), see sort_by_function and sorted_table!.\nNow we define the function that is called in the second bullet above, in read.jl:\nfunction NewNodeType(db::DB, config::Config)::NewNodeType\n    static = load_structvector(db, config, NewNodeTypeStaticV1)\n    defaults = (; foo = 1, bar = false)\n    # Process potential control states in the static data\n    parsed_parameters, valid = parse_static_and_time(db, config, \"NewNodeType\"; static, defaults)\n\n    if !valid\n        error(\"Errors occurred when parsing NewNodeType data.\")\n    end\n\n    # Unpack the fields of static as inputs for the NewNodeType constructor\n    return NewNodeType(\n        NodeID.(NodeType.NewNodeType, parsed_parameters.node_id),\n        parsed_parameters.some_property,\n        parsed_parameters.control_mapping)\nend",
    "crumbs": [
      "Contributing",
      "Adding node types"
    ]
  },
  {
    "objectID": "dev/addnode.html#node-behavior",
    "href": "dev/addnode.html#node-behavior",
    "title": "Adding node types",
    "section": "1.3 Node behavior",
    "text": "1.3 Node behavior\nIn general if the new node type dictates flow, the behavior of the new node in the Ribasim core is defined in a method of the formulate_flow! function, which is called within the water_balance! (both in solve.jl) function being the right hand side of the system of differential equations solved by Ribasim. Here the details depend highly on the specifics of the node type. An example structure of a formulate_flow! method is given below.\nfunction formulate_flow!(new_node_type::NewNodeType, p::Parameters)::Nothing\n    # Retrieve relevant parameters\n    (; graph) = p\n    (; node_id, param_1, param_2) = new_node_type\n\n    # Loop over nodes of NewNodeType\n    for (i, id) in enumerate(node_id)\n        # compute e.g. flow based on param_1[i], param_2[i]\n    end\n\n    return nothing\nend\nIf the new node type is non-conservative, meaning it either adds or removes water from the model, these boundary flows also need to be recorded. This is done by storing it on the diagonal of the flow[from, to] matrix, e.g. flow[id, id] = q, where q is positive for water added to the model.",
    "crumbs": [
      "Contributing",
      "Adding node types"
    ]
  },
  {
    "objectID": "dev/addnode.html#the-jacobian",
    "href": "dev/addnode.html#the-jacobian",
    "title": "Adding node types",
    "section": "1.4 The Jacobian",
    "text": "1.4 The Jacobian\nSee Equations for a mathematical description of the Jacobian.\nBefore the Julia core runs its simulation, the sparsity structure jac_prototype of \\(J\\) is determined with get_jac_prototype in sparsity.jl. This function runs trough all node types and looks for nodes that create dependencies between states. It creates a sparse matrix of zeros and ones, where the ones denote locations of possible non-zeros in \\(J\\). Note that only nodes that set flows in the physical layer (or have their own state like PidControl) affect the sparsity structure.\nWe divide the various node types in groups based on what type of state dependencies they yield, and these groups are discussed below. Each group has its own method update_jac_prototype! in utils.jl for the sparsity structure induced by nodes of that group. NewNodeType should be added to the signature of one these methods, or to the list of node types that do not contribute to the Jacobian in the method of update_jac_prototype! whose signature contains node::AbstractParameterNode. Of course it is also possible that a new method of update_jac_prototype! has to be introduced.\nThe current dependency groups are:\n\nOut-neighbor dependencies: examples are TabulatedRatingCurve, Pump (the latter only in the reduction factor regime and not PID controlled). If the in-neighbor of a node of this group is a basin, then the storage of this basin affects itself and the storage of the outneighbor if that is also a basin;\nEither-neighbor dependencies: examples are LinearResistance, ManningResistance. If either the in-neighbor or out-neighbor of a node of this group is a basin, the storage of this basin depends on itself. If both the in-neighbor and the out-neighbor are basins, their storages also depend on eachother.\nThe PidControl node is a special case which is discussed in the PID equations.\n\nUsing jac_prototype the Jacobian of water_balance! is computed automatically using ForwardDiff.jl with memory management provided by PreallocationTools.jl. These computations make use of DiffCache and dual numbers.",
    "crumbs": [
      "Contributing",
      "Adding node types"
    ]
  },
  {
    "objectID": "dev/addnode.html#python-class",
    "href": "dev/addnode.html#python-class",
    "title": "Adding node types",
    "section": "2.1 Python class",
    "text": "2.1 Python class\nIn python/ribasim/ribasim/config.py add\n\nthe above defined schemas to the imports from ribasim.schemas. This requires code generation to work, see Finishing up;\na class of the following form with all schemas associated with the node type:\n\nclass NewNodeType(MultiNodeModel):\n    static: TableModel[NewNodeTypeStaticSchema] = Field(\n        default_factory=TableModel[NewNodeTypeStaticSchema],\n        json_schema_extra={\"sort_keys\": [\"node_id\"]},\n    )\nIn python/ribasim/ribasim/nodes/__init__.py add\n\nNewNodeType to the imports from ribasim.nodes;\n\"NewNodeType\" to __all__.\n\nIn python/ribasim/ribasim/model.py, add\n\nNewNodeType to the imports from ribasim.config;\nnew_node_type as a parameter of the Model class.\n\nIn python/ribasim/ribasim/geometry/node.py add a color and shape description in the MARKERS and COLORS dictionaries.",
    "crumbs": [
      "Contributing",
      "Adding node types"
    ]
  },
  {
    "objectID": "changelog.html",
    "href": "changelog.html",
    "title": "1 Changelog",
    "section": "",
    "text": "All notable changes to this project will be documented in this file. The format is based on Keep a Changelog,\n\n\n\n\n\nThis major new release contains many improvements. A new formulation allows much smaller water balance errors, which is combined with several performance improvements. Ribasim Python does more validation that was previously only done in the core. The Ribasim QGIS plugin now sets the relations between tables for easier model inspection. Adding min_upstream_level and max_downstream_level to Pump and Outlet means DiscreteControl is often no longer needed. The most significant breaking change is making the node_id and edge_id the index of the Node and Edge table; these need to be globally unique.\nStarting from this release Ribasim is labeled as beta software. Since development is currently mainly driven by applications in the Dutch water system, we expect that addition work needs to be done for general use outside the Netherlands.\nFor coupled simulation with MODFLOW and/or MetaSWAP, this release is part of the iMOD Coupler, specifically release v2024.4.0\n\n\n\nSupport discrete control based on an external concentration condition. #1660\nAdd results/solver_stats.arrow with solver statistics over time. #1677\nAdd icon to ribasim.exe on Windows. #1712\nSave QGIS styling in the model database. #1713\nAdd Delwaq coupling guide. #1619\nSolver speedup due to backtracking relaxation. #1761\nReject adding a duplicate edge in Python. #1719\nSupport transient UserDemand return factor. #1727\nDocument the interpolation of input data. #1720\nAutomate Jacobian sparsity detection. #1606\nSupport specifying the edge_id as model.edge.add(a, b, edge_id=5). #1737\nUse https://ribasim.org/ to host our documentation. #1736\nValidate geometry types in Python. #1760\nAdd relationships between tables in QGIS. #1755\nSupport migrating from older Ribasim versions in Python. #1764\nAdd quick start guide to docs. #1787\nAdd min_upstream_level and max_downstream_level to Pump and Outlet. #1792\nAdd max_downstream_level to TabulatedRatingCurve. #1795\nValidate edge connections in Python. #1765\nAdd low storage reduction factor to ManningResistance. #1796\n\n\n\n\n\nRefactor of the core to ensure smaller water balance errors. #1819\nMake node_id globally unique. #1717\nMake the Node ID the index of the Node table, and Edge ID for Edge. #1737\nMake more Python functions private. #1702\nPut the contents of the CLI zips in a folder. #1722\nChanged water balance error definition. #1767\nDisallow missing priority parameter when using allocation. #1745\nRename Outlet’s min_crest_level to min_upstream_level. #1788\nOnly allow flow under gravity in TabulatedRatingCurve. #1795\nUse dtype_backend=\"pyarrow\" for Pandas DataFrames. #1781\n\n\n\n\n\nRemove oscillations in ManningResistance. #1750\nFix GeoPandas CRS warning. #1810\n\n\n\n\n\nFor this release we said goodbye to the problematic FractionalFlow node, but welcome the ContinuousControl as a long requested feature.\n\n\n\nControl: Add ContinuousControl node type. #1602\nControl: Support listening to flow through connector nodes. #1594\nValidate that TabulatedRatingCurve levels are above Basin bottom. #1607\nValidate that Outlet minimum upstream levels are above Basin bottom. #1607\nAlways show convergence bottlenecks. #1636\nDocstrings for Ribasim Python. #1643\nAllocate to UserDemand from directly connected Basin if possible. #1581\nAdd basin_state.arrow results. #1626\nAlso write stacktraces to ribasim.log. #1653\n\n\n\n\n\nRequire QGIS 3.34 (LTR) or newer for Ribasim QGIS plugin.\n\n\n\n\n\nCompatibility with latest NumPy, Pandera and PyArrow releases. #1618\nLevelDemand can now be without min_level or max_level. #1629\n\n\n\n\n\nRemoved unused urban runoff variable from Basin. #1611\nRemoved unneeded static table from Terminal. #1624\nRemoved FractionalFlow node. #1616\n\n\n\n\n\n\n\n\nSupport for concentration state and time for Delwaq coupling.\nShow exact commit on ribasim --version if it is not a release. #1479\n\n\n\n\n\nOptimized performance.\nDocumentation has been overhauled to be more user-friendly.\nStricter TabulatedRatingCurve validation. #1469\nStricter Basin / profile validation. #1486\nAllocation objective function now gives equal ratios during shortage. #1386\n\n\n\n\n\nDon’t require unique node IDs. #1513\nFix QGIS crash on plugin initialization. #1580\n\n\n\n\n\n\n\n\nThere is more validation on the edges. #1434\nIf the model does not converge and the used algorithm supports it, we log which Basins don’t converge. #1440\n\n\n\n\n\nIf negative storages inadvertently happen, we now throw an error. #1425\nUsers of the QGIS plugin need to remove the old version to avoid two copies due to #1453.\n\n\n\n\n\nPerformance improvements have been a focus of this release, giving up to 10x faster runs. #1433, #1436, #1438, #1448, #1457\nThe CLI exe is now always in the root of the zip and makes use of the libribasim shared library. #1415",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "changelog.html#v2024.11.0---2024-10-08",
    "href": "changelog.html#v2024.11.0---2024-10-08",
    "title": "1 Changelog",
    "section": "",
    "text": "This major new release contains many improvements. A new formulation allows much smaller water balance errors, which is combined with several performance improvements. Ribasim Python does more validation that was previously only done in the core. The Ribasim QGIS plugin now sets the relations between tables for easier model inspection. Adding min_upstream_level and max_downstream_level to Pump and Outlet means DiscreteControl is often no longer needed. The most significant breaking change is making the node_id and edge_id the index of the Node and Edge table; these need to be globally unique.\nStarting from this release Ribasim is labeled as beta software. Since development is currently mainly driven by applications in the Dutch water system, we expect that addition work needs to be done for general use outside the Netherlands.\nFor coupled simulation with MODFLOW and/or MetaSWAP, this release is part of the iMOD Coupler, specifically release v2024.4.0\n\n\n\nSupport discrete control based on an external concentration condition. #1660\nAdd results/solver_stats.arrow with solver statistics over time. #1677\nAdd icon to ribasim.exe on Windows. #1712\nSave QGIS styling in the model database. #1713\nAdd Delwaq coupling guide. #1619\nSolver speedup due to backtracking relaxation. #1761\nReject adding a duplicate edge in Python. #1719\nSupport transient UserDemand return factor. #1727\nDocument the interpolation of input data. #1720\nAutomate Jacobian sparsity detection. #1606\nSupport specifying the edge_id as model.edge.add(a, b, edge_id=5). #1737\nUse https://ribasim.org/ to host our documentation. #1736\nValidate geometry types in Python. #1760\nAdd relationships between tables in QGIS. #1755\nSupport migrating from older Ribasim versions in Python. #1764\nAdd quick start guide to docs. #1787\nAdd min_upstream_level and max_downstream_level to Pump and Outlet. #1792\nAdd max_downstream_level to TabulatedRatingCurve. #1795\nValidate edge connections in Python. #1765\nAdd low storage reduction factor to ManningResistance. #1796\n\n\n\n\n\nRefactor of the core to ensure smaller water balance errors. #1819\nMake node_id globally unique. #1717\nMake the Node ID the index of the Node table, and Edge ID for Edge. #1737\nMake more Python functions private. #1702\nPut the contents of the CLI zips in a folder. #1722\nChanged water balance error definition. #1767\nDisallow missing priority parameter when using allocation. #1745\nRename Outlet’s min_crest_level to min_upstream_level. #1788\nOnly allow flow under gravity in TabulatedRatingCurve. #1795\nUse dtype_backend=\"pyarrow\" for Pandas DataFrames. #1781\n\n\n\n\n\nRemove oscillations in ManningResistance. #1750\nFix GeoPandas CRS warning. #1810",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "changelog.html#v2024.10.0---2024-07-23",
    "href": "changelog.html#v2024.10.0---2024-07-23",
    "title": "1 Changelog",
    "section": "",
    "text": "For this release we said goodbye to the problematic FractionalFlow node, but welcome the ContinuousControl as a long requested feature.\n\n\n\nControl: Add ContinuousControl node type. #1602\nControl: Support listening to flow through connector nodes. #1594\nValidate that TabulatedRatingCurve levels are above Basin bottom. #1607\nValidate that Outlet minimum upstream levels are above Basin bottom. #1607\nAlways show convergence bottlenecks. #1636\nDocstrings for Ribasim Python. #1643\nAllocate to UserDemand from directly connected Basin if possible. #1581\nAdd basin_state.arrow results. #1626\nAlso write stacktraces to ribasim.log. #1653\n\n\n\n\n\nRequire QGIS 3.34 (LTR) or newer for Ribasim QGIS plugin.\n\n\n\n\n\nCompatibility with latest NumPy, Pandera and PyArrow releases. #1618\nLevelDemand can now be without min_level or max_level. #1629\n\n\n\n\n\nRemoved unused urban runoff variable from Basin. #1611\nRemoved unneeded static table from Terminal. #1624\nRemoved FractionalFlow node. #1616",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "changelog.html#v2024.9.0---2024-06-20",
    "href": "changelog.html#v2024.9.0---2024-06-20",
    "title": "1 Changelog",
    "section": "",
    "text": "Support for concentration state and time for Delwaq coupling.\nShow exact commit on ribasim --version if it is not a release. #1479\n\n\n\n\n\nOptimized performance.\nDocumentation has been overhauled to be more user-friendly.\nStricter TabulatedRatingCurve validation. #1469\nStricter Basin / profile validation. #1486\nAllocation objective function now gives equal ratios during shortage. #1386\n\n\n\n\n\nDon’t require unique node IDs. #1513\nFix QGIS crash on plugin initialization. #1580",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "changelog.html#v2024.8.0---2024-05-14",
    "href": "changelog.html#v2024.8.0---2024-05-14",
    "title": "1 Changelog",
    "section": "",
    "text": "There is more validation on the edges. #1434\nIf the model does not converge and the used algorithm supports it, we log which Basins don’t converge. #1440\n\n\n\n\n\nIf negative storages inadvertently happen, we now throw an error. #1425\nUsers of the QGIS plugin need to remove the old version to avoid two copies due to #1453.\n\n\n\n\n\nPerformance improvements have been a focus of this release, giving up to 10x faster runs. #1433, #1436, #1438, #1448, #1457\nThe CLI exe is now always in the root of the zip and makes use of the libribasim shared library. #1415",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "dev/core.html",
    "href": "dev/core.html",
    "title": "Julia core development",
    "section": "",
    "text": "The computational core is one of the components of Ribasim as illustrated in the component overview.\nThe computational process can be divided in three phases:\n\nModel initialization\nRunning the simulation loop\nWriting the output files\n\nA more detailed sequence diagram of the simulation loop is available at the core home page.",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/core.html#install-optional-julia-libraries",
    "href": "dev/core.html#install-optional-julia-libraries",
    "title": "Julia core development",
    "section": "2.1 Install optional Julia libraries",
    "text": "2.1 Install optional Julia libraries\nStart the Julia REPL by executing pixi run julia in your terminal. Within the REPL type ] to enter the Pkg REPL. For more information on how to use Pkg, see the Getting Started page in its documentation. There you can add Revise to your global environment.\npkg&gt; add Revise",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/core.html#setup-revise.jl",
    "href": "dev/core.html#setup-revise.jl",
    "title": "Julia core development",
    "section": "2.2 Setup Revise.jl",
    "text": "2.2 Setup Revise.jl\nRevise.jl is a library that allows you to modify code and use the changes without restarting Julia. You can let it start automatically by following these instructions.",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/core.html#install-visual-studio-code-optional",
    "href": "dev/core.html#install-visual-studio-code-optional",
    "title": "Julia core development",
    "section": "2.3 Install Visual Studio Code (optional)",
    "text": "2.3 Install Visual Studio Code (optional)\nThere is a section on editors and IDEs for Julia on https://julialang.org/, scroll down to see it. We use and recommend Microsoft’s free editor Visual Studio Code. When combined with the Julia extension it provides a powerful and interactive development experience.",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/core.html#sec-test",
    "href": "dev/core.html#sec-test",
    "title": "Julia core development",
    "section": "3.1 Running tests",
    "text": "3.1 Running tests\nYou will want to run the testsuite on a regular basis to check if your changes had unexpected side effects. It is also a good way to find out if your development environment is set up correctly.\nBefore the tests can run, you need to prepare model input.\nWith the root of the repository as your working directory you can start the REPL with activated root environment by running the following:\njulia --project\nWhile not technically required, it is advised to import Ribasim first to catch installation issues early on.\njulia&gt; using Ribasim\nThen open the Pkg REPL by typing ] and execute:\npkg&gt; test Ribasim\nIn order to debug tests, you can run individual test items from Visual Studio Code. Click the green play icon in front of a test item, as show in the image below. The first run will be slow.",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/core.html#render-documentation",
    "href": "dev/core.html#render-documentation",
    "title": "Julia core development",
    "section": "3.2 Render documentation",
    "text": "3.2 Render documentation\nExample models are created and simulated as part of the rendering of the documentation.\nIn order to preview documentation you can run the following command from the docs/ folder. Afterwards, a browser tab will open with the rendered documentation, updating it as you make changes.\npixi run quarto-preview\nThe documentation also includes Jupyter notebooks. Note that they are stored in the repository without any output, and this should stay this way to keep the repository small. The documentation rendering process adds the output by running the notebooks.\n\n\n\n\n\n\nTip\n\n\n\nThe Jupyter VS Code extension allows you to run Jupyter notebooks directly in VS Code.",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/core.html#run-ribasim-simulations",
    "href": "dev/core.html#run-ribasim-simulations",
    "title": "Julia core development",
    "section": "3.3 Run Ribasim simulations",
    "text": "3.3 Run Ribasim simulations\nAssuming your working directory is the root of the repository, you can activate this project by entering the Pkg mode of the REPL with ] and execute:\npkg&gt; activate .\npkg&gt; instantiate\nPress backspace to go back to the Julia REPL. There you can run a model with:\njulia&gt; Ribasim.run(\"path/to/model/ribasim.toml\")\n\n\n\n\n\n\nTip\n\n\n\nThe Julia VS Code extension allows you to execute code cells in REPL. This is a very convenient way of executing only parts of your source file.",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/core.html#build-ribasim",
    "href": "dev/core.html#build-ribasim",
    "title": "Julia core development",
    "section": "3.4 Build Ribasim",
    "text": "3.4 Build Ribasim\nThe Ribasim core can be built into an executable with a command line interface (CLI) and a shared library, libribasim. These products will run without a Julia installation. To create both these products at once, run:\npixi run build\nTo verify that the build was successful, you can run both these commands.\npixi run test-ribasim-api\npixi run test-ribasim-cli\nDuring development these steps are normally done on TeamCity, though in some cases it can be more convenient to build locally.",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/qgis.html",
    "href": "dev/qgis.html",
    "title": "QGIS plugin development",
    "section": "",
    "text": "1 Set up the developer environment\nAfter you have installed the environment as described here you must still activate the QGIS plugins. The simplest way to do this is by running pixi run install-qgis-plugins. It grabs the latest version of the iMOD QGIS plugin and it makes a symlink to the ribasim_qgis folder so that QGIS can find it. It also installs plugins that make it possible to reload and debug your plugin while QGIS is open.\n\n\n\n\n\n\nNote\n\n\n\nOn Windows you need to have Developer mode enabled. Otherwise you will not have enough access rights to create symlinks. For more info, see this Windows blog.\nWe wanted to implement this via pip install --editable, but QGIS doesn’t find the metadata.txt and therefore cannot load the plugin on startup.\n\n\n\n\n2 Running QGIS\nIn order to run QGIS with the plugins, simply call pixi run qgis. You will find the Ribasim and iMOD plugins in the tool bars.\n\n\n\n\n\n\nNote\n\n\n\nOn Windows, running QGIS from the start menu will disable Python, and thus the plugins. QGIS needs some more paths during the startup and the Pixi environment provides those.\n\n\n\n\n3 Running tests\nTo run the QGIS plugin tests in the application environment of QGIS, it is best to make use of the Docker environment provided in this repository. Make sure that docker is installed and available in your path.\nThen simply call pixi run test-ribasim-qgis.\n\n\n4 Debugging\nAfter installing the plugins via pixi run install-qgis-plugins. Extra debugging tools are also installed in QGIS that is installed within your pixi environment.\nAfter you have started pixi run qgis, you can make alterations to the Python code and use the Plugin Reloader to reload the plugin without restarting QGIS. The shortcut in QGIS is CTRL+F5.\nIt is also possible to connect the debugger of Visual Studio Code. For this the debugvs plugin is installed in QGIS. In QGIS press the button to Enable Debug for Visual Studio. Then go to Visual Studio Code and start the launch task Ribasim QGIS: Attach to QGIS. Now you can place breakpoints.\n\n\n\n\n\n\nNote\n\n\n\nWe are currently using debugvs 0.7 with ptvsd as service, since there is an open issue that breaks debugvs 0.8 with debugpy.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin development"
    ]
  },
  {
    "objectID": "dev/release.html",
    "href": "dev/release.html",
    "title": "Release process",
    "section": "",
    "text": "The Ribasim repository contains several components, e.g., the Julia core, the Python tooling and QGIS plugin. The components are currently only guaranteed to work together if they have the same version number. Therefore we release Ribasim as a collection of all the components at once, all carrying the same version number. For maximum interoperability it is suggested to only release all components together, and not individually.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#pre-release-checks",
    "href": "dev/release.html#pre-release-checks",
    "title": "Release process",
    "section": "2.1 Pre-release checks",
    "text": "2.1 Pre-release checks\nBefore starting the release process, ensure that all tests are passing and that all features intended for the release are complete and merged into the main branch.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#update-version-numbers-of-the-components",
    "href": "dev/release.html#update-version-numbers-of-the-components",
    "title": "Release process",
    "section": "2.2 Update version numbers of the components",
    "text": "2.2 Update version numbers of the components\nDetermine the new version number like 2023.1.0, filling in the current year, a bumped MINOR number for normal releases and a bumped MICRO number for non-breaking, hotfix releases. This follows YYYY.MINOR.MICRO from calver.\nCreate a branch that starts with release, like release-2023.1.0. It needs to start with release to trigger extra TeamCity checks.\nUpdate the version numbers in the repository to the new version number. See also the latest Ribasim release. Use find and replace to update all locations. Only update the lines in pixi.lock that refer to Ribasim packages, to avoid accidentally changing the version number of dependencies that happen to have the same version number. Don’t change the old version numbers in changelog.qmd.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#update-the-changelog",
    "href": "dev/release.html#update-the-changelog",
    "title": "Release process",
    "section": "2.3 Update the changelog",
    "text": "2.3 Update the changelog\nThe docs/changelog.qmd file, hosted on ribasim.org/changelog, records the most important changes for users. Review the commits since the latest Ribasim release to make sure these are listed. Change the “Unreleased” section to the new version number and date, and create a new empty “Unreleased” section at the top.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#submit-a-pull-request",
    "href": "dev/release.html#submit-a-pull-request",
    "title": "Release process",
    "section": "2.4 Submit a pull request",
    "text": "2.4 Submit a pull request\nNow submit a pull request with the updated the version numbers and changelog.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#create-a-new-release",
    "href": "dev/release.html#create-a-new-release",
    "title": "Release process",
    "section": "2.5 Create a new release",
    "text": "2.5 Create a new release\nWhen the pull request is merged to main, checkout the commit that updates the version numbers.\nCreate a new tag, which is the letter v followed by the version number, like, v2023.8.0.\nThis can be done by executing:\ngit tag &lt;tagname&gt;\nThen push the tags:\ngit push --tags\nThis will trigger a workflow on TeamCity that will publish a new release on GitHub as soon as it is finished. You can follow the progress here. It also auto-generates a changelog. You need to edit that by moving the auto-generated contents, except the “Full Changelog” link, in a collapsed details block as shown below.\n&lt;details&gt;\n&lt;summary&gt;\nAll changes\n&lt;/summary&gt;\n\n# Put GitHub flavored markdown here\n\n&lt;/details&gt;\n\nNow copy the manually edited changelog entry from changelog.qmd above the details, such that the edited changelog can be seen both from our documentation as well as GitHub releases.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#release-the-ribasim-python-packages-to-pypi",
    "href": "dev/release.html#release-the-ribasim-python-packages-to-pypi",
    "title": "Release process",
    "section": "2.6 Release the Ribasim Python packages to PyPI",
    "text": "2.6 Release the Ribasim Python packages to PyPI\nTo be able to install packages with pip, they need to be released on the Python Package Index (PyPI). In order to publish Ribasim Python or Ribasim API follow the following steps:\n\nOpen a terminal and run pixi run publish-ribasim-python\nOpen a terminal and run pixi run publish-ribasim-api",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#qgis-manual-testing",
    "href": "dev/release.html#qgis-manual-testing",
    "title": "Release process",
    "section": "2.7 QGIS manual testing",
    "text": "2.7 QGIS manual testing\nOur continuous integration (CI) should have caught most issues. A current weak spot in our testing is the QGIS plugin, so a manual test plan is in place. Start with running the automated task to see if it can be correctly installed.\n# This test might give a fatal error on the first run, this is most likely a timing issue.\n# Try to run it again when that happens.\npixi run test-ribasim-qgis-ui\nThen follow the instructions as described in the QGIS manual test plan.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#announce-release",
    "href": "dev/release.html#announce-release",
    "title": "Release process",
    "section": "2.8 Announce release",
    "text": "2.8 Announce release\nAnnounce the release in appropriate channels. Include a link to the release notes and assets, which is whatever this resolves to at that time. Also include a link to the documentation.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/index.html",
    "href": "dev/index.html",
    "title": "Contributing",
    "section": "",
    "text": "Ribasim welcomes contributions.\nThere is developer documentation for the Julia core, the Basic Model Interface (BMI), Python tooling, and the QGIS plugin. A guide on how to add a new node type to both is written in adding node types. Release process describes the steps to follow when creating a new Ribasim release.",
    "crumbs": [
      "Contributing"
    ]
  },
  {
    "objectID": "dev/index.html#clone-ribasim",
    "href": "dev/index.html#clone-ribasim",
    "title": "Contributing",
    "section": "1.1 Clone Ribasim",
    "text": "1.1 Clone Ribasim\nIn order to have the Ribasim repository locally available, you can clone it with Git. Git can be installed from git-scm.com. Once installed, run the following command at a directory of your choice:\nIn order to have the Ribasim repository locally available, run the following command at a directory of your choice:\ngit clone https://github.com/Deltares/Ribasim.git\nTo continue with the following steps, make the root of the repository your working directory by running\ncd Ribasim",
    "crumbs": [
      "Contributing"
    ]
  },
  {
    "objectID": "dev/index.html#setting-up-pixi",
    "href": "dev/index.html#setting-up-pixi",
    "title": "Contributing",
    "section": "1.2 Setting up pixi",
    "text": "1.2 Setting up pixi\nFirst, set up pixi as described on their getting started page.\nThen set up the environment by running the following commands:\npixi run install\nThis will automatically install all required packages for development. Our pixi environment also provides an instance of Julia and QGIS. These will not conflict with any pre-installed applications, as long as you have the pixi environment enabled. You can do this in a terminal by calling pixi shell, or starting programs with pixi run julia, or pixi run qgis. Visual Studio Code will locate the pixi environments; select ('dev': Pixi) once such that all developer tools are available. Unless the setting python.terminal.activateEnvironment is disabled, it will already activate the environment in your terminal.",
    "crumbs": [
      "Contributing"
    ]
  },
  {
    "objectID": "dev/bmi.html",
    "href": "dev/bmi.html",
    "title": "1 Basic Model Interface (BMI)",
    "section": "",
    "text": "For runtime data exchange and coupling with other kernels, the Julia kernel is wrapped in a Python API (ribasim_api) which implements the Basic Modelling Interface BMI.\n\n\nThe following functions are available to interact with the Ribasim model”\n\n\n\n\n\n\n\nsignature\ndescription\n\n\n\n\ninitialize(config_path)\nInitialize a model from the path to the TOML configuration file\n\n\nfinalize()\nWrite all results to the configured files\n\n\nget_current_time()\nGet the current time of the Ribasim simulation\n\n\nget_end_time()\nGet the final time of the Ribasim simulation in seconds\n\n\nget_start_time()\nGet the start time of the Ribasim simulation (0.0)\n\n\nget_time_step()\nGet the proposed next internal Ribasim timestep\n\n\nget_time_units()\nGet the time unit (s)\n\n\nget_value_ptr(string)\nGet the pointer to a Ribasim internal array (see below)\n\n\nupdate()\nPerform a Ribasim internal time step\n\n\nupdate_until(time)\nSet Ribasim internal timesteps until the specified time\n\n\n\nDepending on what is specified in the Ribasim TOML configuration file, Ribasim can internally have adaptive (non-constant) timesteps. update_until will always try to progress the Ribasim simulation to exactly the time specified. This however can fail for algorithms that only support a fixed timestep if that timestep does not fit into the interval until the specified time an integer amount of times.\n\n\n\nThe following pointers to memory containing Ribasim internal arrays are given via the BMI using get_value_ptr(string):\n\n\n\n\n\n\n\n\n\n\n\n\nstring\nmeaning\ntype\nunit\ntemporal type\nwritable\nsorted by\n\n\n\n\nbasin.storage\nstorage per basin\nFloat64\n\\(m^3\\)\ninstantaneous\nno\nbasin node ID\n\n\nbasin.level\nlevel per basin\nFloat64\n\\(m\\)\ninstantaneous\nno\nbasin node ID\n\n\nbasin.infiltration\ninfiltration flux per basin\nFloat64\n\\(m^3 s^{-1}\\)\nforward fill\nyes\nbasin node ID\n\n\nbasin.drainage\ndrainage flux per basin\nFloat64\n\\(m^3 s^{-1}\\)\nforward fill\nyes\nbasin node ID\n\n\nbasin.infiltration_integrated\ncumulative infiltration per basin\nFloat64\n\\(m^3\\)\nintegrated from start\nyes\nbasin node ID\n\n\nbasin.drainage_integrated\ncumulative drainage per basin\nFloat64\n\\(m^3\\)\nintegrated from start\nyes\nbasin node ID\n\n\nbasin.subgrid_level\nsubgrid level\nFloat64\n\\(m\\)\ninstantaneous\nno\nsubgrid ID\n\n\nuser_demand.demand\ndemand per node ID per priority\nFloat64\n\\(m^3 s^{-1}\\)\nforward fill\nyes\nuser_demand node ID, priority index\n\n\nuser_demand.realized\ncumulative intake flow per user\nFloat64\n\\(m^3\\)\nintegrated from start\nyes\nuser_demand node ID\n\n\n\nAdditional notes:\n\nuser_demand.demand yields the only 2D array, the other arrays are 1D. This array is indexed as (node_idx, priority_idx) in Julia, which stores arrays column-major\nThe index of e.g. basins and user demand nodes needs to be inferred from the Ribasim input. The same holds for priority_idx, which is global over all subnetworks\nThe data being writable means that Ribasim takes into account the possibility that the data is updated outiside the Ribasim core\nAlthough the *_integrated and *_realized data is writable, this doesn’t affect the Ribasim simulation. This integrated data is only computed for the BMI, and can be set to \\(0\\) via the BMI to avoid accuracy problems when the values get too large.\nDifferent from what is exposed via the BMI, the basin forcings and realized user demands are averaged over the allocation timestep and saveat interval respectively.",
    "crumbs": [
      "Contributing",
      "Basic Model Interface (BMI)"
    ]
  },
  {
    "objectID": "dev/bmi.html#functions",
    "href": "dev/bmi.html#functions",
    "title": "1 Basic Model Interface (BMI)",
    "section": "",
    "text": "The following functions are available to interact with the Ribasim model”\n\n\n\n\n\n\n\nsignature\ndescription\n\n\n\n\ninitialize(config_path)\nInitialize a model from the path to the TOML configuration file\n\n\nfinalize()\nWrite all results to the configured files\n\n\nget_current_time()\nGet the current time of the Ribasim simulation\n\n\nget_end_time()\nGet the final time of the Ribasim simulation in seconds\n\n\nget_start_time()\nGet the start time of the Ribasim simulation (0.0)\n\n\nget_time_step()\nGet the proposed next internal Ribasim timestep\n\n\nget_time_units()\nGet the time unit (s)\n\n\nget_value_ptr(string)\nGet the pointer to a Ribasim internal array (see below)\n\n\nupdate()\nPerform a Ribasim internal time step\n\n\nupdate_until(time)\nSet Ribasim internal timesteps until the specified time\n\n\n\nDepending on what is specified in the Ribasim TOML configuration file, Ribasim can internally have adaptive (non-constant) timesteps. update_until will always try to progress the Ribasim simulation to exactly the time specified. This however can fail for algorithms that only support a fixed timestep if that timestep does not fit into the interval until the specified time an integer amount of times.",
    "crumbs": [
      "Contributing",
      "Basic Model Interface (BMI)"
    ]
  },
  {
    "objectID": "dev/bmi.html#memory-pointers",
    "href": "dev/bmi.html#memory-pointers",
    "title": "1 Basic Model Interface (BMI)",
    "section": "",
    "text": "The following pointers to memory containing Ribasim internal arrays are given via the BMI using get_value_ptr(string):\n\n\n\n\n\n\n\n\n\n\n\n\nstring\nmeaning\ntype\nunit\ntemporal type\nwritable\nsorted by\n\n\n\n\nbasin.storage\nstorage per basin\nFloat64\n\\(m^3\\)\ninstantaneous\nno\nbasin node ID\n\n\nbasin.level\nlevel per basin\nFloat64\n\\(m\\)\ninstantaneous\nno\nbasin node ID\n\n\nbasin.infiltration\ninfiltration flux per basin\nFloat64\n\\(m^3 s^{-1}\\)\nforward fill\nyes\nbasin node ID\n\n\nbasin.drainage\ndrainage flux per basin\nFloat64\n\\(m^3 s^{-1}\\)\nforward fill\nyes\nbasin node ID\n\n\nbasin.infiltration_integrated\ncumulative infiltration per basin\nFloat64\n\\(m^3\\)\nintegrated from start\nyes\nbasin node ID\n\n\nbasin.drainage_integrated\ncumulative drainage per basin\nFloat64\n\\(m^3\\)\nintegrated from start\nyes\nbasin node ID\n\n\nbasin.subgrid_level\nsubgrid level\nFloat64\n\\(m\\)\ninstantaneous\nno\nsubgrid ID\n\n\nuser_demand.demand\ndemand per node ID per priority\nFloat64\n\\(m^3 s^{-1}\\)\nforward fill\nyes\nuser_demand node ID, priority index\n\n\nuser_demand.realized\ncumulative intake flow per user\nFloat64\n\\(m^3\\)\nintegrated from start\nyes\nuser_demand node ID\n\n\n\nAdditional notes:\n\nuser_demand.demand yields the only 2D array, the other arrays are 1D. This array is indexed as (node_idx, priority_idx) in Julia, which stores arrays column-major\nThe index of e.g. basins and user demand nodes needs to be inferred from the Ribasim input. The same holds for priority_idx, which is global over all subnetworks\nThe data being writable means that Ribasim takes into account the possibility that the data is updated outiside the Ribasim core\nAlthough the *_integrated and *_realized data is writable, this doesn’t affect the Ribasim simulation. This integrated data is only computed for the BMI, and can be set to \\(0\\) via the BMI to avoid accuracy problems when the values get too large.\nDifferent from what is exposed via the BMI, the basin forcings and realized user demands are averaged over the allocation timestep and saveat interval respectively.",
    "crumbs": [
      "Contributing",
      "Basic Model Interface (BMI)"
    ]
  },
  {
    "objectID": "known_issues.html",
    "href": "known_issues.html",
    "title": "Known Issues",
    "section": "",
    "text": "Known issues can be found on the GitHub issues page. Besides the issues that need to be fixed, there are also considerations that had to be made while developing the application.\n\n1 QGIS Plugin Known Shortcomings\n\nThe QGIS plugin does not have a dynamic relation between its own plugin and the layers that are loaded in the QGIS project. That means that deleting a layer from the layers panel does not automatically remove it from the GeoPackage, as the layers are clones.\nTables and geometries are not linked. If you remove an edge or a node, the tables containing information about those objects will remain. It is up to the user to clean up all tables.\nThe QGIS plugin does not update edges when nodes are moved. Snapping is only used to grab the information of the node the user points to.",
    "crumbs": [
      "Overview",
      "Known Issues"
    ]
  },
  {
    "objectID": "tutorial/irrigation-demand.html",
    "href": "tutorial/irrigation-demand.html",
    "title": "Irrigation demand",
    "section": "",
    "text": "from pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport plotly.express as px\nfrom ribasim import Model, Node\nfrom ribasim.nodes import (\n    basin,\n    flow_boundary,\n    tabulated_rating_curve,\n    user_demand,\n)\nfrom shapely.geometry import Point\nbase_dir = Path(\"crystal-basin\")\n\nstarttime = \"2022-01-01\"\nendtime = \"2023-01-01\"\nmodel = Model(\n    starttime=starttime,\n    endtime=endtime,\n    crs=\"EPSG:4326\",\n)\nThese nodes are identical to the previous tutorial:\n# FlowBoundary\ndata = pd.DataFrame({\n    \"time\": pd.date_range(start=\"2022-01-01\", end=\"2023-01-01\", freq=\"MS\"),\n    \"main\": [74.7, 57.9, 63.2, 183.9, 91.8, 47.5, 32.6, 27.6, 26.5, 25.1, 39.3, 37.8, 57.9],\n    \"minor\": [16.3, 3.8, 3.0, 37.6, 18.2, 11.1, 12.9, 12.2, 11.2, 10.8, 15.1, 14.3, 11.8]\n})  # fmt: skip\ndata[\"total\"] = data[\"minor\"] + data[\"main\"]\nmain = model.flow_boundary.add(\n    Node(1, Point(0.0, 0.0), name=\"main\"),\n    [\n        flow_boundary.Time(\n            time=data.time,\n            flow_rate=data.main,\n        )\n    ],\n)\nminor = model.flow_boundary.add(\n    Node(2, Point(-3.0, 0.0), name=\"minor\"),\n    [\n        flow_boundary.Time(\n            time=data.time,\n            flow_rate=data.minor,\n        )\n    ],\n)\n\n# Basin\nconfluence = model.basin.add(\n    Node(3, Point(-1.5, -1), name=\"confluence\"),\n    [\n        basin.Profile(area=[672000, 5600000], level=[0, 6]),\n        basin.State(level=[4]),\n        basin.Time(time=[starttime, endtime]),\n    ],\n)\n\n# TabulatedRatingCurve\nweir = model.tabulated_rating_curve.add(\n    Node(4, Point(-1.5, -1.5), name=\"weir\"),\n    [\n        tabulated_rating_curve.Static(\n            level=[0.0, 2, 5],\n            flow_rate=[0.0, 50, 200],\n        )\n    ],\n)\n\n# Terminal\nsea = model.terminal.add(Node(5, Point(-1.5, -3.0), name=\"sea\"))",
    "crumbs": [
      "Tutorials",
      "Irrigation demand"
    ]
  },
  {
    "objectID": "tutorial/irrigation-demand.html#irrigation-demand",
    "href": "tutorial/irrigation-demand.html#irrigation-demand",
    "title": "Irrigation demand",
    "section": "1 Irrigation demand",
    "text": "1 Irrigation demand\nLet us modify the environment to include agricultural activities within the basin, which necessitate irrigation. Water is diverted from the main river through an irrigation canal, with a portion of it eventually returning to the main river (see Figure 1).\n\n\n\n\n\n\nFigure 1: Crystal basin with irrigation\n\n\n\nFor this schematization update, we need to incorporate three additional nodes:\n\nBasin: Represents a cross-sectional point where water is diverted.\nUserDemand: Represents the irrigation demand.\nTabulatedRatingCurve: Defines the remaining water flow from the main river at the diversion point.\n\n\n1.1 Add a second Basin node\nThis Basin will portray as the point in the river where the diversion takes place, getting the name diversion. Its profile area at this intersection is slightly smaller than at the confluence.\n\ndiversion_basin = model.basin.add(\n    Node(6, Point(-0.75, -0.5), name=\"diversion_basin\"),\n    [\n        basin.Profile(area=[500000, 5000000], level=[0, 6]),\n        basin.State(level=[3]),\n        basin.Time(time=[starttime, endtime]),\n    ],\n)\n\n\n\n1.2 Add the irrigation demand\nAn irrigation district needs to apply irrigation to its field starting from April to September. The irrigated area is \\(&gt; 17000 \\text{ ha}\\) and requires around \\(5 \\text{ mm/day}\\). In this case the irrigation district diverts from the main river an average flow rate of \\(10 \\text{ m}^3/\\text{s}\\) and \\(12 \\text{ m}^3/\\text{s}\\) during spring and summer, respectively. Start of irrigation takes place on the 1st of April until the end of August. The water intake is through a canal (demand).\nFor now, let’s assume the return flow remains \\(0.0\\) (return_factor). Meaning all the supplied water to fulfill the demand is consumed and does not return back to the river. The user demand node interpolates the demand values. Thus the following code needs to be implemented:\n\nirrigation = model.user_demand.add(\n    Node(7, Point(-1.5, 0.5), name=\"irrigation\"),\n    [\n        user_demand.Time(\n            demand=[0.0, 0.0, 10, 12, 12, 0.0],\n            return_factor=0,\n            min_level=0,\n            priority=1,\n            time=[\n                starttime,\n                \"2022-03-31\",\n                \"2022-04-01\",\n                \"2022-07-01\",\n                \"2022-09-30\",\n                \"2022-10-01\",\n            ],\n        )\n    ],\n)\n\n\n\n1.3 Add a TabulatedRatingCurve\nThe second TabulatedRatingCurve node will simulate the rest of the water that is left after diverting a part from the main river to the irrigation disctrict. The rest of the water will flow naturally towards the confluence:\n\ndiversion_weir = model.tabulated_rating_curve.add(\n    Node(8, Point(-1.125, -0.75), name=\"diversion_weir\"),\n    [\n        tabulated_rating_curve.Static(\n            level=[0.0, 1.5, 5],\n            flow_rate=[0.0, 45, 200],\n        )\n    ],\n)\n\n\n\n1.4 Add edges\n\nmodel.edge.add(main, diversion_basin, name=\"main\")\nmodel.edge.add(minor, confluence, name=\"minor\")\nmodel.edge.add(diversion_basin, irrigation, name=\"irrigation\")\nmodel.edge.add(irrigation, confluence)\nmodel.edge.add(diversion_basin, diversion_weir, name=\"not diverted\")\nmodel.edge.add(diversion_weir, confluence)\nmodel.edge.add(confluence, weir)\nmodel.edge.add(weir, sea, name=\"sea\")\n\n\ntoml_path = base_dir / \"Crystal-2/ribasim.toml\"\nmodel.write(toml_path)\ncli_path = \"ribasim\"\n\n\n\n1.5 Plot model and run\nPlot the schematization and run the model. This time the new outputs should be written in a new folder called Crystal-2:\n\nmodel.plot();\n\n\n\n\n\n\n\n\n\n\n1.6 Plot and compare the Basin results\nPlot the simulated levels and storages at the diverted section and at the confluence.\n\ndf_basin = pd.read_feather(\n    base_dir / \"Crystal-2/results/basin.arrow\", dtype_backend=\"pyarrow\"\n)\n\n# Create pivot tables and plot for basin data\ndf_basin_wide = df_basin.pivot_table(\n    index=\"time\", columns=\"node_id\", values=[\"storage\", \"level\"]\n)\n\ndf_basin_div = df_basin_wide.loc[:, pd.IndexSlice[:, diversion_basin.node_id]]\ndf_basin_conf = df_basin_wide.loc[:, pd.IndexSlice[:, confluence.node_id]]\n\n\ndef plot_basin_data(\n    ax, ax_twin, df_basin, level_color=\"b\", storage_color=\"r\", title=\"Basin\"\n):\n    # Plot level data\n    for column in df_basin[\"level\"].columns:\n        ax.plot(\n            df_basin.index,\n            df_basin[\"level\"][column],\n            linestyle=\"-\",\n            color=level_color,\n            label=f\"Level - {column}\",\n        )\n\n    # Plot storage data\n    for column in df_basin[\"storage\"].columns:\n        ax_twin.plot(\n            df_basin.index,\n            df_basin[\"storage\"][column],\n            linestyle=\"--\",\n            color=storage_color,\n            label=f\"Storage - {column}\",\n        )\n\n    ax.set_ylabel(\"Level [m]\", color=level_color)\n    ax_twin.set_ylabel(\"Storage [m³]\", color=storage_color)\n\n    ax.tick_params(axis=\"y\", labelcolor=level_color)\n    ax_twin.tick_params(axis=\"y\", labelcolor=storage_color)\n\n    ax.set_title(title)\n\n    # Combine legends from both axes\n    lines, labels = ax.get_legend_handles_labels()\n    lines_twin, labels_twin = ax_twin.get_legend_handles_labels()\n    ax.legend(lines + lines_twin, labels + labels_twin, loc=\"upper left\")\n\n\n# Create subplots\nfig, (ax1, ax3) = plt.subplots(2, 1, figsize=(12, 12), sharex=True)\n\n# Plot Div basin data\nax2 = ax1.twinx()  # Secondary y-axis for storage\nplot_basin_data(ax1, ax2, df_basin_div, title=\"Diversion Basin level and storage\")\n\n# Plot Conf basin data\nax4 = ax3.twinx()  # Secondary y-axis for storage\nplot_basin_data(ax3, ax4, df_basin_conf, title=\"Confluence Basin level and storage\")\n\n# Common X label\nax3.set_xlabel(\"Time\")\nfig.tight_layout()  # Adjust layout to fit labels\nplt.show()\n\n\n\n\n\n\n\n\nThe figure above illustrates the water levels and storage capacities for each Basin.\nWhen compared to the natural flow conditions, where no water is abstracted for irrigation (See Crystal 1), there is a noticeable decrease in both storage and water levels at the confluence downstream. This reduction is attributed to the irrigation demand upstream with no return flow, which decreases the amount of available water in the main river, resulting in lower water levels at the confluence.\n\n\n1.7 Plot and compare the flow results\nPlot the flow results in an interactive plotting tool.\n\ndf_flow = pd.read_feather(\n    base_dir / \"Crystal-2/results/flow.arrow\", dtype_backend=\"pyarrow\"\n)\n# Add the edge names and then remove unnamed edges\ndf_flow[\"name\"] = model.edge.df[\"name\"].loc[df_flow[\"edge_id\"]].to_numpy()\ndf_flow = df_flow[df_flow[\"name\"].astype(bool)]\n\n# Plot the flow data, interactive plot with Plotly\npivot_flow = df_flow.pivot_table(\n    index=\"time\", columns=\"name\", values=\"flow_rate\"\n).reset_index()\nfig = px.line(pivot_flow, x=\"time\", y=pivot_flow.columns[1:], title=\"Flow [m3/s]\")\n\nfig.update_layout(legend_title_text=\"Edge\")\nfig.show()\n\n                                                \n\n\nTry toggling the edges on and off by clicking on them in the edges.",
    "crumbs": [
      "Tutorials",
      "Irrigation demand"
    ]
  },
  {
    "objectID": "guide/coupling.html",
    "href": "guide/coupling.html",
    "title": "Coupling",
    "section": "",
    "text": "Ribasim can also be (online) coupled to other kernels with the help of iMOD Coupler. The corresponding documentation can be found within the iMOD Suite Documentation.",
    "crumbs": [
      "How-to guides",
      "Coupling"
    ]
  },
  {
    "objectID": "guide/coupling.html#setup",
    "href": "guide/coupling.html#setup",
    "title": "Coupling",
    "section": "2.1 Setup",
    "text": "2.1 Setup\nDelwaq can calculate the concentration of substances in Basin nodes over time, based on initial concentrations, and of FlowBoundary nodes. Ribasim exposes the Basin / concentration, Basin / concentration_state, FlowBoundary / concentration, and LevelBoundary / concentration tables to setup these substances and concentrations.\nWhen a Ribasim model ran with the above tables, one can use the utilities in the delwaq namespace of the Ribasim Python API to generate the input required for Delwaq to run, as well as to parse the output from Delwaq into a Ribasim compatible format. For more information see the guide.",
    "crumbs": [
      "How-to guides",
      "Coupling"
    ]
  },
  {
    "objectID": "guide/delwaq.html",
    "href": "guide/delwaq.html",
    "title": "Ribasim Delwaq coupling",
    "section": "",
    "text": "In order to generate the Delwaq input files, we need a completed Ribasim simulation (typically one with a results folder) that ideally also includes some substances and initial concentrations. Let’s take the basic test model for example, which already has set some initial concentrations.\nAll testmodels can be downloaded from here.\nfrom pathlib import Path\n\ntoml_path = Path(\"../../generated_testmodels/basic/ribasim.toml\")\n\nassert toml_path.is_file()\nThis Ribasim model already has substance concentrations for Cl and Tracer in the input tables, and we will use these to generate the Delwaq input files.\nfrom ribasim import Model\n\nmodel = Model.read(toml_path)\n\ndisplay(model.basin.concentration_state)  # basin initial state\ndisplay(model.basin.concentration)  # basin boundaries\ndisplay(model.flow_boundary.concentration)  # flow boundaries\ndisplay(model.level_boundary.concentration)  # level boundaries\nmodel.plot();  # for later comparison\n\nBasin / concentration_state\n\n\n\n\n\n\nnode_id\nsubstance\nconcentration\n\n\nfid\n\n\n\n\n\n\n\n0\n1\nCl\n0.0\n\n\n1\n3\nCl\n0.0\n\n\n2\n6\nCl\n0.0\n\n\n3\n9\nCl\n0.0\n\n\n\n\n\n\n\nBasin / concentration\n\n\n\n\n\n\nnode_id\ntime\nsubstance\ndrainage\nprecipitation\n\n\nfid\n\n\n\n\n\n\n\n\n\n0\n1\n2020-01-01 00:00:00\nCl\n0.0\n0.0\n\n\n1\n1\n2020-01-02 00:00:00\nCl\n1.0\n1.0\n\n\n2\n1\n2020-01-01 00:00:00\nTracer\n1.0\n1.0\n\n\n3\n3\n2020-01-01 00:00:00\nCl\n0.0\n0.0\n\n\n4\n3\n2020-01-02 00:00:00\nCl\n1.0\n1.0\n\n\n5\n3\n2020-01-01 00:00:00\nTracer\n1.0\n1.0\n\n\n6\n6\n2020-01-01 00:00:00\nCl\n0.0\n0.0\n\n\n7\n6\n2020-01-02 00:00:00\nCl\n1.0\n1.0\n\n\n8\n6\n2020-01-01 00:00:00\nTracer\n1.0\n1.0\n\n\n9\n9\n2020-01-01 00:00:00\nCl\n0.0\n0.0\n\n\n10\n9\n2020-01-02 00:00:00\nCl\n1.0\n1.0\n\n\n11\n9\n2020-01-01 00:00:00\nTracer\n1.0\n1.0\n\n\n\n\n\n\n\nFlowBoundary / concentration\n\n\n\n\n\n\nnode_id\ntime\nsubstance\nconcentration\n\n\nfid\n\n\n\n\n\n\n\n\n0\n15\n2020-01-01 00:00:00\nCl\n0.0\n\n\n1\n15\n2020-01-01 00:00:00\nTracer\n1.0\n\n\n2\n16\n2020-01-01 00:00:00\nCl\n0.0\n\n\n3\n16\n2020-01-01 00:00:00\nTracer\n1.0\n\n\n\n\n\n\n\nLevelBoundary / concentration\n\n\n\n\n\n\nnode_id\ntime\nsubstance\nconcentration\n\n\nfid\n\n\n\n\n\n\n\n\n0\n11\n2020-01-01 00:00:00\nCl\n34.0\n\n\n1\n17\n2020-01-01 00:00:00\nCl\n34.0\nmodel.basin.profile\n\nBasin / profile\n\n\n\n\n\n\nnode_id\narea\nlevel\n\n\nfid\n\n\n\n\n\n\n\n0\n1\n0.01\n0.0\n\n\n1\n1\n1000.0\n1.0\n\n\n2\n3\n0.01\n0.0\n\n\n3\n3\n1000.0\n1.0\n\n\n4\n6\n0.01\n0.0\n\n\n5\n6\n1000.0\n1.0\n\n\n6\n9\n0.01\n0.0\n\n\n7\n9\n1000.0\n1.0\nLet’s add another tracer to the model, to setup a fraction calculation.\nfrom ribasim.delwaq import add_tracer\n\nadd_tracer(model, 11, \"Foo\")\nadd_tracer(model, 15, \"Bar\")\ndisplay(model.flow_boundary.concentration)  # flow boundaries\ndisplay(model.level_boundary.concentration)  # flow boundaries\n\nmodel.write(toml_path)\n\nFlowBoundary / concentration\n\n\n\n\n\n\nnode_id\ntime\nsubstance\nconcentration\n\n\nfid\n\n\n\n\n\n\n\n\n0\n15\n2020-01-01 00:00:00\nCl\n0.0\n\n\n1\n15\n2020-01-01 00:00:00\nTracer\n1.0\n\n\n2\n16\n2020-01-01 00:00:00\nCl\n0.0\n\n\n3\n16\n2020-01-01 00:00:00\nTracer\n1.0\n\n\n4\n15\n2020-01-01 00:00:00\nBar\n1.0\n\n\n\n\n\n\n\nLevelBoundary / concentration\n\n\n\n\n\n\nnode_id\ntime\nsubstance\nconcentration\n\n\nfid\n\n\n\n\n\n\n\n\n0\n11\n2020-01-01 00:00:00\nCl\n34.0\n\n\n1\n17\n2020-01-01 00:00:00\nCl\n34.0\n\n\n2\n11\n2020-01-01 00:00:00\nFoo\n1.0\n\n\n\n\n\n\n\nPosixPath('../../generated_testmodels/basic/ribasim.toml')\nGiven the path to a completed Ribasim simulation, we can call ribasim.delwaq.generate for generating the required input files for Delwaq from scratch.\nfrom ribasim.delwaq import generate\n\noutput_path = Path(\"../../generated_testmodels/basic/delwaq\")\n\ngraph, substances = generate(toml_path, output_path)\nThis call produces a handful of files in the user defined folder. Let’s take a look at them:\nlist(output_path.iterdir())\n\n[PosixPath('../../generated_testmodels/basic/delwaq/ribasim.vol'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim_bndlist.inc'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim.atr'),\n PosixPath('../../generated_testmodels/basic/delwaq/flows.csv'),\n PosixPath('../../generated_testmodels/basic/delwaq/delwaq.inp'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim.are'),\n PosixPath('../../generated_testmodels/basic/delwaq/B5_bounddata.inc'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim.nc'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim.vel'),\n PosixPath('../../generated_testmodels/basic/delwaq/volumes.csv'),\n PosixPath('../../generated_testmodels/basic/delwaq/dimr_config.xml'),\n PosixPath('../../generated_testmodels/basic/delwaq/network.csv'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim.flo'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim.len'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim.poi')]\nThese files form a complete Delwaq simulation, and can be run by either pointing DIMR to the dimr_config.xml file or pointing Delwaq to the delwaq.inp file.\nNote that the call to generate produces two output variables; graph and substances that are required for parsing the results of the Delwaq model later on. Nonetheless, we can also inspect them here, and inspect the created Delwaq network.\nsubstances  # list of substances, as will be present in the Delwaq netcdf output\n\n{'Bar',\n 'Cl',\n 'Continuity',\n 'Drainage',\n 'FlowBoundary',\n 'Foo',\n 'Initial',\n 'LevelBoundary',\n 'Precipitation',\n 'Terminal',\n 'Tracer',\n 'UserDemand'}\nAs you can see, the complete substances list is a combination of user input (Cl and Tracer in the input tables), a Continuity tracer, and tracers for all nodetypes in the Ribasim model. The latter tracers allow for deeper inspection of the Ribasim model, such as debugging the mass balance by plotting fraction graphs. Let’s inspect the graph next, which is the Delwaq network that was created from the Ribasim model:\nimport matplotlib.pyplot as plt\nimport networkx as nx\n\n# Let's draw the graph\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\nnx.draw(\n    graph,\n    pos={k: v[\"pos\"] for k, v in graph.nodes(data=True)},\n    with_labels=True,\n    labels={k: k for k, v in graph.nodes(data=True)},\n    ax=ax[0],\n)\nax[0].set_title(\"Delwaq node IDs\")\nnx.draw(\n    graph,\n    pos={k: v[\"pos\"] for k, v in graph.nodes(data=True)},\n    with_labels=True,\n    labels={k: v[\"id\"] for k, v in graph.nodes(data=True)},\n    ax=ax[1],\n)\nax[1].set_title(\"Ribasim node IDs\")\nfig.suptitle(\"Delwaq network\");\nHere we plotted the Delwaq network twice, with the node IDs as used by Delwaq on the left hand side, and the corresponding Ribasim node IDs on the right hand side. As you can see, the Delwaq network is very similar to the Ribasim network, with some notable changes:",
    "crumbs": [
      "How-to guides",
      "Coupling guides",
      "Ribasim Delwaq coupling"
    ]
  },
  {
    "objectID": "guide/delwaq.html#parsing-the-results",
    "href": "guide/delwaq.html#parsing-the-results",
    "title": "Ribasim Delwaq coupling",
    "section": "1 Parsing the results",
    "text": "1 Parsing the results\nWith Delwaq having run, we can now parse the results using ribasim.delwaq.parse. This function requires the graph and substances variables that were output by ribasim.delwaq.generate, as well as the path to the results folder of the Delwaq simulation.\n\nfrom ribasim.delwaq import parse\n\nnmodel = parse(toml_path, graph, substances, output_folder=output_path)\n\nThe parsed model is identical to the Ribasim model, with the exception of the added concentration_external table that contains all tracer results from Delwaq.\n\ndisplay(nmodel.basin.concentration_external)\nprint(substances)\nt = nmodel.basin.concentration_external.df\nt[t.time == t.time.unique()[2]]\n\nBasin / concentration_external\n\n\n\n\n\n\ntime\nnode_id\nconcentration\nsubstance\n\n\nfid\n\n\n\n\n\n\n\n\n0\n2020-01-01 00:00:00\n1\n0.0\nCl\n\n\n1464\n2020-01-01 00:00:00\n1\n1.0\nInitial\n\n\n2928\n2020-01-01 00:00:00\n1\n1.0\nContinuity\n\n\n4392\n2020-01-01 00:00:00\n1\n0.0\nFoo\n\n\n5856\n2020-01-01 00:00:00\n1\n0.0\nLevelBoundary\n\n\n...\n...\n...\n...\n...\n\n\n11711\n2020-12-31 00:00:00\n9\n0.971058\nTracer\n\n\n13175\n2020-12-31 00:00:00\n9\n0.0\nUserDemand\n\n\n14639\n2020-12-31 00:00:00\n9\n0.0\nDrainage\n\n\n16103\n2020-12-31 00:00:00\n9\n0.328267\nPrecipitation\n\n\n17567\n2020-12-31 00:00:00\n9\n0.642792\nFlowBoundary\n\n\n\n\n17568 rows × 4 columns\n\n\n\n{'Cl', 'Initial', 'Continuity', 'Foo', 'LevelBoundary', 'Bar', 'Terminal', 'Tracer', 'UserDemand', 'Drainage', 'Precipitation', 'FlowBoundary'}\n\n\n\n\n\n\n\n\n\ntime\nnode_id\nconcentration\nsubstance\n\n\nfid\n\n\n\n\n\n\n\n\n8\n2020-01-03 00:00:00\n1\n11.312317\nCl\n\n\n1472\n2020-01-03 00:00:00\n1\n0.034849\nInitial\n\n\n2936\n2020-01-03 00:00:00\n1\n1.0\nContinuity\n\n\n4400\n2020-01-03 00:00:00\n1\n0.231711\nFoo\n\n\n5864\n2020-01-03 00:00:00\n1\n0.332715\nLevelBoundary\n\n\n7328\n2020-01-03 00:00:00\n1\n0.044192\nBar\n\n\n8792\n2020-01-03 00:00:00\n1\n0.0\nTerminal\n\n\n10256\n2020-01-03 00:00:00\n1\n0.632436\nTracer\n\n\n11720\n2020-01-03 00:00:00\n1\n0.0\nUserDemand\n\n\n13184\n2020-01-03 00:00:00\n1\n0.0\nDrainage\n\n\n14648\n2020-01-03 00:00:00\n1\n0.146194\nPrecipitation\n\n\n16112\n2020-01-03 00:00:00\n1\n0.486242\nFlowBoundary\n\n\n9\n2020-01-03 00:00:00\n3\n22.043247\nCl\n\n\n1473\n2020-01-03 00:00:00\n3\n0.024916\nInitial\n\n\n2937\n2020-01-03 00:00:00\n3\n1.0\nContinuity\n\n\n4401\n2020-01-03 00:00:00\n3\n0.488448\nFoo\n\n\n5865\n2020-01-03 00:00:00\n3\n0.648331\nLevelBoundary\n\n\n7329\n2020-01-03 00:00:00\n3\n0.093191\nBar\n\n\n8793\n2020-01-03 00:00:00\n3\n0.0\nTerminal\n\n\n10257\n2020-01-03 00:00:00\n3\n0.326753\nTracer\n\n\n11721\n2020-01-03 00:00:00\n3\n0.0\nUserDemand\n\n\n13185\n2020-01-03 00:00:00\n3\n0.0\nDrainage\n\n\n14649\n2020-01-03 00:00:00\n3\n0.119581\nPrecipitation\n\n\n16113\n2020-01-03 00:00:00\n3\n0.207172\nFlowBoundary\n\n\n10\n2020-01-03 00:00:00\n6\n16.879162\nCl\n\n\n1474\n2020-01-03 00:00:00\n6\n0.018737\nInitial\n\n\n2938\n2020-01-03 00:00:00\n6\n1.0\nContinuity\n\n\n4402\n2020-01-03 00:00:00\n6\n0.15889\nFoo\n\n\n5866\n2020-01-03 00:00:00\n6\n0.496446\nLevelBoundary\n\n\n7330\n2020-01-03 00:00:00\n6\n0.334212\nBar\n\n\n8794\n2020-01-03 00:00:00\n6\n0.0\nTerminal\n\n\n10258\n2020-01-03 00:00:00\n6\n0.484817\nTracer\n\n\n11722\n2020-01-03 00:00:00\n6\n0.0\nUserDemand\n\n\n13186\n2020-01-03 00:00:00\n6\n0.0\nDrainage\n\n\n14650\n2020-01-03 00:00:00\n6\n0.114232\nPrecipitation\n\n\n16114\n2020-01-03 00:00:00\n6\n0.370585\nFlowBoundary\n\n\n11\n2020-01-03 00:00:00\n9\n30.641869\nCl\n\n\n1475\n2020-01-03 00:00:00\n9\n0.009631\nInitial\n\n\n2939\n2020-01-03 00:00:00\n9\n1.0\nContinuity\n\n\n4403\n2020-01-03 00:00:00\n9\n0.033968\nFoo\n\n\n5867\n2020-01-03 00:00:00\n9\n0.901231\nLevelBoundary\n\n\n7331\n2020-01-03 00:00:00\n9\n0.047579\nBar\n\n\n8795\n2020-01-03 00:00:00\n9\n0.0\nTerminal\n\n\n10259\n2020-01-03 00:00:00\n9\n0.089137\nTracer\n\n\n11723\n2020-01-03 00:00:00\n9\n0.0\nUserDemand\n\n\n13187\n2020-01-03 00:00:00\n9\n0.0\nDrainage\n\n\n14651\n2020-01-03 00:00:00\n9\n0.034149\nPrecipitation\n\n\n16115\n2020-01-03 00:00:00\n9\n0.054988\nFlowBoundary\n\n\n\n\n\n\n\nWe can use this table to plot the results of the Delwaq model, both spatially as over time.\n\nfrom ribasim.delwaq import plot_fraction\n\nplot_fraction(nmodel, 1)  # default tracers, should add up to 1\nplot_fraction(nmodel, 9, [\"Foo\", \"Bar\"])  # custom tracers\nplot_fraction(nmodel, 9, [\"Continuity\"])  # mass balance check\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom ribasim.delwaq import plot_spatial\n\nplot_spatial(nmodel, \"Bar\")\nplot_spatial(nmodel, \"Foo\", versus=\"Bar\")  # ratio of Meuse to Rhine",
    "crumbs": [
      "How-to guides",
      "Coupling guides",
      "Ribasim Delwaq coupling"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ribasim",
    "section": "",
    "text": "Ribasim is a water resources model to simulate the physical behavior of a managed open water system based on a set of control rules and a prioritized water allocation strategy.\nRibasim is written in the Julia programming language and is built on top of the SciML: Open Source Software for Scientific Machine Learning libraries.\nThe initial version of Ribasim is developed by Deltares as part of a consortium for the Dutch watersystem. This activity is co-funded by TKI Deltatechnology, a Dutch public–private partnership innovation program from the Ministry of Economic Affairs. Ribasim will be used as the surface water module of the Netherlands Hydrologic Instrument (NHI).\n\nRibasim model of the main water distribution network in the Netherlands.",
    "crumbs": [
      "Overview",
      "Ribasim"
    ]
  },
  {
    "objectID": "concept/core.html",
    "href": "concept/core.html",
    "title": "Julia core",
    "section": "",
    "text": "With the term “core”, we mean the computational engine of Ribasim. As detailed in the usage documentation, it is generally used as a command line tool.\nA quick overview of the model concept is available in the introduction, while a more in depth discussion is available on the model concept page. The theory is described on the equations page, and more in-depth numerical considerations are described on the numerical considerations page. As allocation is a large and self-contained part of the Ribasim core, it is described on the separate allocation page. Input validation is described on the validation page.\nThe core is implemented in the Julia programming language, and can be found in the Ribasim repository under the core/ folder. For developers we also advise to read the developer documentation. Information on coupling can be found here.\nAn overview of all components is given in the installation section.\n\n1 The simulation loop\nThe computational process can be divided in three phases:\n\nModel initialization\nRunning the simulation loop\nWriting the output files\n\nThe figure below gives a more detailed description of the simulation loop in the form of a sequence diagram. From top to bottom, it contains the following blocks:\n\nAllocation optimization; activated when the allocation timestep has been passed;\nControl actions; activated when some discrete control callback is triggered;\nWater balance; computing the flows over flow edges happens each timestep;\nTime integration step; done by the integrator from OrdinaryDiffEq.jl.\n\n\n\n\n\n\nsequenceDiagram\n    autonumber\n    participant Int as Process: Integrator\n    participant Optim as Process: Allocation optimization\n    participant Param as Data: Parameters\n    participant State as Data: State\n    participant Sim as Process: Water balance\n    loop Simulation loop (OrdinaryDiffEq.jl)\n        activate Int\n        %% Allocation\n        rect rgb(200, 200, 200)\n            opt Allocation optimization, per allocation network (JuMP.jl, HiGHS)\n                activate Optim\n                Int-&gt;&gt;Optim: Callback: allocation timestep has passed\n                Param--&gt;&gt;Optim: Input\n                State--&gt;&gt;Optim: Input\n                Optim-&gt;&gt;Optim: Optimize Basin allocations if below target level\n                Optim-&gt;&gt;Optim: Optimize UserDemand allocation, per priority\n                Optim--&gt;&gt;Param: Set allocated flow rates\n                deactivate Optim\n            end\n        end\n        %% Control\n        rect rgb(200, 200, 200)\n            opt Control actions\n                Int-&gt;&gt;Int: DiscreteControl callback\n                Int--&gt;&gt;Param: Parameter updates by control\n            end\n        end\n        %% water_balance!\n        rect rgb(200, 200, 200)\n            activate Sim\n            State--&gt;&gt;Sim: Input\n            Param--&gt;&gt;Sim: Input\n            Sim-&gt;&gt;Sim: Compute flows over edges per node type\n            Sim--&gt;&gt;Param: Set flows\n            deactivate Sim\n        end\n        %% Time integration\n        rect rgb(200, 200, 200)\n            State--&gt;&gt;Int: Input\n            Param--&gt;&gt;Int: Input\n            Int-&gt;&gt;Int: Time integration step\n            Int--&gt;&gt;State: Update state\n        end\n        deactivate Int\n  end\n\n\n\n\n\n\n\n\n2 Nested allocation\nSince water systems may be extensive, like in the Netherlands, Ribasim models may become large networks with over ten thousand nodes. To keep a proper functioning allocation concept under these circumstances, the modeller can decompose the network domain into a main network and multiple sub-networks. The allocation will then be conducted in three steps:\n\nconduct an inventory of demands from the sub-networks to inlets from the main network,\nallocate the available water in the main network to the subnetworks inlets,\nallocate the assigned water within each subnetwork to the individual demand nodes.\n\nThe demand nodes then will request this updated demand from the rule-based simulation. Whether this updated demand is indeed abstracted depends on all dry-fall control mechanism implemented in the rule-based simulation.\nThe following sequence diagram illustrates this calculation process within then allocation phase.\n\n\n\n\n\nsequenceDiagram\nparticipant boundary\nparticipant basin\nparticipant user_demand\nparticipant allocation_subNetwork\nparticipant allocation_mainNetwork\n\nuser_demand-&gt;&gt;allocation_subNetwork: demand\nloop\n   allocation_subNetwork--&gt;&gt;allocation_mainNetwork: demand inventory at inlets\nend\nuser_demand-&gt;&gt;allocation_mainNetwork: demand\nboundary-&gt;&gt;allocation_mainNetwork: source availability\nbasin-&gt;&gt;allocation_mainNetwork: source availability\nallocation_mainNetwork--&gt;&gt;allocation_mainNetwork: allocate to inlets (and user_demands)\nallocation_mainNetwork-&gt;&gt;user_demand: allocated\nallocation_mainNetwork-&gt;&gt;allocation_subNetwork: allocated\nloop\n   allocation_subNetwork--&gt;&gt;allocation_subNetwork: allocate to user_demands\nend\nallocation_subNetwork-&gt;&gt;user_demand: allocated\nuser_demand-&gt;&gt;basin: abstracted",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Julia core"
    ]
  },
  {
    "objectID": "concept/modelconcept.html",
    "href": "concept/modelconcept.html",
    "title": "Model concept",
    "section": "",
    "text": "A brief summary of the concept is given introduction. As indicated, the model concept is organized in three layers:",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Model concept"
    ]
  },
  {
    "objectID": "concept/modelconcept.html#water-balance-equations",
    "href": "concept/modelconcept.html#water-balance-equations",
    "title": "Model concept",
    "section": "1.1 Water balance equations",
    "text": "1.1 Water balance equations\nThe water balance equation for a drainage basin (Wikipedia contributors 2022) can be defined by a first-order ordinary differential equation (ODE), where the change of the storage \\(S\\) over time is determined by the inflow fluxes minus the outflow fluxes.\n\\[\n\\frac{\\mathrm{d}S}{\\mathrm{d}t} = Q_{in} - Q_{out}\n\\]\nWe can split out the fluxes into separate terms, such as precipitation \\(P\\) and evapotranspiration \\(ET\\). For now other fluxes are combined into \\(Q_{rest}\\). If we define all fluxes entering our reservoir as positive, and those leaving the system as negative, all fluxes can be summed up.\n\\[\n\\frac{\\mathrm{d}S}{\\mathrm{d}t} = P + ET + Q_{rest}\n\\]\nWe don’t use these equations directly. Rather, we use an equivalent formulation where solve for the cumulative flows instead of the Basin storages. For more details on this see Equations.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Model concept"
    ]
  },
  {
    "objectID": "concept/modelconcept.html#time",
    "href": "concept/modelconcept.html#time",
    "title": "Model concept",
    "section": "1.2 Time",
    "text": "1.2 Time\nThe water balance equation can be applied on many timescales; years, weeks, days or hours. Depending on the application and available data any of these can be the best choice. In Ribasim, we make use of DifferentialEquations.jl and its ODE solvers. Many of these solvers are based on adaptive time stepping, which means the solver will decide how large the time steps can be depending on the state of the system.\nThe forcing, like precipitation, is generally provided as a time series. Ribasim is set up to support unevenly spaced timeseries. The solver will stop on timestamps where new forcing values are available, so they can be loaded as the new value.\nRibasim is essentially a continuous model, rather than daily or hourly. If you want to use hourly forcing, you only need to make sure that your forcing data contains hourly updates. The output frequency can be configured independently. To be able to write a closed water balance, we accumulate the fluxes. This way any variations in between timesteps are also included, and we can output in m³ rather than m³s⁻¹.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Model concept"
    ]
  },
  {
    "objectID": "concept/modelconcept.html#sec-space",
    "href": "concept/modelconcept.html#sec-space",
    "title": "Model concept",
    "section": "1.3 Space",
    "text": "1.3 Space\nThe water balance equation can be applied on different spatial scales. Besides modelling a single lumped watershed, it allows you to divide the area into a network of connected representative elementary watersheds (REWs) (Reggiani, Sivapalan, and Majid Hassanizadeh 1998). At this scale global water balance laws can be formulated by means of integration of point-scale conservation equations over control volumes. Such an approach makes Ribasim a semi-distributed model. In this document we typically use the term “basin” to refer to the REW. Each basin has an associated polygon, and the set of basins is connected to each other as described by a graph, which we call the network. Below is a representation of both on the map.\n\n\n\nMozart Local Surface Water polygons and their drainage.\n\n\nThe network is described as graph. Flow can be bi-directional, and the graph does not have to be acyclic.\n\n\n\n\n\ngraph LR;\n    A[\"basin A\"] --- B[\"basin B\"];\n    A --- C[\"basin C\"];\n    B --- D[\"basin D\"];\n    C --- D;\n\n\n\n\n\n\nInternally a directed graph is used. The direction is defined to be the positive flow direction, and is generally set in the dominant flow direction. The basins are the nodes of the network graph. Basin states and properties such storage volume and wetted area are associated with the nodes (A, B, C, D), as are most forcing data such as precipitation, evaporation, or water demand. Basin connection properties and interbasin flows are associated with the edges (the lines between A, B, C, and D) instead.\nMultiple basins may exist within the same spatial polygon, representing different aspects of the surface water system (perennial ditches, ephemeral ditches, or even surface ponding). Figure 1, Figure 2, Figure 3 show the 25.0 m rasterized primary, secondary, and tertiary surface waters as identified by BRT TOP10NL (PDOK 2022) in the Hupsel basin. These systems may represented in multiple ways.\n\n\n\n\n\n\nFigure 1: Hupsel: primary surface water.\n\n\n\n\n\n\n\n\n\nFigure 2: Hupsel: secondary surface water.\n\n\n\n\n\n\n\n\n\nFigure 3: Hupsel: tertiary surface water.\n\n\n\nAs a single basin (A) containing all surface water, discharging to its downstream basin to the west (B):\n\n\n\n\n\ngraph LR;\n    A[\"basin A\"] --&gt; B[\"basin B\"];\n\n\n\n\n\n\nSuch a system may be capable of representing discharge, but it cannot represent residence times or differences in solute concentrations: within a single basin, a drop of water is mixed instantaneously. Instead, we may the group primary (P), secondary (S), and tertiary (T) surface waters. Then T may flow into S, S into P, and P discharges to the downstream basin (B.)\n\n\n\n\n\ngraph LR;\n    T[\"basin T\"] --&gt; S[\"basin S\"];\n    S --&gt; P[\"basin P\"];\n    P --&gt; B[\"basin B\"];\n\n\n\n\n\n\nAs each (sub)basin has its own volume, low throughput (high volume, low discharge, long residence time) and high throughput (low volume, high discharge, short residence time) systems can be represented in a lumped manner; of course, more detail requires more parameters.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Model concept"
    ]
  },
  {
    "objectID": "concept/modelconcept.html#structures-in-a-water-system",
    "href": "concept/modelconcept.html#structures-in-a-water-system",
    "title": "Model concept",
    "section": "1.4 Structures in a water system",
    "text": "1.4 Structures in a water system\nIn addition to free flowing waterbodies, a watersystem typically has structures to control the flow of water. Ribasim uses connector nodes which simplify the hydraulic behavior for the free flowing conditions or structures. The following type of connector nodes are available for this purpose:\n\nTabulatedRatingCurve: one-directional flow based on upstream head. Node type typically used for gravity flow conditions either free flowing open water channels or over a fixed structure.\nLinearResistance: bi-directional flow based on head difference and linear resistance. Node type typically used for bi-directional flow situations or situations where head difference over a structure determines its actual flow capacity.\nManningResistance: bi-directional flow based on head difference and resistance using Manning-Gauckler formula. Same usage as LinearResistance, providing a better hydrological meaning to the resistance parameterization.\nPump: one-directional structure with a set flow rate. Node type typically used in combination with control to force water over the edge.\nOutlet: one-directional gravity structure with a set flow rate. Node type typically used in combination with control to force water over the edge, even if their is a mismatch in actual hydraulic capacity. The node type has an automated mechanism to stop the flow when the head difference is zero.\n\nThe control layer can activate or deactivate nodes, set flow rates for the Pump and Outlet, or choose different parameterizations for TabulatedRatingCurve, LinearResistance or ManningResistance.\nConnector nodes are required within a Ribasim network to determine the flow exchange between basins.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Model concept"
    ]
  },
  {
    "objectID": "concept/allocation.html",
    "href": "concept/allocation.html",
    "title": "Allocation",
    "section": "",
    "text": "Allocation is the process of assigning an allocated flow rate to demand nodes in the physical layer of the model based on information about sources, the different demand nodes over various priorities, constraints introduced by nodes, local water availability and graph topology. The allocation procedure implemented in Ribasim is heavily inspired by the maximum flow problem.\nThe allocation problem is solved per subnetwork (and main network) of the Ribasim model. Each subnetwork is used to formulate an optimization problem with the JuMP package, which is solved using the HiGHS solver. For more in-depth information see also the example of solving the maximum flow problem with JuMP.jl here.\nBefore the optimization for each priority there is a simple step that tries to allocate flow to the UserDemand nodes from the their directly connected basin.\n\n\n\n\n\n\nNote\n\n\n\nwithin this Allocation section the main network is also considered to be a subnetwork.",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#schematisation-input",
    "href": "concept/allocation.html#schematisation-input",
    "title": "Allocation",
    "section": "3.1 Schematisation input",
    "text": "3.1 Schematisation input\n\n3.1.1 The subnetwork\nThe allocation problem is solved per subnetwork, which is given by a subset \\(S \\subset V\\) of node ids. Different subnetworks are disjoint from eachother.\n\n\n3.1.2 Source flows\nSources are indicated by a set of edges in the subnetwork \\[\nE_S^\\text{source} \\subset E.\n\\] That is, if \\((i,j) \\in E_S^\\text{source}\\), then the average over the last allocation interval \\(\\Delta t_{\\text{alloc}}\\) of the of the flow over this edge \\[\n    \\frac{1}{\\Delta t_{\\text{alloc}}}\\int_{t - \\Delta t_{\\text{alloc}}}^tQ_{ij}(t') dt'\n\\] is treated as a source flow in the allocation problem. These edges are either coming from a boundary/source node (e.g. a level or flow boundary) or connect the main network to a subnetwork. For the definition of \\(Q_{ij}\\) see the formal model description.\n\n\n3.1.3 User demands\nThe subnetwork contains a subset of UserDemand nodes \\(U_S \\subset S\\), who all have static or time varying demands over various priorities \\(p\\): \\[\n    d^p_i(t), \\quad i \\in U_S, p = 1,2,\\ldots, p_{\\max}.\n\\]\n\n\n\n\n\n\nNote\n\n\n\nOn this page we assume that the priorities are given by all integers from \\(1\\) to some \\(p_{\\max} \\in \\mathbb{N}\\). For the Ribasim input this is not a requirement; some of these in between priority values can be missing, only the ordering of the given priorities is taken into account.\n\n\n\n\n3.1.4 Flow demands\nThe subnetwork contains a subset of nodes \\(FD_S \\subset S\\) which have a demand of a single priority \\(p_{\\text{fd}}\\). With this we define \\[\n    d^p_i(t) =\n    \\begin{cases}\n        0 \\text{ if } p \\ne p_{\\text{fd}} \\\\\n        d^{p_{\\text{df}}} \\text{ if } p = p_{\\text{fd}}\n    \\end{cases}\n\\] for all \\(i \\in FD_S\\). Here \\(d^{p_{\\text{df}}}\\) is given by the original flow demand minus the flows trough node \\(i\\) at all priorities \\(p &lt; p_{\\text{fd}}\\).",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#simulation-physical-layer-input",
    "href": "concept/allocation.html#simulation-physical-layer-input",
    "title": "Allocation",
    "section": "3.2 Simulation (physical layer) input",
    "text": "3.2 Simulation (physical layer) input\n\n3.2.1 Vertical fluxes and local storage\nApart from the source flows denoted by edges, there are other sources of water in the subnetwork, associated with the basins in the subnetwork \\(B_S = B \\cap S\\). Firstly there is the average over the last allocation interval \\(\\Delta t_{\\text{alloc}}\\) of the vertical fluxes (precipitation, evaporation, infiltration and drainage) for each basin: \\[\n    \\phi_i(t) = \\frac{1}{\\Delta t_{\\text{alloc}}}\\int_{t - \\Delta t_{\\text{alloc}}}^t \\left[Q_{P,i}(t') - Q_{E,i}(t') + Q_{\\text{drn},i}(t') - Q_{\\text{inf},i}(t') \\right] dt', \\quad \\forall i \\in B_S.\n\\]\nWe consider fluxes into the basin to be positive and out of the basin to be negative. For more information see the natural water balance terms.\nSecondly, there is either a supply or demand from the storage in the basin. Given a minimum level \\(\\ell_{\\min, i}\\) and a maximum level \\(\\ell_{\\max, i}\\) which correspond to a minimum storage \\(s_{\\min, i}\\) and maximum storage \\(s_{\\max, i}\\) respectively, we get a flow supply of \\[\n    F^{\\text{basin out}}_{\\max, i} = \\max\\left(0.0, \\frac{u_i(t)-s_{\\max,i}}{\\Delta t_{\\text{alloc}}} + \\phi_i(t)\\right)\n\\]\nand a demand of \\[\n    d^p_i = \\max\\left(0.0, \\frac{s_{\\min,i} - u_i(t)}{\\Delta t_{\\text{alloc}}} - \\phi_i(t)\\right),\n\\]\nfor all \\(i \\in B_S\\). Note that the basin demand has only a single priority, so for other priorities this demand is \\(0\\).\n\n\n3.2.2 Constraining factors\n\n3.2.2.1 Flow magnitude and direction constraints\nNodes in the Ribasim model that have a max_flow_rate, i.e. Pump, Outlet and LinearResistance, put a constraint on the flow through that node. Some nodes only allow flow in one direction, like Pump, Outlet and TabulatedRatingCurve.\n\n\n3.2.2.2 UserDemand return flows\nUserDemand nodes dictate proportional relationships between flows over edges in the subnetwork. The return factor is given by \\(0 \\le r_i \\le 1, i \\in U_S\\).",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#the-subnetwork-1",
    "href": "concept/allocation.html#the-subnetwork-1",
    "title": "Allocation",
    "section": "3.3 The subnetwork",
    "text": "3.3 The subnetwork\nThe subnetwork consists of a set of nodes \\(S \\subset V\\) and edges\n\\[\n    E_S = (S \\times S) \\cup E_S^\\text{source},\n\\]\ni.e. the edges that lie within the subnetwork together with the source edges (which can be partially outside the subnetwork). The nodes in \\(S\\) together with the connected nodes outside the subnetwork are called the extended subnetwork.\n\n3.3.1 Capacities\nEach edge in the subnetwork has an associated capacity. These capacities are collected in the sparse capacity matrix \\(C_S \\in \\overline{\\mathbb{R}}_{\\ge 0}^{n\\times n}\\) where \\(n\\) is the number of nodes in the extended subnetwork. An edge capacity is infinite if there is nothing in the model constraining the capacity.\nThe capacities are determined in different ways:\n\nIf an edge does not exist in the allocation network, i.e. \\((i,j) \\notin E_S\\) for certain \\(1 \\le i,j\\le n'\\), then \\((C_S)_{i,j} = 0\\);\nThe capacity of the edge \\(e \\in E_S\\) is given by the smallest max_flow_rate of the nodes along the equivalent edges in the subnetwork. If there are no nodes with a max_flow_rate, the edge capacity is infinite;\nIf the edge is a source, the capacity of the edge is given by the flow rate of that source;\nIf an edge comes from a node with a flow demand, it has infinite capacity at priorities other than this of this flow demand, and zero capacity otherwise.\n\nThere are also capacities for special edges:\n\n\\(C^{LD}_S \\in \\mathbb{R}^b_{\\ge 0}\\) where \\(b = \\# B_S\\) is the number of basins, for the flow supplied by basins based on level demand (this capacity is 0 for basins that have no level demand).\n\\(C^{FD}_S \\in \\mathbb{R}^c_{\\ge 0}\\) where \\(c = \\# FD_S\\) is the number of nodes with a flow demand, for the flow supplied by flow buffers at these nodes with a flow demand.\n\\(C^{UD}_S \\in \\mathbb{R}^f_{\\ge 0}\\) where \\(f = \\# U_S\\), for the flow supplied by the user demand outflow source whose capacity is given by return flows.",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#the-optimization-variables",
    "href": "concept/allocation.html#the-optimization-variables",
    "title": "Allocation",
    "section": "4.1 The optimization variables",
    "text": "4.1 The optimization variables\nThere are several types of variable whose value has to be determined to solve the allocation problem:\n\nThe flows \\(F \\in \\mathbb{R}_{\\ge 0}^{n\\times n}\\) over the edges in the allocation network;\nThe flows \\(F^\\text{basin out}_{i}, F^\\text{basin in}_{i} \\geq 0\\) for all \\(i \\in B_S\\) supplied and consumed by the basins with a level demand respectively;\nThe flows \\(F^\\text{buffer out}_{i}, F^\\text{buffer in}_{i} \\ge 0\\) for all \\(i \\in FD_S \\cup FF_S\\) supplied and consumed by the flow buffers of nodes with a flow demand.",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#the-optimization-objective",
    "href": "concept/allocation.html#the-optimization-objective",
    "title": "Allocation",
    "section": "4.2 The optimization objective",
    "text": "4.2 The optimization objective\nThe goal of allocation is to get the flow to nodes with demands as close as possible to these demands. To achieve this, a sum error of terms is minimized.\n\\[\n    \\min E_{\\text{user demand}} + E_{\\text{level demand}} + E_{\\text{flow demand}}\n\\]\nThe error between the flows and user demands is denoted by \\(E_{\\text{user demand}}\\), where \\[\n    E_{\\text{user demand}} = \\sum_{(i,j)\\in E_S\\;:\\; i\\in U_S} d_j^p(t)\\left(1 - \\frac{F_{ij}}{d_j^p(t)}\\right)^2\n\\]\n\n\n\n\n\n\nNote\n\n\n\nWhen performing main network allocation, the connections to subnetworks are also interpreted as UserDemand nodes with demands determined by subnetwork demand collection.\n\n\nThis type of objective cares about the fraction of the demand allocated, and will lead to an equal fraction of all demands allocated when possible. For a discussion on this see here.\nLikewise, the error of level demands from basins is the squared relative difference between flows consumed by basins and basin demands. \\[\n    E_{\\text{level demand}} = \\sum_{i \\in B_S} d_i^p(t)\\left(1 - \\frac{F_i^\\text{basin in}}{d_i^p(t)}\\right)^2\n\\]\nLastly, the error of the flow demands is given as below. \\[\n    E_{\\text{flow demand}} = \\sum_{i \\in FD_S} d_i^p(t)\\left(1 -  \\frac{F_i^\\text{buffer in}}{d_i^p(t)}\\right)^2\n\\]",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#the-optimization-constraints",
    "href": "concept/allocation.html#the-optimization-constraints",
    "title": "Allocation",
    "section": "4.3 The optimization constraints",
    "text": "4.3 The optimization constraints\nFor convenience, we use the notation\n\\[\\begin{align}\n    V^{\\text{out}}_S(i) = \\left\\{j \\in V : (i,j) \\in E_S\\right\\} \\\\\n    V^{\\text{in}}_S(j) = \\left\\{i \\in V : (i,j) \\in E_S\\right\\}\n\\end{align}\\]\nfor the set of in-neighbors and out-neighbors of a node in the network respectively.\n\nFlow conservation: For all nodes \\(k\\) that are not a source or a sink (i.e. FlowBoundary, LevelBoundary, UserDemand) we have a flow conservation constraint: \\[\n  \\sum F_{\\text{out special}} + \\sum_{j \\in V^{\\text{out}}_S(k)} F_{kj} = \\sum F_{\\text{in special}} + \\sum_{i \\in V^{\\text{in}}_S(k)} F_{ik}, \\quad \\forall k \\in B_S.\n\\tag{1}\\]\n\nIn here, we have the following special flows:\n\nIf \\(k\\) is a basin with a flow demand, there is a special outflow \\(F^{\\text{basin in}}_k\\) and a special inflow \\(F^{\\text{basin out}}_k\\);\nIf the node has a buffer (see here) there is a special outflow \\(F^{\\text{buffer in}}_k\\) and a special inflow \\(F^{\\text{buffer out}}_k\\).\n\n\n\n\n\n\n\nNote\n\n\n\nIn the above, the placement of the basin and buffer flows might seem counter-intuitive. Think of the storage or buffer as a separate node connected to the node with the demand.\n\n\n\nCapacity: the flows over the edges are bounded by the edge capacity: \\[\n  F_{ij} \\le \\left(C_S\\right)_{ij}, \\quad \\forall(i,j) \\in E_S.\n\\tag{2}\\] By the definition of \\(C_S\\) this also includes the source flows. The same holds for the basin outflows:\n\n\\[\n    F^{\\text{basin out}}_{i} \\le F^{\\text{basin out}}_{\\max, i}, \\quad \\forall i \\in B_S.\n\\]\n\n\n\n\n\n\nNote\n\n\n\nWhen performing subnetwork demand collection, these capacities are set to \\(\\infty\\) for edges which connect the main network to a subnetwork. For all other sources the capacity is set to \\(0\\), so that demand collection only uses flow from the main network inlet.\n\n\nSimilar constraints hold for the flow out of basins, flow demand buffers and user demand outflow sources: \\[\nF^\\text{basin out}_{i} \\le (C^{FD}_S)_i, \\quad \\forall i \\in B_S,\n\\]\n\\[\nF^\\text{buffer out}_{i} \\le (C^{FD}_S)_i, \\quad \\forall i \\in FD_S,\n\\]\n\\[\nF_{ij} \\le (C^{UD}_S)_i, \\quad \\forall i \\in U_S, \\quad V_S^{\\text{out}}(i) = \\{j\\}.\n\\] Here we use that each UserDemand node in the allocation network has a unique outflow edge. The user outflow source capacities are increased after each optimization solve by the return fraction: \\[\n    r_i \\cdot F_{ki}, \\quad V_S^{\\text{in}}(i) = \\{k\\}.\n\\]\n\nFlow sign: Furthermore there are the non-negativity constraints for the flows and allocations, see The optimization variables.",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#example",
    "href": "concept/allocation.html#example",
    "title": "Allocation",
    "section": "4.4 Example",
    "text": "4.4 Example\nThe following is an example of an optimization problem for the example shown here:\n\n\nCode\nusing Ribasim\nusing Ribasim: NodeID\nusing SQLite\nusing ComponentArrays: ComponentVector\n\ntoml_path = normpath(@__DIR__, \"../../generated_testmodels/allocation_example/ribasim.toml\")\np = Ribasim.Model(toml_path).integrator.p\nu = ComponentVector(; storage = zeros(length(p.basin.node_id)))\n\nallocation_model = p.allocation.allocation_models[1]\nt = 0.0\npriority_idx = 1\n\nRibasim.set_objective_priority!(allocation_model, p, u, t, priority_idx)\nRibasim.set_initial_values!(allocation_model, p, u, t)\n\nprintln(p.allocation.allocation_models[1].problem)\n\n\nMin F[(Basin #5, UserDemand #6)]² + F[(Basin #2, UserDemand #3)]²\nSubject to\n flow_conservation[Basin #5] : -F[(Basin #5, UserDemand #6)] - F[(Basin #5, TabulatedRatingCurve #7)] + F[(LinearResistance #4, Basin #5)] - F[(Basin #5, LinearResistance #4)] + F[(UserDemand #6, Basin #5)] = 0\n flow_conservation[TabulatedRatingCurve #7] : F[(Basin #5, TabulatedRatingCurve #7)] - F[(TabulatedRatingCurve #7, Terminal #8)] = 0\n flow_conservation[LinearResistance #4] : F[(Basin #2, LinearResistance #4)] - F[(LinearResistance #4, Basin #2)] - F[(LinearResistance #4, Basin #5)] + F[(Basin #5, LinearResistance #4)] = 0\n flow_conservation[Terminal #8] : F[(TabulatedRatingCurve #7, Terminal #8)] = 0\n flow_conservation[Basin #2] : -F[(Basin #2, LinearResistance #4)] + F[(LinearResistance #4, Basin #2)] + F[(FlowBoundary #1, Basin #2)] + F[(UserDemand #3, Basin #2)] - F[(Basin #2, UserDemand #3)] = 0\n source[(FlowBoundary #1, Basin #2)] : F[(FlowBoundary #1, Basin #2)] ≤ 172800\n source_user[UserDemand #3] : F[(UserDemand #3, Basin #2)] ≤ 0\n source_user[UserDemand #6] : F[(UserDemand #6, Basin #5)] ≤ 0\n F[(Basin #2, LinearResistance #4)] ≥ 0\n F[(LinearResistance #4, Basin #2)] ≥ 0\n F[(Basin #5, UserDemand #6)] ≥ 0\n F[(Basin #5, TabulatedRatingCurve #7)] ≥ 0\n F[(TabulatedRatingCurve #7, Terminal #8)] ≥ 0\n F[(FlowBoundary #1, Basin #2)] ≥ 0\n F[(UserDemand #3, Basin #2)] ≥ 0\n F[(Basin #2, UserDemand #3)] ≥ 0\n F[(LinearResistance #4, Basin #5)] ≥ 0\n F[(Basin #5, LinearResistance #4)] ≥ 0\n F[(UserDemand #6, Basin #5)] ≥ 0",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "reference/validation.html",
    "href": "reference/validation.html",
    "title": "Validation",
    "section": "",
    "text": "The tables below show the validation rules applied to the input to the Julia core before running the model.\n\n1 Connectivity\nIn the table below, each column shows which node types are allowed to be downstream (or ‘down-control’) of the node type at the top of the column.\n\n\nCode\nusing Ribasim\nusing DataFrames: DataFrame\nusing MarkdownTables\n\nnode_names_snake_case = Symbol[]\nnode_names_camel_case = Symbol[]\nfor (node_name, node_type) in zip(fieldnames(Ribasim.Parameters), fieldtypes(Ribasim.Parameters))\n    if node_type &lt;: Ribasim.AbstractParameterNode\n        push!(node_names_snake_case, node_name)\n        push!(node_names_camel_case, nameof(node_type))\n    end\nend\n\nfunction to_symbol(b::Bool)::String\n    return b ? \"✓\" : \"x\"\nend\n\n\ndf = DataFrame()\ndf[!, :downstream] = node_names_snake_case\n\nfor node_name in node_names_snake_case\n    df[!, node_name] =\n        [(to_symbol(node_name_ in Ribasim.neighbortypes(node_name))) for node_name_ in node_names_snake_case]\nend\n\nmarkdown_table(df)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndownstream\nbasin\nlinear_resistance\nmanning_resistance\ntabulated_rating_curve\nlevel_boundary\nflow_boundary\npump\noutlet\nterminal\ndiscrete_control\ncontinuous_control\npid_control\nuser_demand\nlevel_demand\nflow_demand\n\n\n\n\nbasin\nx\n✓\n✓\n✓\nx\n✓\n✓\n✓\nx\nx\nx\nx\n✓\n✓\nx\n\n\nlinear_resistance\n✓\nx\nx\nx\n✓\nx\nx\nx\nx\n✓\nx\nx\nx\nx\n✓\n\n\nmanning_resistance\n✓\nx\nx\nx\nx\nx\nx\nx\nx\n✓\nx\nx\nx\nx\n✓\n\n\ntabulated_rating_curve\n✓\nx\nx\nx\n✓\nx\nx\nx\nx\n✓\nx\nx\nx\nx\n✓\n\n\nlevel_boundary\nx\n✓\nx\n✓\nx\n✓\n✓\n✓\nx\nx\nx\nx\n✓\nx\nx\n\n\nflow_boundary\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\n\n\npump\n✓\nx\nx\nx\n✓\nx\nx\nx\nx\n✓\n✓\n✓\nx\nx\n✓\n\n\noutlet\n✓\nx\nx\nx\n✓\nx\nx\nx\nx\n✓\n✓\n✓\nx\nx\n✓\n\n\nterminal\nx\nx\nx\n✓\nx\n✓\n✓\n✓\nx\nx\nx\nx\n✓\nx\nx\n\n\ndiscrete_control\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\n\n\ncontinuous_control\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\n\n\npid_control\nx\nx\nx\nx\nx\nx\nx\nx\nx\n✓\nx\nx\nx\nx\nx\n\n\nuser_demand\n✓\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\n\n\nlevel_demand\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\n\n\nflow_demand\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\n\n\n\n\n\n\n\n2 Neighbor amounts\nThe table below shows for each node type between which bounds the amount of in- and outneighbors must be, for both flow and control edges.\n\n\nCode\nflow_in_min = Vector{String}()\nflow_in_max = Vector{String}()\nflow_out_min = Vector{String}()\nflow_out_max = Vector{String}()\ncontrol_in_min = Vector{String}()\ncontrol_in_max = Vector{String}()\ncontrol_out_min = Vector{String}()\ncontrol_out_max = Vector{String}()\n\nfunction unbounded(i::Int)::String\n    return i == typemax(Int) ? \"∞\" : string(i)\nend\n\nfor node_name in node_names_camel_case\n    bounds_flow = Ribasim.n_neighbor_bounds_flow(node_name)\n    push!(flow_in_min, string(bounds_flow.in_min))\n    push!(flow_in_max, unbounded(bounds_flow.in_max))\n    push!(flow_out_min, string(bounds_flow.out_min))\n    push!(flow_out_max, unbounded(bounds_flow.out_max))\n\n    bounds_control = Ribasim.n_neighbor_bounds_control(node_name)\n    push!(control_in_min, string(bounds_control.in_min))\n    push!(control_in_max, unbounded(bounds_control.in_max))\n    push!(control_out_min, string(bounds_control.out_min))\n    push!(control_out_max, unbounded(bounds_control.out_max))\n\nend\n\ndf = DataFrame(\n    ;\n    node_type = node_names_snake_case,\n    flow_in_min,\n    flow_in_max,\n    flow_out_min,\n    flow_out_max,\n    control_in_min,\n    control_in_max,\n    control_out_min,\n    control_out_max,\n)\n\nmarkdown_table(df)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnode_type\nflow_in_min\nflow_in_max\nflow_out_min\nflow_out_max\ncontrol_in_min\ncontrol_in_max\ncontrol_out_min\ncontrol_out_max\n\n\n\n\nbasin\n0\n∞\n0\n∞\n0\n1\n0\n0\n\n\nlinear_resistance\n1\n1\n1\n1\n0\n1\n0\n0\n\n\nmanning_resistance\n1\n1\n1\n1\n0\n1\n0\n0\n\n\ntabulated_rating_curve\n1\n1\n1\n1\n0\n1\n0\n0\n\n\nlevel_boundary\n0\n∞\n0\n∞\n0\n0\n0\n0\n\n\nflow_boundary\n0\n0\n1\n∞\n0\n0\n0\n0\n\n\npump\n1\n1\n1\n1\n0\n1\n0\n0\n\n\noutlet\n1\n1\n1\n1\n0\n1\n0\n0\n\n\nterminal\n1\n∞\n0\n0\n0\n0\n0\n0\n\n\ndiscrete_control\n0\n0\n0\n0\n0\n0\n1\n∞\n\n\ncontinuous_control\n0\n0\n0\n0\n0\n0\n1\n∞\n\n\npid_control\n0\n0\n0\n0\n0\n1\n1\n1\n\n\nuser_demand\n1\n1\n1\n1\n0\n0\n0\n0\n\n\nlevel_demand\n0\n0\n0\n0\n0\n0\n1\n∞\n\n\nflow_demand\n0\n0\n0\n0\n0\n0\n1\n1",
    "crumbs": [
      "Reference",
      "Validation"
    ]
  },
  {
    "objectID": "reference/test-models.html",
    "href": "reference/test-models.html",
    "title": "Test models",
    "section": "",
    "text": "Ribasim developers use the following models in their testbench and in order to test new features.\n\n\nCode\nimport ribasim_testmodels\nimport matplotlib.pyplot as plt\n\nfor model_name, model_constructor in ribasim_testmodels.constructors.items():\n    if model_name.startswith(\"invalid\"):\n        continue\n\n    model = model_constructor()\n    fig, ax = plt.subplots(figsize = (6, 4))\n    model.plot(ax)\n    ax.set_title(label=model_name, loc=\"left\")\n    fig.text(0, 1, model_constructor.__doc__)\n    ax.axis('off')\n    plt.show()\n    plt.close(fig)",
    "crumbs": [
      "Reference",
      "Test models"
    ]
  },
  {
    "objectID": "reference/python/Solver.html",
    "href": "reference/python/Solver.html",
    "title": "1 Solver",
    "section": "",
    "text": "Solver()\nDefines the numerical solver options. For more details see https://docs.sciml.ai/DiffEqDocs/stable/basics/common_solver_opts/#solver_options.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nalgorithm\nstr\nThe used numerical time integration algorithm (Optional, defaults to QNDF)\n\n\nsaveat\nfloat\nTime interval in seconds between saves of output data. 0 saves every timestep, inf only saves at start- and endtime. (Optional, defaults to 86400)\n\n\ndt\nfloat\nTimestep of the solver. (Optional, defaults to None which implies adaptive timestepping)\n\n\ndtmin\nfloat\nThe minimum allowed timestep of the solver (Optional, defaults to 0.0)\n\n\ndtmax\nfloat\nThe maximum allowed timestep size (Optional, defaults to 0.0 which implies the total length of the simulation)\n\n\nforce_dtmin\nbool\nIf a smaller dt than dtmin is needed to meet the set error tolerances, the simulation stops, unless force_dtmin = true (Optional, defaults to False)\n\n\nabstol\nfloat\nThe absolute tolerance for adaptive timestepping (Optional, defaults to 1e-7)\n\n\nreltol\nfloat\nThe relative tolerance for adaptive timestepping (Optional, defaults to 1e-7)\n\n\nmaxiters\nint\nThe total number of linear iterations over the whole simulation. (Defaults to 1e9, only needs to be increased for extremely long simulations)\n\n\nsparse\nbool\nWhether a sparse Jacobian matrix is used, which gives a significant speedup for models with &gt;~10 basins.\n\n\nautodiff\nbool\nWhether automatic differentiation instead of fine difference is used to compute the Jacobian. (Optional, defaults to true)"
  },
  {
    "objectID": "reference/python/Solver.html#attributes",
    "href": "reference/python/Solver.html#attributes",
    "title": "1 Solver",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nalgorithm\nstr\nThe used numerical time integration algorithm (Optional, defaults to QNDF)\n\n\nsaveat\nfloat\nTime interval in seconds between saves of output data. 0 saves every timestep, inf only saves at start- and endtime. (Optional, defaults to 86400)\n\n\ndt\nfloat\nTimestep of the solver. (Optional, defaults to None which implies adaptive timestepping)\n\n\ndtmin\nfloat\nThe minimum allowed timestep of the solver (Optional, defaults to 0.0)\n\n\ndtmax\nfloat\nThe maximum allowed timestep size (Optional, defaults to 0.0 which implies the total length of the simulation)\n\n\nforce_dtmin\nbool\nIf a smaller dt than dtmin is needed to meet the set error tolerances, the simulation stops, unless force_dtmin = true (Optional, defaults to False)\n\n\nabstol\nfloat\nThe absolute tolerance for adaptive timestepping (Optional, defaults to 1e-7)\n\n\nreltol\nfloat\nThe relative tolerance for adaptive timestepping (Optional, defaults to 1e-7)\n\n\nmaxiters\nint\nThe total number of linear iterations over the whole simulation. (Defaults to 1e9, only needs to be increased for extremely long simulations)\n\n\nsparse\nbool\nWhether a sparse Jacobian matrix is used, which gives a significant speedup for models with &gt;~10 basins.\n\n\nautodiff\nbool\nWhether automatic differentiation instead of fine difference is used to compute the Jacobian. (Optional, defaults to true)"
  },
  {
    "objectID": "reference/python/index.html",
    "href": "reference/python/index.html",
    "title": "1 Python API",
    "section": "",
    "text": "Allocation\nDefines the allocation optimization algorithm options.\n\n\nLogging\nDefines the logging behavior of the core.\n\n\nNode\nDefines a node for the model.\n\n\nSolver\nDefines the numerical solver options.\n\n\nEdgeTable\nDefines the connections between nodes.\n\n\nModel\nA model of inland water resources systems.",
    "crumbs": [
      "Reference",
      "Python API"
    ]
  },
  {
    "objectID": "reference/python/index.html#ribasim",
    "href": "reference/python/index.html#ribasim",
    "title": "1 Python API",
    "section": "",
    "text": "Allocation\nDefines the allocation optimization algorithm options.\n\n\nLogging\nDefines the logging behavior of the core.\n\n\nNode\nDefines a node for the model.\n\n\nSolver\nDefines the numerical solver options.\n\n\nEdgeTable\nDefines the connections between nodes.\n\n\nModel\nA model of inland water resources systems.",
    "crumbs": [
      "Reference",
      "Python API"
    ]
  },
  {
    "objectID": "reference/python/Logging.html",
    "href": "reference/python/Logging.html",
    "title": "1 Logging",
    "section": "",
    "text": "Logging()\nDefines the logging behavior of the core.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nverbosity\nVerbosity\nThe verbosity of the logging: debug/info/warn/error (Optional, defaults to info)"
  },
  {
    "objectID": "reference/python/Logging.html#attributes",
    "href": "reference/python/Logging.html#attributes",
    "title": "1 Logging",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nverbosity\nVerbosity\nThe verbosity of the logging: debug/info/warn/error (Optional, defaults to info)"
  },
  {
    "objectID": "reference/node/continuous-control.html",
    "href": "reference/node/continuous-control.html",
    "title": "ContinuousControl",
    "section": "",
    "text": "The ContinuousControl node allows for fine control of a controllable property of a connector node, which is updated at each time step. This control can be set up as follows:",
    "crumbs": [
      "Reference",
      "Nodes",
      "ContinuousControl"
    ]
  },
  {
    "objectID": "reference/node/continuous-control.html#variable",
    "href": "reference/node/continuous-control.html#variable",
    "title": "ContinuousControl",
    "section": "1.1 Variable",
    "text": "1.1 Variable\nThe compound variable schema defines linear combinations of variables which can be used in conditions. This means that this schema defines new variables with the given compound_variable_id that look like \\[\n    \\text{weight}_1 * \\text{variable}_1 + \\text{weight}_2 * \\text{variable}_2 + \\ldots,\n\\]\nwhich can be for instance an average or a difference of variables. If a variable comes from a timeseries, a look ahead \\(\\Delta t\\) can be supplied. There is only one compound variable per ContinuousControl node.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\nlisten_node_type\nString\n-\nknown node type\n\n\nlisten_node_id\nInt32\n-\nsorted per node_id\n\n\nvariable\nString\n-\nmust be “level” or “flow_rate”, sorted per listen_node_id\n\n\nweight\nFloat64\n-\n(optional, default 1.0)\n\n\nlook_ahead\nFloat64\n\\(\\text{s}\\)\nOnly on transient boundary conditions, non-negative (optional, default 0.0).",
    "crumbs": [
      "Reference",
      "Nodes",
      "ContinuousControl"
    ]
  },
  {
    "objectID": "reference/node/continuous-control.html#function",
    "href": "reference/node/continuous-control.html#function",
    "title": "ContinuousControl",
    "section": "1.2 Function",
    "text": "1.2 Function\nThe function table defines a piecewise linear function \\(f\\) interpolating between (input, output) datapoints for each ContinuousControl node. The total computation thus looks like\n\\[\n    f(\\text{weight}_1 * \\text{variable}_1 + \\text{weight}_2 * \\text{variable}_2 + \\ldots).\n\\]\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ninput\nFloat64\n-\nsorted per node_id\n\n\noutput\nFloat64\n-\n-\n\n\ncontrolled_variable\nString\n-\nmust be “level” or “flow_rate”",
    "crumbs": [
      "Reference",
      "Nodes",
      "ContinuousControl"
    ]
  },
  {
    "objectID": "reference/node/flow-demand.html",
    "href": "reference/node/flow-demand.html",
    "title": "FlowDemand",
    "section": "",
    "text": "A FlowDemand node associates a non-consuming flow demand to a connector node (e.g. Pump, TabulatedRatingCurve) for one single priority. FlowDemand nodes can set a flow demand only for a single connector node.",
    "crumbs": [
      "Reference",
      "Nodes",
      "FlowDemand"
    ]
  },
  {
    "objectID": "reference/node/flow-demand.html#static",
    "href": "reference/node/flow-demand.html#static",
    "title": "FlowDemand",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\npriority\nInt32\n-\npositive\n\n\ndemand\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative",
    "crumbs": [
      "Reference",
      "Nodes",
      "FlowDemand"
    ]
  },
  {
    "objectID": "reference/node/flow-demand.html#time",
    "href": "reference/node/flow-demand.html#time",
    "title": "FlowDemand",
    "section": "1.2 Time",
    "text": "1.2 Time\nThis table is the transient form of the FlowDemand table, in which a time-dependent demand can be supplied. Similar to the static version, only a single priority per FlowDemand node can be provided.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ntime\nDateTime\n-\nsorted per node_id\n\n\npriority\nInt32\n-\npositive\n\n\ndemand\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative",
    "crumbs": [
      "Reference",
      "Nodes",
      "FlowDemand"
    ]
  },
  {
    "objectID": "reference/node/flow-boundary.html",
    "href": "reference/node/flow-boundary.html",
    "title": "FlowBoundary",
    "section": "",
    "text": "A FlowBoundary adds water to the model at a specified flow rate. It can be used as a boundary condition like a measured upstream flow rate, or lateral inflow.",
    "crumbs": [
      "Reference",
      "Nodes",
      "FlowBoundary"
    ]
  },
  {
    "objectID": "reference/node/flow-boundary.html#static",
    "href": "reference/node/flow-boundary.html#static",
    "title": "FlowBoundary",
    "section": "1.1 Static",
    "text": "1.1 Static\nWe require that the edge connecting the FlowBoundary to the Basin should point towards the Basin, so that positive flow corresponds to water being added to the model. The set flow rate will be pumped unless the intake storage (for a negative flow rate) is less than \\(10~\\text{ m}^3\\), in which case the flow rate will be linearly reduced to \\(0~\\text{ m}^3/s\\). Note that the connected node must always be a Basin.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\nactive\nBool\n-\n(optional, default true)\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative",
    "crumbs": [
      "Reference",
      "Nodes",
      "FlowBoundary"
    ]
  },
  {
    "objectID": "reference/node/flow-boundary.html#time",
    "href": "reference/node/flow-boundary.html#time",
    "title": "FlowBoundary",
    "section": "1.2 Time",
    "text": "1.2 Time\nThis table is the transient form of the FlowBoundary table. The only differences are that a time column is added and the nodes are assumed to be active so this column is removed. The table must by sorted by time, and per time it must be sorted by node_id. With this the flow rates can be updated over time. In between the given times the flow rate is interpolated linearly, and outside the flow rate is constant given by the nearest time value. Note that a node_id can be either in this table or in the static one, but not both.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ntime\nDateTime\n-\nsorted per node_id\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative",
    "crumbs": [
      "Reference",
      "Nodes",
      "FlowBoundary"
    ]
  },
  {
    "objectID": "reference/node/flow-boundary.html#sec-flow-boundary-conc",
    "href": "reference/node/flow-boundary.html#sec-flow-boundary-conc",
    "title": "FlowBoundary",
    "section": "1.3 Concentration",
    "text": "1.3 Concentration\nThis table defines the concentration(s) of (a) substance(s) for the flow from the FlowBoundary.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ntime\nDateTime\n-\nsorted per node_id\n\n\nsubstance\nString\n-\ncan correspond to known Delwaq substances\n\n\nconcentration\nFloat64\n\\(\\text{g}/\\text{m}^3\\)",
    "crumbs": [
      "Reference",
      "Nodes",
      "FlowBoundary"
    ]
  },
  {
    "objectID": "reference/node/manning-resistance.html",
    "href": "reference/node/manning-resistance.html",
    "title": "ManningResistance",
    "section": "",
    "text": "The ManningResistance node calculates a flow rate between two Basins based on their water levels. The flow rate is calculated by conservation of energy and the Manning-Gauckler formula to estimate friction losses.",
    "crumbs": [
      "Reference",
      "Nodes",
      "ManningResistance"
    ]
  },
  {
    "objectID": "reference/node/manning-resistance.html#static",
    "href": "reference/node/manning-resistance.html#static",
    "title": "ManningResistance",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ncontrol_state\nString\n-\n(optional) sorted per node_id\n\n\nactive\nBool\n-\n(optional, default true)\n\n\nlength\nFloat64\n\\(\\text{m}\\)\npositive\n\n\nmanning_n\nFloat64\n\\(\\text{s} \\text{m}^{-\\frac{1}{3}}\\)\npositive\n\n\nprofile_width\nFloat64\n\\(\\text{m}\\)\npositive\n\n\nprofile_slope\nFloat64\n-\n-",
    "crumbs": [
      "Reference",
      "Nodes",
      "ManningResistance"
    ]
  },
  {
    "objectID": "reference/node/level-boundary.html",
    "href": "reference/node/level-boundary.html",
    "title": "LevelBoundary",
    "section": "",
    "text": "LevelBoundary is a node whose water level is determined by the input. It can be used as a boundary condition like the level of the sea or a lake. Since the water level is unaffected by flow, it acts like an infinitely large Basin. Connect the LevelBoundary to a node that will look at the level to calculate the flow, like a LinearResistance.",
    "crumbs": [
      "Reference",
      "Nodes",
      "LevelBoundary"
    ]
  },
  {
    "objectID": "reference/node/level-boundary.html#static",
    "href": "reference/node/level-boundary.html#static",
    "title": "LevelBoundary",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\nactive\nBool\n-\n(optional, default true)\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\n-",
    "crumbs": [
      "Reference",
      "Nodes",
      "LevelBoundary"
    ]
  },
  {
    "objectID": "reference/node/level-boundary.html#time",
    "href": "reference/node/level-boundary.html#time",
    "title": "LevelBoundary",
    "section": "1.2 Time",
    "text": "1.2 Time\nThis table is the transient form of the LevelBoundary table. The only difference is that a time column is added and activity is assumed to be true. The table must by sorted by time, and per time it must be sorted by node_id. With this the levels can be updated over time. In between the given times the level is interpolated linearly, and outside the flow rate is constant given by the nearest time value. Note that a node_id can be either in this table or in the static one, but not both.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ntime\nDateTime\n-\nsorted per node_id\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\n-",
    "crumbs": [
      "Reference",
      "Nodes",
      "LevelBoundary"
    ]
  },
  {
    "objectID": "reference/node/level-boundary.html#sec-level-boundary-conc",
    "href": "reference/node/level-boundary.html#sec-level-boundary-conc",
    "title": "LevelBoundary",
    "section": "1.3 Concentration",
    "text": "1.3 Concentration\nThis table defines the concentration(s) of (a) substance(s) for the flow from the LevelBoundary.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ntime\nDateTime\n-\nsorted per node_id\n\n\nsubstance\nString\n-\ncan correspond to known Delwaq substances\n\n\nconcentration\nFloat64\n\\(\\text{g}/\\text{m}^3\\)",
    "crumbs": [
      "Reference",
      "Nodes",
      "LevelBoundary"
    ]
  },
  {
    "objectID": "reference/node/basin.html",
    "href": "reference/node/basin.html",
    "title": "Basin",
    "section": "",
    "text": "The Basin is the central node in each schematization, since it is the only one that stores water. It can exchange water with all other nodes. The connected nodes determine how water is exchanged; the Basin has no flow behavior of its own.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#static",
    "href": "reference/node/basin.html#static",
    "title": "Basin",
    "section": "1.1 Static",
    "text": "1.1 Static\nThe Basin / static table can be used to set the static value of variables. The time table has a similar schema, with the time column added. A static value for a variable is only used if there is no dynamic forcing data for that variable. Specifically, if there is either no time table, it is empty, or all timestamps of that variable are missing.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\nprecipitation\nFloat64\n\\(\\text{m}/\\text{s}\\)\nnon-negative\n\n\npotential_evaporation\nFloat64\n\\(\\text{m}/\\text{s}\\)\nnon-negative\n\n\ndrainage\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\ninfiltration\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\n\nNote that if variables are not set in the static table, default values are used when possible. These are generally zero, e.g. no precipitation, no inflow. If it is not possible to have a reasonable and safe default, a value must be provided in the static table.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#time",
    "href": "reference/node/basin.html#time",
    "title": "Basin",
    "section": "1.2 Time",
    "text": "1.2 Time\nThis table is the transient form of the Basin table. The only difference is that a time column is added. The table must by sorted by time, and per time it must be sorted by node_id.\n\n1.2.1 Interpolation\nAt the given timestamps the values are set in the simulation, such that the timeseries can be seen as forward filled.\n\n\nCode\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, Markdown\n\nnp.random.seed(1)\nfig, ax = plt.subplots()\nfontsize = 15\n\nN = 5\ny = np.random.rand(N)\nx = np.cumsum(np.random.rand(N))\n\ndef forward_fill(x_):\n    i = min(max(0, np.searchsorted(x, x_)-1), len(x)-1)\n    return y[i]\n\ndef plot_forward_fill(i):\n    ax.plot([x[i], x[i+1]], [y[i], y[i]], color = \"C0\", label = \"interpolation\" if i == 0 else None)\n\nax.scatter(x[:-1],y[:-1], label = \"forcing at data points\")\nfor i in range(N-1):\n    plot_forward_fill(i)\n\nx_missing_data = np.sort(x[0] + (x[-1] - x[0]) * np.random.rand(5))\ny_missing_data = [forward_fill(x_) for x_ in x_missing_data]\nax.scatter(x_missing_data, y_missing_data, color = \"C0\", marker = \"x\", label = \"missing data\")\nax.set_xticks([])\nax.set_yticks([])\nax.set_xlabel(\"time\", fontsize = fontsize)\nax.set_ylabel(\"forcing\", fontsize = fontsize)\nxlim = ax.get_xlim()\nax.set_xlim(xlim[0], (x[-2] + x[-1])/2)\nax.legend()\n\nmarkdown_table = pd.DataFrame(\n        data = {\n            \"time\" : x,\n            \"forcing\" : y\n        }\n    ).to_markdown(index = False)\n\ndisplay(Markdown(markdown_table))\n\n\n\n\n\ntime\nforcing\n\n\n\n\n0.0923386\n0.417022\n\n\n0.278599\n0.720324\n\n\n0.62416\n0.000114375\n\n\n1.02093\n0.302333\n\n\n1.55974\n0.146756\n\n\n\n\n\n\n\n\n\n\n\n\nAs shown this interpolation type supports missing data, and just maintains the last available value. Because of this for instance precipitation can be updated while evaporation stays the same.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#sec-state",
    "href": "reference/node/basin.html#sec-state",
    "title": "Basin",
    "section": "1.3 State",
    "text": "1.3 State\nThe state table gives the initial water levels of all Basins.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\n\\(\\ge\\) basin bottom\n\n\n\nEach Basin ID needs to be in the table. To use the final state of an earlier simulation as an initial condition, copy results/basin_state.arrow over to the input_dir, and point the TOML to it:\n[basin]\nstate = \"basin_state.arrow\"\nThis will start of the simulation with the same water levels as the end of the earlier simulation. Since there is no time information in this state, the user is responsible to ensure that the earlier endtime matches the current starttime. This only applies when the user wishes to continue an existing simulation as if it was one continuous simulation.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#profile",
    "href": "reference/node/basin.html#profile",
    "title": "Basin",
    "section": "1.4 Profile",
    "text": "1.4 Profile\nThe profile table defines the physical dimensions of the storage reservoir of each basin.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\narea\nFloat64\n\\(\\text{m}^2\\)\nnon-negative, per node_id: start positive and not decreasing\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\nper node_id: increasing\n\n\n\nThe level is the level at the basin outlet. All levels are defined in meters above a datum that is the same for the entire model. An example of the first 4 rows of such a table is given below. The first 3 rows define the profile of ID 2. The number of rows can vary per ID, and must be at least 2. Using a very large number of rows may impact performance.\n\n\n\nnode_id\narea\nlevel\n\n\n\n\n2\n1.0\n6.0\n\n\n2\n1000.0\n7.0\n\n\n2\n1000.0\n9.0\n\n\n3\n1.0\n2.2\n\n\n\nWe use the symbol \\(A\\) for area, \\(h\\) for level and \\(S\\) for storage. The profile provides a function \\(A(h)\\) for each basin. Internally this get converted to two functions, \\(A(S)\\) and \\(h(S)\\), by integrating over the function, setting the storage to zero for the bottom of the profile. The minimum area cannot be zero to avoid numerical issues. The maximum area is used to convert the precipitation flux into an inflow.\n\n1.4.1 Interpolation\n\n1.4.1.1 Level to area\nThe level to area relationship is defined with the Basin / profile data using linear interpolation. An example of such a relationship is shown below.\n\n\nCode\nfig, ax = plt.subplots()\n\n# Data\nN = 3\narea = 25 * np.cumsum(np.random.rand(N))\nlevel = np.cumsum(np.random.rand(N))\n\n# Interpolation\nax.scatter(level,area, label = \"data\")\nax.plot(level,area, label = \"interpolation\")\nax.set_xticks([level[0], level[-1]])\nax.set_xticklabels([\"bottom\", \"last supplied level\"])\nax.set_xlabel(\"level\", fontsize = fontsize)\nax.set_ylabel(\"area\", fontsize = fontsize)\nax.set_yticks([0])\n\n# Extrapolation\nlevel_extrap = 2 * level[-1] - level[-2]\narea_extrap = 2 * area[-1] - area[-2]\nax.plot([level[-1], level_extrap], [area[-1], area_extrap], color = \"C0\", ls = \"dashed\", label = \"extrapolation\")\nxlim = ax.get_xlim()\nax.set_xlim(xlim[0], (level[-1] + level_extrap)/2)\n\nax.legend()\nfig.tight_layout()\n\nmarkdown_table = pd.DataFrame(\n        data = {\n            \"level\" : level,\n            \"area\" : area\n        }\n    ).to_markdown(index = False)\n\ndisplay(Markdown(markdown_table))\n\n\n\n\n\nlevel\narea\n\n\n\n\n0.140387\n16.7617\n\n\n0.338488\n27.1943\n\n\n1.13923\n41.1616\n\n\n\n\n\n\n\n\n\n\n\n\nFor this interpolation it is validated that:\n\nThe areas are positive and are non-decreasing;\nThere are at least 2 data points.\n\nThis interpolation is used in each evaluation of the right hand side function of the ODE.\n\n\n1.4.1.2 Level to storage\nThe level to storage relationship gives the volume of water in the basin at a given level, which is given by the integral over the level to area relationship from the basin bottom to the given level:\n\\[\n    S(h) = \\int_{h_0}^h A(h')\\text{d}h'.\n\\]\n\n\nCode\nstorage = np.diff(level) * area[:-1] + 0.5 * np.diff(area) * np.diff(level)\nstorage = np.cumsum(storage)\nstorage = np.insert(storage, 0, 0.0)\ndef S(h):\n    i = min(max(0, np.searchsorted(level, h)-1), len(level)-2)\n    return storage[i] + area[i] * (h - level[i]) + 0.5 * (area[i+1] - area[i]) / (level[i+1] - level[i]) * (h - level[i])**2\n\nS = np.vectorize(S)\n\n# Interpolation\nfig, ax = plt.subplots()\nlevel_eval = np.linspace(level[0], level[-1], 100)\nstorage_eval = S(np.linspace(level[0], level[-1], 100))\nax.scatter(level, storage, label = \"storage at datapoints\")\nax.plot(level_eval, storage_eval, label = \"interpolation\")\nax.set_xticks([level[0], level[-1]])\nax.set_xticklabels([\"bottom\", \"last supplied level\"])\nax.set_yticks([0])\nax.set_xlabel(\"level\", fontsize = fontsize)\nax.set_ylabel(\"storage\", fontsize = fontsize)\n\n# Extrapolation\nlevel_eval_extrap = np.linspace(level[-1], level_extrap, 35)\nstorage_eval_extrap = S(level_eval_extrap)\nax.plot(level_eval_extrap, storage_eval_extrap, color = \"C0\", linestyle = \"dashed\", label = \"extrapolation\")\nxlim = ax.get_xlim()\nax.set_xlim(xlim[0], (level[-1] + level_extrap)/2)\nax.legend()\n\n\n\n\n\n\n\n\n\nfor converting the initial state in terms of levels to an initial state in terms of storages used in the core.\n\n\n1.4.1.3 Interactive basin example\nThe profile data is not detailed enough to create a full 3D picture of the basin. However, if we assume the profile data is for a stretch of canal of given length, the following plot shows a cross section of the basin.\n\n\nCode\nimport plotly.graph_objects as go\nimport numpy as np\n\ndef linear_interpolation(X,Y,x):\n    i = min(max(0, np.searchsorted(X, x)-1), len(X)-2)\n    return Y[i] + (Y[i+1] - Y[i])/(X[i+1] - X[i]) * (x - X[i])\n\ndef A(h):\n    return linear_interpolation(level, area, h)\n\nfig = go.Figure()\n\nx = area/2\nx = np.concat([-x[::-1], x])\ny = np.concat([level[::-1], level])\n\n# Basin profile\nfig.add_trace(\n    go.Scatter(\n        x = x,\n        y = y,\n        line = dict(color = \"green\"),\n        name = \"Basin profile\"\n    )\n)\n\n# Basin profile extrapolation\ny_extrap = np.array([level[-1], level_extrap])\nx_extrap = np.array([area[-1]/2, area_extrap/2])\nfig.add_trace(\n    go.Scatter(\n        x = x_extrap,\n        y = y_extrap,\n        line = dict(color = \"green\", dash = \"dash\"),\n        name = \"Basin extrapolation\"\n    )\n)\nfig.add_trace(\n    go.Scatter(\n        x = -x_extrap,\n        y = y_extrap,\n        line = dict(color = \"green\", dash = \"dash\"),\n        showlegend = False\n    )\n)\n\n# Water level\nfig.add_trace(\n    go.Scatter(x = [-area[0]/2, area[0]/2],\n               y = [level[0], level[0]],\n               line = dict(color = \"blue\"),\n               name= \"Water level\")\n)\n\n# Fill area\nfig.add_trace(\n    go.Scatter(\n        x = [],\n        y = [],\n        fill = 'tonexty',\n        fillcolor = 'rgba(0, 0, 255, 0.2)',\n        line = dict(color = 'rgba(255, 255, 255, 0)'),\n        name = \"Filled area\"\n    )\n)\n\n# Create slider steps\nsteps = []\nfor h in np.linspace(level[0], level_extrap, 100):\n    a = A(h)\n    s = S(h).item()\n\n\n    i = min(max(0, np.searchsorted(level, h)-1), len(level)-2)\n    fill_area = np.append(area[:i+1], a)\n    fill_level = np.append(level[:i+1], h)\n    fill_x = np.concat([-fill_area[::-1]/2, fill_area/2])\n    fill_y = np.concat([fill_level[::-1], fill_level])\n\n    step = dict(\n        method = \"update\",\n        args=[\n            {\n                \"x\": [x, x_extrap, -x_extrap, [-a/2, a/2], fill_x],\n                \"y\": [y, y_extrap, y_extrap, [h, h], fill_y]\n            },\n            {\"title\": f\"Interactive water level &lt;br&gt; Area: {a:.2f}, Storage: {s:.2f}\"}\n        ],\n        label=str(round(h, 2))\n    )\n    steps.append(step)\n\n# Create slider\nsliders = [dict(\n    active=0,\n    currentvalue={\"prefix\": \"Level: \"},\n    pad={\"t\": 25},\n    steps=steps\n)]\n\nfig.update_layout(\n    title = {\n        \"text\": f\"Interactive water level &lt;br&gt; Area: {area[0]:.2f}, Storage: 0.0\",\n    },\n    yaxis_title = \"level\",\n    sliders = sliders,\n    margin = {\"t\": 100, \"b\": 100}\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\n1.4.1.4 Storage to level\nThe level is computed from the storage by inverting the level to storage relationship shown above. See here for more details.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#area",
    "href": "reference/node/basin.html#area",
    "title": "Basin",
    "section": "1.5 Area",
    "text": "1.5 Area\nThe optional area table is not used during computation, but provides a place to associate areas in the form of polygons to Basins. Using this makes it easier to recognize which water or land surfaces are represented by Basins.\n\n\n\ncolumn\ntype\nrestriction\n\n\n\n\nnode_id\nInt32\nsorted\n\n\ngeom\nPolygon or MultiPolygon\n(optional)",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#subgrid",
    "href": "reference/node/basin.html#subgrid",
    "title": "Basin",
    "section": "1.6 Subgrid",
    "text": "1.6 Subgrid\nThe subgrid table defines a piecewise linear interpolation from a basin water level to a subgrid element water level. Many subgrid elements may be associated with a single basin, each with distinct interpolation functions. This functionality can be used to translate a single lumped basin level to a more spatially detailed representation (e.g comparable to the output of a hydrodynamic simulation).\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nsubgrid_id\nInt32\n-\nsorted\n\n\nnode_id\nInt32\n-\nconstant per subgrid_id\n\n\nbasin_level\nFloat64\n\\(\\text{m}\\)\nsorted per subgrid_id\n\n\nsubgrid_level\nFloat64\n\\(\\text{m}\\)\nsorted per subgrid_id\n\n\n\nThe table below shows example input for two subgrid elements:\n\n\n\nsubgrid_id\nnode_id\nbasin_level\nsubgrid_level\n\n\n\n\n1\n9\n0.0\n0.0\n\n\n1\n9\n1.0\n1.0\n\n\n1\n9\n2.0\n2.0\n\n\n2\n9\n0.0\n0.5\n\n\n2\n9\n1.0\n1.5\n\n\n2\n9\n2.0\n2.5\n\n\n\nBoth subgrid elements use the water level of the basin with node_id 9 to interpolate to their respective water levels. The first element has a one to one connection with the water level; the second also has a one to one connection, but is offset by half a meter. A basin water level of 0.3 would be translated to a water level of 0.3 for the first subgrid element, and 0.8 for the second. Water levels beyond the last basin_level are linearly extrapolated.\nNote that the interpolation to subgrid water level is not constrained by any water balance within Ribasim. Generally, to create physically meaningful subgrid water levels, the subgrid table must be parametrized properly such that the spatially integrated water volume of the subgrid elements agrees with the total storage volume of the basin.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#sec-basin-conc",
    "href": "reference/node/basin.html#sec-basin-conc",
    "title": "Basin",
    "section": "1.7 Concentration",
    "text": "1.7 Concentration\nThis table defines the concentration(s) of (a) substance(s) for the inflow boundaries of a Basin node.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ntime\nDateTime\n-\nsorted per node_id\n\n\nsubstance\nString\n\ncan correspond to known Delwaq substances\n\n\ndrainage\nFloat64\n\\(\\text{g}/\\text{m}^3\\)\n(optional)\n\n\nprecipitation\nFloat64\n\\(\\text{g}/\\text{m}^3\\)\n(optional)",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#sec-basin-conc-state",
    "href": "reference/node/basin.html#sec-basin-conc-state",
    "title": "Basin",
    "section": "1.8 ConcentrationState",
    "text": "1.8 ConcentrationState\nThis table defines the concentration(s) of (a) substance(s) in the Basin at the start of the simulation.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\nsubstance\nString\n-\ncan correspond to known Delwaq substances\n\n\nconcentration\nFloat64\n\\(\\text{g}/\\text{m}^3\\)",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#concentrationexternal",
    "href": "reference/node/basin.html#concentrationexternal",
    "title": "Basin",
    "section": "1.9 ConcentrationExternal",
    "text": "1.9 ConcentrationExternal\nThis table is used for (external) concentrations, that can be used for Control lookups.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ntime\nDateTime\n-\nsorted per node_id\n\n\nsubstance\nString\n-\ncan correspond to known Delwaq substances\n\n\nconcentration\nFloat64\n\\(\\text{g}/\\text{m}^3\\)",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#sec-reduction-factor",
    "href": "reference/node/basin.html#sec-reduction-factor",
    "title": "Basin",
    "section": "2.1 The reduction factor",
    "text": "2.1 The reduction factor\nAt several points in the equations below a reduction factor is used. This is a term that makes certain transitions more smooth, for instance when a pump stops providing water when its source basin dries up. The reduction factor is given by\n\\[\\begin{align}\n    \\phi(x; p) =\n    \\begin{cases}\n    0 &\\text{if}\\quad x &lt; 0 \\\\\n        -2 \\left(\\frac{x}{p}\\right)^3 + 3\\left(\\frac{x}{p}\\right)^2 &\\text{if}\\quad 0 \\le x \\le p \\\\\n        1 &\\text{if}\\quad x &gt; p\n    \\end{cases}\n\\end{align}\\]\nHere \\(p &gt; 0\\) is the threshold value which determines the interval \\([0,p]\\) of the smooth transition between \\(0\\) and \\(1\\), see the plot below.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x, p = 3):\n    x_scaled = x / p\n    phi = (-2 * x_scaled + 3) * x_scaled**2\n    phi = np.where(x &lt; 0, 0, phi)\n    phi = np.where(x &gt; p, 1, phi)\n\n    return phi\n\nfontsize = 15\np = 3\nN = 100\nx_min = -1\nx_max = 4\nx = np.linspace(x_min,x_max,N)\nphi = f(x,p)\n\nfig,ax = plt.subplots(dpi=80)\nax.plot(x,phi)\n\ny_lim = ax.get_ylim()\n\nax.set_xticks([0,p], [0,\"$p$\"], fontsize=fontsize)\nax.set_yticks([0,1], [0,1], fontsize=fontsize)\nax.hlines([0,1],x_min,x_max, color = \"k\", ls = \":\", zorder=-1)\nax.vlines([0,p], *y_lim, color = \"k\", ls = \":\")\nax.set_xlim(x_min,x_max)\nax.set_xlabel(\"$x$\", fontsize=fontsize)\nax.set_ylabel(r\"$\\phi(x;p)$\", fontsize=fontsize)\nax.set_ylim(y_lim)\n\nfig.tight_layout()\nplt.show()",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#precipitation",
    "href": "reference/node/basin.html#precipitation",
    "title": "Basin",
    "section": "2.2 Precipitation",
    "text": "2.2 Precipitation\nThe precipitation term is given by\n\\[\n    Q_P = P \\cdot A.\n\\tag{1}\\]\nHere \\(P = P(t)\\) is the precipitation rate and \\(A\\) is the maximum area given in the Basin / profile table. Precipitation in the Basin area is assumed to be directly added to the Basin storage. The modeler needs to ensure all precipitation enters the model, and there is no overlap in the maximum profile areas, otherwise extra water is created. If a part of the catchment is not in any Basin profile, the modeler has to verify that water source is not forgotten. It can for instance be converted to a flow rate and added to a Basin as a FlowBoundary.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#evaporation",
    "href": "reference/node/basin.html#evaporation",
    "title": "Basin",
    "section": "2.3 Evaporation",
    "text": "2.3 Evaporation\nThe evaporation term is given by\n\\[\n    Q_E = E_\\text{pot} \\cdot A(u) \\cdot \\phi(d;0.1).\n\\tag{2}\\]\nHere \\(E_\\text{pot} = E_\\text{pot}(t)\\) is the potential evaporation rate and \\(A\\) is the wetted area. \\(\\phi\\) is the reduction factor which depends on the depth \\(d\\). It provides a smooth gradient as \\(u \\rightarrow 0\\).\nA straightforward formulation \\(Q_E = \\mathrm{max}(E_\\text{pot} A(u), 0)\\) is unsuitable, as \\(\\frac{\\mathrm{d}Q_E}{\\mathrm{d}u}(u=0)\\) is not well-defined.\nA non-smooth derivative results in extremely small timesteps and long computation time. In a physical interpretation, evaporation is switched on or off per individual droplet of water. In general, the effect of the reduction term is negligible, or not even necessary. As a surface water dries, its wetted area decreases and so does the evaporative flux. However, for (simplified) cases with constant wetted surface (a rectangular profile), evaporation only stops at \\(u = 0\\).",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#infiltration-and-drainage",
    "href": "reference/node/basin.html#infiltration-and-drainage",
    "title": "Basin",
    "section": "2.4 Infiltration and Drainage",
    "text": "2.4 Infiltration and Drainage\nInfiltration is provided as a lump sum for the Basin. If Ribasim is coupled with MODFLOW 6, the infiltration is computed as the sum of all positive flows of the MODFLOW 6 boundary conditions in the Basin:\n\\[\n    Q_\\text{inf} = \\sum_{i=1}^{n} \\sum_{j=1}^{m} \\max(Q_{\\mathrm{mf6}_{i,j}}, 0.0)\n\\tag{3}\\]\nWhere \\(i\\) is the index of the boundary condition, \\(j\\) the MODFLOW 6 cell index, \\(n\\) the number of boundary conditions, and \\(\\text{m}\\) the number of MODFLOW 6 cells in the Basin. \\(Q_{\\mathrm{mf6}_{i,j}}\\) is the flow computed by MODFLOW 6 for cell \\(j\\) for boundary condition \\(i\\).\nDrainage is a lump sum for the Basin, and consists of the sum of the absolute value of all negative flows of the MODFLOW 6 boundary conditions in the Basin.\n\\[\n    Q_\\text{drn} = \\sum_{i=1}^{n} \\sum_{j=1}^{m} \\left| \\min(Q_{\\mathrm{mf6}_{i,j}}, 0.0) \\right|\n\\tag{4}\\]\nThe interaction with MODFLOW 6 boundary conditions is explained in greater detail in the the iMOD Coupler docs.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/outlet.html",
    "href": "reference/node/outlet.html",
    "title": "Outlet",
    "section": "",
    "text": "The Outlet lets water flow downstream with a prescribed flow rate. It is similar to the Pump, except that water only flows down, by gravity.\nWhen PID controlled, the Outlet must point towards the controlled Basin in terms of edges.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Outlet"
    ]
  },
  {
    "objectID": "reference/node/outlet.html#static",
    "href": "reference/node/outlet.html#static",
    "title": "Outlet",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\ncontrol_state\nString\n-\n(optional) sorted per node_id\n\n\nactive\nBool\n-\n(optional, default true)\n\n\nflow_rate\nFloat64\n$^3/$\nnon-negative\n\n\nmin_flow_rate\nFloat64\n$^3/$\n(optional, default 0.0)\n\n\nmax_flow_rate\nFloat64\n$^3/$\n(optional)\n\n\nmin_upstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)\n\n\nmax_downstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)",
    "crumbs": [
      "Reference",
      "Nodes",
      "Outlet"
    ]
  },
  {
    "objectID": "reference/node/terminal.html",
    "href": "reference/node/terminal.html",
    "title": "Terminal",
    "section": "",
    "text": "A Terminal is a water sink without state or properties. Any water that flows into a Terminal node is removed from the model. No water can come into the model from a Terminal node. For example, Terminal nodes can be used as a downstream boundary.\n\n1 Tables\nNo tables are required for Terminal nodes.\n\n\n2 Equations\nThe incoming node determines the flow into the Terminal node.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Terminal"
    ]
  }
]